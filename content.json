{"meta":{"title":"相思似海深旧事如天远","subtitle":"where there is a will there is a way","description":"江西理工大学2020级硕士研究生","author":null,"url":"http://pistachio0812.github.io","root":"/"},"pages":[{"title":"categories","date":"2022-03-13T07:36:30.000Z","updated":"2022-03-13T12:55:19.588Z","comments":true,"path":"categories/index.html","permalink":"http://pistachio0812.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-03-13T07:39:41.000Z","updated":"2022-03-13T13:01:34.747Z","comments":true,"path":"tags/index.html","permalink":"http://pistachio0812.github.io/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2022-03-13T07:41:41.000Z","updated":"2022-03-13T13:48:25.663Z","comments":true,"path":"about/index.html","permalink":"http://pistachio0812.github.io/about/index.html","excerpt":"","text":"网站开发者是江西理工大学2020级硕士研究生，热衷于学习一些除学习之外的技能，硕士研究方向为目标检测，如果有志同道合的朋友看到这里，希望可以进一步探讨，可以通过CSDN留言给我。"}],"posts":[{"title":"文献阅读笔记","slug":"文献阅读合集","date":"2022-04-08T01:40:57.885Z","updated":"2022-04-08T01:50:30.981Z","comments":true,"path":"2022/04/08/en/文献阅读合集/","link":"","permalink":"http://pistachio0812.github.io/2022/04/08/en/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%90%88%E9%9B%86/","excerpt":"","text":"1.DetNet 2.SNIP","categories":[],"tags":[]},{"title":"Matplotlib学习笔记","slug":"Matplotlib学习笔记","date":"2022-04-03T12:25:29.304Z","updated":"2022-04-07T02:16:54.501Z","comments":true,"path":"2022/04/03/CN/Matplotlib学习笔记/","link":"","permalink":"http://pistachio0812.github.io/2022/04/03/CN/Matplotlib%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"介绍Matplotlib 是 Python 的绘图库，它能让使用者很轻松地将数据图形化，并且提供多样化的输出格式。可以用来绘制各种静态，动态，交互式的图表。是一个非常强大的 Python 画图工具，我们可以使用该工具将很多数据通过图表的形式更直观的呈现出来。可以绘制线图、散点图、等高线图、条形图、柱状图、3D 图形、甚至是图形动画等等。 应用Matplotlib 通常与 NumPy 和 SciPy（Scientific Python）一起使用， 这种组合广泛用于替代 MatLab，是一个强大的科学计算环境，有助于我们通过 Python 学习数据科学或者机器学习。 SciPy 是一个开源的 Python 算法库和数学工具包。 SciPy 包含的模块有最优化、线性代数、积分、插值、特殊函数、快速傅里叶变换、信号处理和图像处理、常微分方程求解和其他科学与工程中常用的计算。 安装本章节，我们使用 pip 工具来安装 Matplotlib 库，如果还未安装该工具，可以参考 Python pip 安装与使用。 升级 pip： 1python3 -m pip install -U pip 安装 matplotlib 库： 1python3 -m pip install -U matplotlib 安装完成后，我们就可以通过 import 来导入 matplotlib 库： import matplotlib 以下实例，我们通过导入 matplotlib 库，然后查看 matplotlib 库的版本号： 实例1: import matplotlib print(matplotlib.__version__) 执行以上代码，输出结果如下： 13.4.2 Matplotlib PyplotPyplot 是 Matplotlib 的子库，提供了和 MATLAB 类似的绘图 API。 Pyplot 是常用的绘图模块，能很方便让用户绘制 2D 图表。 Pyplot 包含一系列绘图函数的相关函数，每个函数会对当前的图像进行一些修改，例如：给图像加上标记，生新的图像，在图像中产生新的绘图区域等等。 使用的时候，我们可以使用 import 导入 pyplot 库，并设置一个别名 plt： import matplotlib.pyplot as plt 这样我们就可以使用 plt 来引用 Pyplot 包的方法。 以下实例，我们通过两个坐标 (0,0) 到 (6,100) 来绘制一条线: 实例1: 12345678import matplotlib.pyplot as pltimport numpy as npxpoints = np.array([0, 6])ypoints = np.array([0, 100])plt.plot(xpoints, ypoints)plt.show() 输出结果如下： 以上实例中我们使用了 Pyplot 的 plot() 函数， plot() 函数是绘制二维图形的最基本函数。 plot() 用于画图它可以绘制点和线，语法格式如下： 1234# 画单条线plot([x], y, [fmt], *, data=None, **kwargs)# 画多条线plot([x], y, [fmt], [x2], y2, [fmt2], ..., **kwargs) 参数说明： x, y：点或线的节点，x 为 x 轴数据，y 为 y 轴数据，数据可以列表或数组。 fmt：可选，定义基本格式（如颜色、标记和线条样式）。 **kwargs：可选，用在二维平面图上，设置指定属性，如标签，线的宽度等。 1234&gt;&gt;&gt; plot(x, y) # 创建 y 中数据与 x 中对应值的二维线图，使用默认样式&gt;&gt;&gt; plot(x, y, &#x27;bo&#x27;) # 创建 y 中数据与 x 中对应值的二维线图，使用蓝色实心圈绘制&gt;&gt;&gt; plot(y) # x 的值为 0..N-1&gt;&gt;&gt; plot(y, &#x27;r+&#x27;) # 使用红色 + 号 颜色字符：‘b’ 蓝色，’m’ 洋红色，’g’ 绿色，’y’ 黄色，’r’ 红色，’k’ 黑色，’w’ 白色，’c’ 青绿色，’#008000’ RGB 颜色符串。多条曲线不指定颜色时，会自动选择不同颜色。 线型参数：‘‐’ 实线，’‐‐’ 破折线，’‐.’ 点划线，’:’ 虚线。 标记字符：‘.’ 点标记，’,’ 像素标记(极小点)，’o’ 实心圈标记，’v’ 倒三角标记，’^’ 上三角标记，’&gt;’ 右三角标记，’&lt;’ 左三角标记…等等。 如果我们只想绘制两个坐标点，而不是一条线，可以使用 o 参数，表示一个实心圈的标记。 实例2：绘制坐标 (1, 3) 和 (8, 10) 的两个点 12345678import matplotlib.pyplot as pltimport numpy as npxpoints = np.array([1, 8])ypoints = np.array([3, 10])plt.plot(xpoints, ypoints, &#x27;o&#x27;)plt.show() 我们也可以绘制任意数量的点，只需确保两个轴上的点数相同即可。 实例3：绘制一条不规则线，坐标为 (1, 3) 、 (2, 8) 、(6, 1) 、(8, 10)，对应的两个数组为：[1, 2, 6, 8] 与 [3, 8, 1, 10]。 12345678import matplotlib.pyplot as pltimport numpy as npxpoints = np.array([1, 2, 6, 8])ypoints = np.array([3, 8, 1, 10])plt.plot(xpoints, ypoints)plt.show() 实例4：如果我们不指定 x 轴上的点，y只限定范围。 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([3, 10])plt.plot(ypoints)plt.show() 从上图可以看出 x 的值默认设置为 **[0, 1]**。 实例5：如果我们不指定 x 轴上的点，y表明具体的点，则 x 会根据 y 的值来设置为 0, 1, 2, 3..N-1 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([3, 8, 1, 10, 5, 7])plt.plot(ypoints)plt.show() 实例6：以下实例我们绘制一个正弦和余弦图，在 plt.plot() 参数中包含两对 x,y 值，第一对是 x,y，这对应于正弦函数，第二对是 x,z，这对应于余弦函数。 12345678import matplotlib.pyplot as pltimport numpy as npx = np.arange(0,4*np.pi,0.1) # start,stop,stepy = np.sin(x)z = np.cos(x)plt.plot(x,y,x,z)plt.show() Matplotlib 绘图标记绘图过程如果我们想要给坐标自定义一些不一样的标记，就可以使用 plot() 方法的 marker 参数来定义。 实例1:定义实心圆标记 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([1,3,4,5,8,9,6,1,3,4,5,2,4])plt.plot(ypoints, marker = &#x27;o&#x27;)plt.show() marker可以定义的符号如下： 标记 符号 描述 “.” 点 “,” 像素点 “o” 实心圆 “v” 下三角 “^” 上三角 “&lt;” 左三角 “&gt;” 右三角 “1” 下三叉 “2” 上三叉 “3” 左三叉 “4” 右三叉 “8” 八角形 “s” 正方形 “p” 五边形 “P” 加号（填充） “*” 星号 “h” 六边形 1 “H” 六边形 2 “+” 加号 “x” 乘号 x “X” 乘号 x (填充) “D” 菱形 “d” 瘦菱形 “|” 竖线 “_” 横线 0 (TICKLEFT) 左横线 1 (TICKRIGHT) 右横线 2 (TICKUP) 上竖线 3 (TICKDOWN) 下竖线 4 (CARETLEFT) 左箭头 5 (CARETRIGHT) 右箭头 6 (CARETUP) 上箭头 7 (CARETDOWN) 下箭头 8 (CARETLEFTBASE) 左箭头 (中间点为基准) 9 (CARETRIGHTBASE) 右箭头 (中间点为基准) 10 (CARETUPBASE) 上箭头 (中间点为基准) 11 (CARETDOWNBASE) 下箭头 (中间点为基准) “None”, “ “ or “” 没有任何标记 ‘$…$’ 渲染指定的字符。例如 “$f$” 以字母 f 为标记。 实例2:定义了 ***** 标记 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([1,3,4,5,8,9,6,1,3,4,5,2,4])plt.plot(ypoints, marker = &#x27;*&#x27;)plt.show() 实例3:定义下箭头 12345import matplotlib.pyplot as pltimport matplotlib.markersplt.plot([1, 2, 3], marker=matplotlib.markers.CARETDOWNBASE)plt.show() fmt 参数fmt 参数定义了基本格式，如标记、线条样式和颜色。 1fmt = &#x27;[marker][line][color]&#x27; 例如 o:r，o 表示实心圆标记，**:** 表示虚线，r 表示颜色为红色。 实例4： 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([6, 2, 13, 10])plt.plot(ypoints, &#x27;o:r&#x27;)plt.show() 线类型： 线类型标记 描述 ‘-‘ 实线 ‘:’ 虚线 ‘–’ 破折线 ‘-.’ 点划线 颜色类型： 颜色标记 描述 ‘r’ 红色 ‘g’ 绿色 ‘b’ 蓝色 ‘c’ 青色 ‘m’ 品红 ‘y’ 黄色 ‘k’ 黑色 ‘w’ 白色 标记大小和颜色我们可以自定义标记的大小与颜色，使用的参数分别是： markersize，简写为 ms：定义标记的大小。 markerfacecolor，简写为 mfc：定义标记内部的颜色。 markeredgecolor，简写为 mec：定义标记边框的颜色。 实例5：设置标记大小 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([6, 2, 13, 10])plt.plot(ypoints, marker = &#x27;o&#x27;, ms = 20)plt.show() 实例6：设置标记外边框颜色 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([6, 2, 13, 10])plt.plot(ypoints, marker = &#x27;o&#x27;, ms = 20, mec = &#x27;r&#x27;)plt.show() 实例7：设置标记内部颜色 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([6, 2, 13, 10])plt.plot(ypoints, marker = &#x27;o&#x27;, ms = 20, mfc = &#x27;r&#x27;)plt.show() 实例8：自定义标记内部与边框的颜色 123456import matplotlib.pyplot as pltimport numpy as npypoints = np.array([6, 2, 13, 10])plt.plot(ypoints, marker = &#x27;o&#x27;, ms = 20, mec = &#x27;#4CAF50&#x27;, mfc = &#x27;#4CAF50&#x27;)plt.show() Matplotlib 绘图线绘图过程如果我们自定义线的样式，包括线的类型、颜色和大小等。 线的类型线的类型可以使用 linestyle 参数来定义，简写为 ls 类型 简写 说明 ‘solid’ (默认) ‘-‘ 实线 ‘dotted’ ‘:’ 点虚线 ‘dashed’ ‘–’ 破折线 ‘dashdot’ ‘-.’ 点划线 ‘None’ ‘’ 或 ‘ ‘ 不画线 实例1： 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([6, 2, 13, 10])plt.plot(ypoints, linestyle = &#x27;dotted&#x27;)plt.show() 实例2：使用简写 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([6, 2, 13, 10])plt.plot(ypoints, ls = &#x27;-.&#x27;)plt.show() 线的颜色线的颜色可以使用 color 参数来定义，简写为 c。 颜色类型： 颜色标记 描述 ‘r’ 红色 ‘g’ 绿色 ‘b’ 蓝色 ‘c’ 青色 ‘m’ 品红 ‘y’ 黄色 ‘k’ 黑色 ‘w’ 白色 当然也可以自定义颜色类型，例如：SeaGreen、#8FBC8F 等，完整样式可以参考 HTML 颜色值。 实例3： 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([6, 2, 13, 10])plt.plot(ypoints, color = &#x27;r&#x27;)plt.show() 实例4： 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([6, 2, 13, 10])plt.plot(ypoints, c = &#x27;#8FBC8F&#x27;)plt.show() 实例5： 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([6, 2, 13, 10])plt.plot(ypoints, c = &#x27;SeaGreen&#x27;)plt.show() 线的宽度线的宽度可以使用 linewidth 参数来定义，简写为 lw，值可以是浮点数，如：1、2.0、5.67 等 实例6： 1234567import matplotlib.pyplot as pltimport numpy as npypoints = np.array([6, 2, 13, 10])plt.plot(ypoints, linewidth = &#x27;12.5&#x27;)plt.show() 多条线plot() 方法中可以包含多对 x,y 值来绘制多条线。 实例7： 12345678910import matplotlib.pyplot as pltimport numpy as npy1 = np.array([3, 7, 5, 9])y2 = np.array([6, 2, 13, 10])plt.plot(y1)plt.plot(y2)plt.show() 从上图可以看出 x 的值默认设置为 **[0, 1, 2, 3]**。 实例8： 12345678910import matplotlib.pyplot as pltimport numpy as npx1 = np.array([0, 1, 2, 3])y1 = np.array([3, 7, 5, 9])x2 = np.array([0, 1, 2, 3])y2 = np.array([6, 2, 13, 10])plt.plot(x1, y1, x2, y2)plt.show() Matplotlib 轴标签和标题我们可以使用 xlabel() 和 ylabel() 方法来设置 x 轴和 y 轴的标签。 实例1： 1234567891011import numpy as npimport matplotlib.pyplot as pltx = np.array([1, 2, 3, 4])y = np.array([1, 4, 9, 16])plt.plot(x, y)plt.xlabel(&quot;x - label&quot;)plt.ylabel(&quot;y - label&quot;)plt.show() 标题实例2：使用 title() 方法来设置标题: 123456789101112import numpy as npimport matplotlib.pyplot as pltx = np.array([1, 2, 3, 4])y = np.array([1, 4, 9, 16])plt.plot(x, y)plt.title(&quot;line chart&quot;)plt.xlabel(&quot;x - label&quot;)plt.ylabel(&quot;y - label&quot;)plt.show() 图像中文显示Matplotlib 默认情况不支持中文，我们可以使用以下简单的方法来解决。 这里我们使用思源黑体，思源黑体是 Adobe 与 Google 推出的一款开源字体。 官网：https://source.typekit.com/source-han-serif/cn/ GitHub 地址：https://github.com/adobe-fonts/source-han-sans/tree/release/OTF/SimplifiedChinese 打开链接后，在里面选一个就好了： 你也可以在网盘下载: https://pan.baidu.com/s/10-w1JbXZSnx3Tm6uGpPGOw，提取码：**yxqu**。 可以下载个 OTF 字体，比如 SourceHanSansSC-Bold.otf，将该文件文件放在当前执行的代码文件中： SourceHanSansSC-Bold.otf 文件放在当前执行的代码文件中。 实例3： 12345678910111213141516import numpy as np from matplotlib import pyplot as plt import matplotlib # fname 为 你下载的字体库路径，注意 SourceHanSansSC-Bold.otf 字体的路径zhfont1 = matplotlib.font_manager.FontProperties(fname=&quot;SourceHanSansSC-Bold.otf&quot;) x = np.arange(1,11) y = 2 * x + 5 plt.title(&quot;测试&quot;, fontproperties=zhfont1) # fontproperties 设置中文显示，fontsize 设置字体大小plt.xlabel(&quot;x标签&quot;, fontproperties=zhfont1)plt.ylabel(&quot;y标签&quot;, fontproperties=zhfont1)plt.plot(x,y) plt.show() 此外，我们还可以使用系统的字体： 123456from matplotlib import pyplot as pltimport matplotliba=sorted([f.name for f in matplotlib.font_manager.fontManager.ttflist])for i in a: print(i) 打印出你的 font_manager 的 ttflist 中所有注册的名字，找一个看中文字体例如：STFangsong(仿宋）,然后添加以下代码即可： 1plt.rcParams[&#x27;font.family&#x27;]=[&#x27;STFangsong&#x27;] 实例4：:自定义字体的样式 12345678910111213141516171819import numpy as npfrom matplotlib import pyplot as pltimport matplotlib # fname 为 你下载的字体库路径，注意 SourceHanSansSC-Bold.otf 字体的路径，size 参数设置字体大小zhfont1 = matplotlib.font_manager.FontProperties(fname=&quot;SourceHanSansSC-Bold.otf&quot;, size=18)font1 = &#123;&#x27;color&#x27;:&#x27;blue&#x27;,&#x27;size&#x27;:20&#125;font2 = &#123;&#x27;color&#x27;:&#x27;darkred&#x27;,&#x27;size&#x27;:15&#125;x = np.arange(1,11)y = 2 * x + 5# fontdict 可以使用 css 来设置字体样式plt.title(&quot;菜鸟教程 - 测试&quot;, fontproperties=zhfont1, fontdict = font1) # fontproperties 设置中文显示，fontsize 设置字体大小plt.xlabel(&quot;x 轴&quot;, fontproperties=zhfont1)plt.ylabel(&quot;y 轴&quot;, fontproperties=zhfont1)plt.plot(x,y)plt.show() 标题与标签的定位title() 方法提供了 loc 参数来设置标题显示的位置，可以设置为: **’left’, ‘right’, 和 ‘center’， 默认值为 ‘center’**。 xlabel() 方法提供了 loc 参数来设置 x 轴显示的位置，可以设置为: **’left’, ‘right’, 和 ‘center’， 默认值为 ‘center’**。 ylabel() 方法提供了 loc 参数来设置 y 轴显示的位置，可以设置为: **’bottom’, ‘top’, 和 ‘center’， 默认值为 ‘center’**。 实例5： 12345678910111213141516171819import numpy as npfrom matplotlib import pyplot as pltimport matplotlib # fname 为 你下载的字体库路径，注意 SourceHanSansSC-Bold.otf 字体的路径，size 参数设置字体大小zhfont1 = matplotlib.font_manager.FontProperties(fname=&quot;SourceHanSansSC-Bold.otf&quot;, size=18)font1 = &#123;&#x27;color&#x27;:&#x27;blue&#x27;,&#x27;size&#x27;:20&#125;font2 = &#123;&#x27;color&#x27;:&#x27;darkred&#x27;,&#x27;size&#x27;:15&#125;x = np.arange(1,11)y = 2 * x + 5# fontdict 可以使用 css 来设置字体样式plt.title(&quot;菜鸟教程 - 测试&quot;, fontproperties=zhfont1, fontdict = font1, loc=&quot;left&quot;) # fontproperties 设置中文显示，fontsize 设置字体大小plt.xlabel(&quot;x 轴&quot;, fontproperties=zhfont1, loc=&quot;left&quot;)plt.ylabel(&quot;y 轴&quot;, fontproperties=zhfont1, loc=&quot;top&quot;)plt.plot(x,y)plt.show() Matplotlib 网格线我们可以使用 pyplot 中的 grid() 方法来设置图表中的网格线。 grid() 方法语法格式如下： 1matplotlib.pyplot.grid(b=None, which=&#x27;major&#x27;, axis=&#x27;both&#x27;, ) 参数说明： b：可选，默认为 None，可以设置布尔值，true 为显示网格线，false 为不显示，如果设置 **kwargs 参数，则值为 true。 which：可选，可选值有 ‘major’、’minor’ 和 ‘both’，默认为 ‘major’，表示应用更改的网格线。 axis：可选，设置显示哪个方向的网格线，可以是取 ‘both’（默认），’x’ 或 ‘y’，分别表示两个方向，x 轴方向或 y 轴方向。 **kwargs：可选，设置网格样式，可以是 color&#x3D;’r’, linestyle&#x3D;’-‘ 和 linewidth&#x3D;2，分别表示网格线的颜色，样式和宽度。 实例1：添加一个简单的网格线，参数使用默认值 12345678910111213141516import numpy as npimport matplotlib.pyplot as pltx = np.array([1, 2, 3, 4])y = np.array([1, 4, 9, 16])plt.title(&quot;RUNOOB grid() Test&quot;)plt.xlabel(&quot;x - label&quot;)plt.ylabel(&quot;y - label&quot;)plt.plot(x, y)plt.grid()plt.show() 实例2:添加一个简单的网格线，axis 参数使用 x，设置 x 轴方向显示网格线 12345678910111213141516import numpy as npimport matplotlib.pyplot as pltx = np.array([1, 2, 3, 4])y = np.array([1, 4, 9, 16])plt.title(&quot;RUNOOB grid() Test&quot;)plt.xlabel(&quot;x - label&quot;)plt.ylabel(&quot;y - label&quot;)plt.plot(x, y)plt.grid(axis=&#x27;x&#x27;) # 设置 y 就在轴方向显示网格线plt.show() 以下实例添加一个简单的网格线，并设置网格线的样式，格式如下： 1grid(color = &#x27;color&#x27;, linestyle = &#x27;linestyle&#x27;, linewidth = number) 参数说明： color：‘b’ 蓝色，’m’ 洋红色，’g’ 绿色，’y’ 黄色，’r’ 红色，’k’ 黑色，’w’ 白色，’c’ 青绿色，’#008000’ RGB 颜色符串。 linestyle：‘‐’ 实线，’‐‐’ 破折线，’‐.’ 点划线，’:’ 虚线。 linewidth：设置线的宽度，可以设置一个数字。 实例3： 12345678910111213141516import numpy as npimport matplotlib.pyplot as pltx = np.array([1, 2, 3, 4])y = np.array([1, 4, 9, 16])plt.title(&quot;RUNOOB grid() Test&quot;)plt.xlabel(&quot;x - label&quot;)plt.ylabel(&quot;y - label&quot;)plt.plot(x, y)plt.grid(color = &#x27;r&#x27;, linestyle = &#x27;--&#x27;, linewidth = 0.5)plt.show() Matplotlib绘制多图我们可以使用 pyplot 中的 subplot() 和 subplots() 方法来绘制多个子图。 subplot() 方法在绘图时需要指定位置，subplots() 方法可以一次生成多个，在调用时只需要调用生成对象的 ax 即可。 subplot1234subplot(nrows, ncols, index, **kwargs)subplot(pos, **kwargs)subplot(**kwargs)subplot(ax) 以上函数将整个绘图区域分成 nrows 行和 ncols 列，然后从左到右，从上到下的顺序对每个子区域进行编号 1…N ，左上的子区域的编号为 1、右下的区域编号为 N，编号可以通过参数 index 来设置。 设置 numRows ＝ 1，numCols ＝ 2，就是将图表绘制成 1x2 的图片区域, 对应的坐标为： 1(1, 1), (1, 2) plotNum ＝ 1, 表示的坐标为(1, 1), 即第一行第一列的子图。 plotNum ＝ 2, 表示的坐标为(1, 2), 即第一行第二列的子图。 实例1： 123456789101112131415161718192021import matplotlib.pyplot as pltimport numpy as np#plot 1:xpoints = np.array([0, 6])ypoints = np.array([0, 100])plt.subplot(1, 2, 1)plt.plot(xpoints,ypoints)plt.title(&quot;plot 1&quot;)#plot 2:x = np.array([1, 2, 3, 4])y = np.array([1, 4, 9, 16])plt.subplot(1, 2, 2)plt.plot(x,y)plt.title(&quot;plot 2&quot;)plt.suptitle(&quot;RUNOOB subplot Test&quot;)plt.show() 设置 numRows ＝ 2，numCols ＝ 2，就是将图表绘制成 2x2 的图片区域, 对应的坐标为： 12(1, 1), (1, 2)(2, 1), (2, 2) plotNum ＝ 1, 表示的坐标为(1, 1), 即第一行第一列的子图。 plotNum ＝ 2, 表示的坐标为(1, 2), 即第一行第二列的子图。 plotNum ＝ 3, 表示的坐标为(2, 1), 即第二行第一列的子图。 plotNum ＝ 4, 表示的坐标为(2, 2), 即第二行第二列的子图。 实例2： 12345678910111213141516171819202122232425262728293031323334353637import matplotlib.pyplot as pltimport numpy as np#plot 1:x = np.array([0, 6])y = np.array([0, 100])plt.subplot(2, 2, 1)plt.plot(x,y)plt.title(&quot;plot 1&quot;)#plot 2:x = np.array([1, 2, 3, 4])y = np.array([1, 4, 9, 16])plt.subplot(2, 2, 2)plt.plot(x,y)plt.title(&quot;plot 2&quot;)#plot 3:x = np.array([1, 2, 3, 4])y = np.array([3, 5, 7, 9])plt.subplot(2, 2, 3)plt.plot(x,y)plt.title(&quot;plot 3&quot;)#plot 4:x = np.array([1, 2, 3, 4])y = np.array([4, 5, 6, 7])plt.subplot(2, 2, 4)plt.plot(x,y)plt.title(&quot;plot 4&quot;)plt.suptitle(&quot;RUNOOB subplot Test&quot;)plt.show() subplots()subplots() 方法语法格式如下： 1matplotlib.pyplot.subplots(nrows=1, ncols=1, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **fig_kw) 参数说明： nrows：默认为 1，设置图表的行数。 ncols：默认为 1，设置图表的列数。 sharex、sharey：设置 x、y 轴是否共享属性，默认为 false，可设置为 ‘none’、’all’、’row’ 或 ‘col’。 False 或 none 每个子图的 x 轴或 y 轴都是独立的，True 或 ‘all’：所有子图共享 x 轴或 y 轴，’row’ 设置每个子图行共享一个 x 轴或 y 轴，’col’：设置每个子图列共享一个 x 轴或 y 轴。 squeeze：布尔值，默认为 True，表示额外的维度从返回的 Axes(轴)对象中挤出，对于 N1 或 1N 个子图，返回一个 1 维数组，对于 N*M，N&gt;1 和 M&gt;1 返回一个 2 维数组。如果设置为 False，则不进行挤压操作，返回一个元素为 Axes 实例的2维数组，即使它最终是1x1。 subplot_kw：可选，字典类型。把字典的关键字传递给 add_subplot() 来创建每个子图。 gridspec_kw：可选，字典类型。把字典的关键字传递给 GridSpec 构造函数创建子图放在网格里(grid)。 **fig_kw：把详细的关键字参数传给 figure() 函数。 实例3： 123456789101112131415161718192021222324252627282930313233343536373839import matplotlib.pyplot as pltimport numpy as np# 创建一些测试数据 -- 图1x = np.linspace(0, 2*np.pi, 400)y = np.sin(x**2)# 创建一个画像和子图 -- 图2fig, ax = plt.subplots()ax.plot(x, y)ax.set_title(&#x27;Simple plot&#x27;)# 创建两个子图 -- 图3f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)ax1.plot(x, y)ax1.set_title(&#x27;Sharing Y axis&#x27;)ax2.scatter(x, y)# 创建四个子图 -- 图4fig, axs = plt.subplots(2, 2, subplot_kw=dict(projection=&quot;polar&quot;))axs[0, 0].plot(x, y)axs[1, 1].scatter(x, y)# 共享 x 轴plt.subplots(2, 2, sharex=&#x27;col&#x27;)# 共享 y 轴plt.subplots(2, 2, sharey=&#x27;row&#x27;)# 共享 x 轴和 y 轴plt.subplots(2, 2, sharex=&#x27;all&#x27;, sharey=&#x27;all&#x27;)# 这个也是共享 x 轴和 y 轴plt.subplots(2, 2, sharex=True, sharey=True)# 创建10 张图，已经存在的则删除fig, ax = plt.subplots(num=10, clear=True)plt.show() Matplotlib散点图我们可以使用 pyplot 中的 scatter() 方法来绘制散点图。 scatter() 方法语法格式如下： 1matplotlib.pyplot.scatter(x, y, s=None, c=None, marker=None, cmap=None, norm=None, vmin=None, vmax=None, alpha=None, linewidths=None, *, edgecolors=None, plotnonfinite=False, data=None, **kwargs) 参数说明： x，y：长度相同的数组，也就是我们即将绘制散点图的数据点，输入数据。 s：点的大小，默认 20，也可以是个数组，数组每个参数为对应点的大小。 c：点的颜色，默认蓝色 ‘b’，也可以是个 RGB 或 RGBA 二维行数组。 marker：点的样式，默认小圆圈 ‘o’。 cmap：Colormap，默认 None，标量或者是一个 colormap 的名字，只有 c 是一个浮点数数组的时才使用。如果没有申明就是 image.cmap。 norm：Normalize，默认 None，数据亮度在 0-1 之间，只有 c 是一个浮点数的数组的时才使用。 vmin，vmax：：亮度设置，在 norm 参数存在时会忽略。 alpha：：透明度设置，0-1 之间，默认 None，即不透明。 linewidths：：标记点的长度。 edgecolors：：颜色或颜色序列，默认为 ‘face’，可选值有 ‘face’, ‘none’, None。 plotnonfinite：：布尔值，设置是否使用非限定的 c ( inf, -inf 或 nan) 绘制点。 **kwargs：：其他参数。 以下实例 scatter() 函数接收长度相同的数组参数，一个用于 x 轴的值，另一个用于 y 轴上的值： 实例1： 12345678import matplotlib.pyplot as pltimport numpy as npx = np.array([1, 2, 3, 4, 5, 6, 7, 8])y = np.array([1, 4, 9, 16, 7, 11, 23, 18])plt.scatter(x, y)plt.show() 实例2：设置图标大小 12345678import matplotlib.pyplot as pltimport numpy as npx = np.array([1, 2, 3, 4, 5, 6, 7, 8])y = np.array([1, 4, 9, 16, 7, 11, 23, 18])sizes = np.array([20,50,100,200,500,1000,60,90])plt.scatter(x, y, s=sizes)plt.show() 实例3：自定义点的颜色 123456789import matplotlib.pyplot as pltimport numpy as npx = np.array([1, 2, 3, 4, 5, 6, 7, 8])y = np.array([1, 4, 9, 16, 7, 11, 23, 18])colors = np.array([&quot;red&quot;,&quot;green&quot;,&quot;black&quot;,&quot;orange&quot;,&quot;purple&quot;,&quot;beige&quot;,&quot;cyan&quot;,&quot;magenta&quot;])plt.scatter(x, y, c=colors)plt.show() 实例4：设置两组散点图 123456789101112import matplotlib.pyplot as pltimport numpy as npx = np.array([5,7,8,7,2,17,2,9,4,11,12,9,6])y = np.array([99,86,87,88,111,86,103,87,94,78,77,85,86])plt.scatter(x, y, color = &#x27;hotpink&#x27;)x = np.array([2,2,8,1,15,8,12,9,7,3,11,4,7,14,12])y = np.array([100,105,84,105,90,99,90,95,94,100,79,112,91,80,85])plt.scatter(x, y, color = &#x27;#88c999&#x27;)plt.show() 实例5：使用随机数来设置散点图 123456789101112131415161718import numpy as npimport matplotlib.pyplot as plt# 随机数生成器的种子np.random.seed(19680801)N = 50x = np.random.rand(N)y = np.random.rand(N)colors = np.random.rand(N)area = (30 * np.random.rand(N))**2 # 0 to 15 point radiiplt.scatter(x, y, s=area, c=colors, alpha=0.5) # 设置颜色及透明度plt.title(&quot;RUNOOB Scatter Test&quot;) # 设置标题plt.show() 颜色条ColormapMatplotlib 模块提供了很多可用的颜色条。 颜色条就像一个颜色列表，其中每种颜色都有一个范围从 0 到 100 的值。 下面是一个颜色条的例子： 实例6：设置颜色条需要使用 cmap 参数，默认值为 ‘viridis’，之后颜色值设置为 0 到 100 的数组 12345678910import matplotlib.pyplot as pltimport numpy as npx = np.array([5,7,8,7,2,17,2,9,4,11,12,9,6])y = np.array([99,86,87,88,111,86,103,87,94,78,77,85,86])colors = np.array([0, 10, 20, 30, 40, 45, 50, 55, 60, 70, 80, 90, 100])plt.scatter(x, y, c=colors, cmap=&#x27;viridis&#x27;)plt.show() 实例7：如果要显示颜色条，需要使用 plt.colorbar() 方法 123456789101112import matplotlib.pyplot as pltimport numpy as npx = np.array([5,7,8,7,2,17,2,9,4,11,12,9,6])y = np.array([99,86,87,88,111,86,103,87,94,78,77,85,86])colors = np.array([0, 10, 20, 30, 40, 45, 50, 55, 60, 70, 80, 90, 100])plt.scatter(x, y, c=colors, cmap=&#x27;viridis&#x27;)plt.colorbar()plt.show() 实例8：换个颜色条参数， cmap 设置为 afmhot_r 12345678910import matplotlib.pyplot as pltimport numpy as npx = np.array([5,7,8,7,2,17,2,9,4,11,12,9,6])y = np.array([99,86,87,88,111,86,103,87,94,78,77,85,86])colors = np.array([0, 10, 20, 30, 40, 45, 50, 55, 60, 70, 80, 90, 100])plt.scatter(x, y, c=colors, cmap=&#x27;afmhot_r&#x27;)plt.colorbar()plt.show() 颜色条参数值可以是以下值： 颜色名称 保留关键字 Accent Accent_r Blues Blues_r BrBG BrBG_r BuGn BuGn_r BuPu BuPu_r CMRmap CMRmap_r Dark2 Dark2_r GnBu GnBu_r Greens Greens_r Greys Greys_r OrRd OrRd_r Oranges Oranges_r PRGn PRGn_r Paired Paired_r Pastel1 Pastel1_r Pastel2 Pastel2_r PiYG PiYG_r PuBu PuBu_r PuBuGn PuBuGn_r PuOr PuOr_r PuRd PuRd_r Purples Purples_r RdBu RdBu_r RdGy RdGy_r RdPu RdPu_r RdYlBu RdYlBu_r RdYlGn RdYlGn_r Reds Reds_r Set1 Set1_r Set2 Set2_r Set3 Set3_r Spectral Spectral_r Wistia Wistia_r YlGn YlGn_r YlGnBu YlGnBu_r YlOrBr YlOrBr_r YlOrRd YlOrRd_r afmhot afmhot_r autumn autumn_r binary binary_r bone bone_r brg brg_r bwr bwr_r cividis cividis_r cool cool_r coolwarm coolwarm_r copper copper_r cubehelix cubehelix_r flag flag_r gist_earth gist_earth_r gist_gray gist_gray_r gist_heat gist_heat_r gist_ncar gist_ncar_r gist_rainbow gist_rainbow_r gist_stern gist_stern_r gist_yarg gist_yarg_r gnuplot gnuplot_r gnuplot2 gnuplot2_r gray gray_r hot hot_r hsv hsv_r inferno inferno_r jet jet_r magma magma_r nipy_spectral nipy_spectral_r ocean ocean_r pink pink_r plasma plasma_r prism prism_r rainbow rainbow_r seismic seismic_r spring spring_r summer summer_r tab10 tab10_r tab20 tab20_r tab20b tab20b_r tab20c tab20c_r terrain terrain_r twilight twilight_r twilight_shifted twilight_shifted_r viridis viridis_r winter winter_r Matplotlib柱形图我们可以使用 pyplot 中的 bar() 方法来绘制柱形图。 bar() 方法语法格式如下： 1matplotlib.pyplot.bar(x, height, width=0.8, bottom=None, *, align=&#x27;center&#x27;, data=None, **kwargs) 参数说明： x：浮点型数组，柱形图的 x 轴数据。 height：浮点型数组，柱形图的高度。 width：浮点型数组，柱形图的宽度。 bottom：浮点型数组，底座的 y 坐标，默认 0。 align：柱形图与 x 坐标的对齐方式，’center’ 以 x 位置为中心，这是默认值。 ‘edge’：将柱形图的左边缘与 x 位置对齐。要对齐右边缘的条形，可以传递负数的宽度值及 align&#x3D;’edge’。 **kwargs：：其他参数。 实例1：简单实用 bar() 来创建一个柱形图 12345678import matplotlib.pyplot as pltimport numpy as npx = np.array([&quot;Runoob-1&quot;, &quot;Runoob-2&quot;, &quot;Runoob-3&quot;, &quot;C-RUNOOB&quot;])y = np.array([12, 22, 6, 18])plt.bar(x,y)plt.show() 实例2：垂直方向的柱形图可以使用 barh() 方法来设置 12345678import matplotlib.pyplot as pltimport numpy as npx = np.array([&quot;Runoob-1&quot;, &quot;Runoob-2&quot;, &quot;Runoob-3&quot;, &quot;C-RUNOOB&quot;])y = np.array([12, 22, 6, 18])plt.barh(x,y)plt.show() 实例3：设置柱形图颜色 12345678import matplotlib.pyplot as pltimport numpy as npx = np.array([&quot;Runoob-1&quot;, &quot;Runoob-2&quot;, &quot;Runoob-3&quot;, &quot;C-RUNOOB&quot;])y = np.array([12, 22, 6, 18])plt.bar(x, y, color = &quot;#4CAF50&quot;)plt.show() 实例4：自定义各个柱形的颜色 12345678import matplotlib.pyplot as pltimport numpy as npx = np.array([&quot;Runoob-1&quot;, &quot;Runoob-2&quot;, &quot;Runoob-3&quot;, &quot;C-RUNOOB&quot;])y = np.array([12, 22, 6, 18])plt.bar(x, y, color = [&quot;#4CAF50&quot;,&quot;red&quot;,&quot;hotpink&quot;,&quot;#556B2F&quot;])plt.show() 实例5：设置柱形图宽度，bar() 方法使用 width 设置 12345678import matplotlib.pyplot as pltimport numpy as npx = np.array([&quot;Runoob-1&quot;, &quot;Runoob-2&quot;, &quot;Runoob-3&quot;, &quot;C-RUNOOB&quot;])y = np.array([12, 22, 6, 18])plt.bar(x, y, width = 0.1)plt.show() 实例6：barh() 方法使用 height 设置 height 12345678import matplotlib.pyplot as pltimport numpy as npx = np.array([&quot;Runoob-1&quot;, &quot;Runoob-2&quot;, &quot;Runoob-3&quot;, &quot;C-RUNOOB&quot;])y = np.array([12, 22, 6, 18])plt.barh(x, y, height = 0.1)plt.show() Matplotlib饼图我们可以使用 pyplot 中的 pie() 方法来绘制饼图。 pie() 方法语法格式如下： 1matplotlib.pyplot.pie(x, explode=None, labels=None, colors=None, autopct=None, pctdistance=0.6, shadow=False, labeldistance=1.1, startangle=0, radius=1, counterclock=True, wedgeprops=None, textprops=None, center=0, 0, frame=False, rotatelabels=False, *, normalize=None, data=None)[source] 参数说明： x：浮点型数组，表示每个扇形的面积。 explode：数组，表示各个扇形之间的间隔，默认值为0。 labels：列表，各个扇形的标签，默认值为 None。 colors：数组，表示各个扇形的颜色，默认值为 None。 autopct：设置饼图内各个扇形百分比显示格式，**%d%%** 整数百分比，**%0.1f** 一位小数， %0.1f%% 一位小数百分比， %0.2f%% 两位小数百分比。 labeldistance：标签标记的绘制位置，相对于半径的比例，默认值为 1.1，如 &lt;1则绘制在饼图内侧。 pctdistance：：类似于 labeldistance，指定 autopct 的位置刻度，默认值为 0.6。 shadow：：布尔值 True 或 False，设置饼图的阴影，默认为 False，不设置阴影。 radius：：设置饼图的半径，默认为 1。 startangle：：起始绘制饼图的角度，默认为从 x 轴正方向逆时针画起，如设定 &#x3D;90 则从 y 轴正方向画起。 counterclock：布尔值，设置指针方向，默认为 True，即逆时针，False 为顺时针。 wedgeprops ：字典类型，默认值 None。参数字典传递给 wedge 对象用来画一个饼图。例如：wedgeprops&#x3D;{‘linewidth’:5} 设置 wedge 线宽为5。 textprops ：字典类型，默认值为：None。传递给 text 对象的字典参数，用于设置标签（labels）和比例文字的格式。 center ：浮点类型的列表，默认值：(0,0)。用于设置图标中心位置。 frame ：布尔类型，默认值：False。如果是 True，绘制带有表的轴框架。 rotatelabels ：布尔类型，默认为 False。如果为 True，旋转每个 label 到指定的角度。 实例1：简单实用 pie() 来创建一个柱形图 1234567import matplotlib.pyplot as pltimport numpy as npy = np.array([35, 25, 25, 15])plt.pie(y)plt.show() 实例2：设置饼图各个扇形的标签与颜色 1234567891011import matplotlib.pyplot as pltimport numpy as npy = np.array([35, 25, 25, 15])plt.pie(y, labels=[&#x27;A&#x27;,&#x27;B&#x27;,&#x27;C&#x27;,&#x27;D&#x27;], # 设置饼图标签 colors=[&quot;#d5695d&quot;, &quot;#5d8ca8&quot;, &quot;#65a479&quot;, &quot;#a564c9&quot;], # 设置饼图颜色 )plt.title(&quot;RUNOOB Pie Test&quot;) # 设置标题plt.show() 实例3：突出显示第二个扇形，并格式化输出百分比 12345678910111213import matplotlib.pyplot as pltimport numpy as npy = np.array([35, 25, 25, 15])plt.pie(y, labels=[&#x27;A&#x27;,&#x27;B&#x27;,&#x27;C&#x27;,&#x27;D&#x27;], # 设置饼图标签 colors=[&quot;#d5695d&quot;, &quot;#5d8ca8&quot;, &quot;#65a479&quot;, &quot;#a564c9&quot;], # 设置饼图颜色 explode=(0, 0.2, 0, 0), # 第二部分突出显示，值越大，距离中心越远 autopct=&#x27;%.2f%%&#x27;, # 格式化输出百分比 )plt.title(&quot;RUNOOB Pie Test&quot;)plt.show() 注意：默认情况下，第一个扇形的绘制是从 x 轴开始并逆时针移动：","categories":[],"tags":[]},{"title":"pip换源","slug":"pip换源","date":"2022-04-01T11:34:54.383Z","updated":"2022-04-01T11:57:04.204Z","comments":true,"path":"2022/04/01/en/pip换源/","link":"","permalink":"http://pistachio0812.github.io/2022/04/01/en/pip%E6%8D%A2%E6%BA%90/","excerpt":"","text":"由于使用pip或pip3安装python第三方包时，经常出现read timed out问题，所以需要将pip的官方软件源服务器换成国内的镜像服务器，从而提升python软件包安装效率和成功率，pip 国内的一些镜像： 阿里云 http://mirrors.aliyun.com/pypi/simple/ 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 豆瓣(douban) http://pypi.douban.com/simple/ 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ 中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/ 更换源临时使用可以在使用 pip 的时候在后面加上-i 参数，指定 pip 源 1eg: pip install scrapy -i https://pypi.tuna.tsinghua.edu.cn/simple 永久修改linux修改 ~&#x2F;.pip&#x2F;pip.conf (没有就创建一个文件夹及文件，文件夹要加“.”，表示是隐藏文件夹)， 内容如下： 1234[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple[install]trusted-host = https://pypi.tuna.tsinghua.edu.cn windows1.pip永久换源 1pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/ 在cmd命令行中输入上述命令即可。 最后，升级 pip 到最新的版本 1pip install pip -U 1python -m pip install --user --upgrade pip 2.直接在 user 目录中创建一个 pip 目录，如：C:\\Users\\xx\\pip，在 pip 目录下新建文件 pip.ini，即 %HOMEPATH%\\pip\\pip.ini，内容如下： 1234[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple[install]trusted-host = pypi.tuna.tsinghua.edu.cn 可以在开始运行里面输入三个点 ...，敲回车即可打开用户目录。","categories":[],"tags":[]},{"title":"详解注意力机制","slug":"注意力机制","date":"2022-03-31T07:14:05.585Z","updated":"2022-04-07T02:22:50.476Z","comments":true,"path":"2022/03/31/CN/注意力机制/","link":"","permalink":"http://pistachio0812.github.io/2022/03/31/CN/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/","excerpt":"","text":"注意力机制注意力机制就是让网络关注到它更需要关注的地方，是一种网络自适应注意的方式。注意力机制可以分为通道注意力，空间注意力以及二者的结合。 相关论文1.SENet 2017年提出的SENet是最后一届ImageNet竞赛的冠军，其实现示意图如下所示，对于输入进来的特征层，我们关注其每一个通道的权重，对于SENet而言，其重点是获得输入进来的特征层，每一个通道的权值。利用SENet，我们可以让网络关注它最需要关注的通道。 其具体实现方式就是：1、对输入进来的特征层进行全局平均池化。2、然后进行两次全连接，第一次全连接神经元个数较少，第二次全连接神经元个数和输入特征层相同。3、在完成两次全连接后，我们再取一次Sigmoid将值固定到0-1之间，此时我们获得了输入特征层每一个通道的权值（0-1之间）。4、在获得这个权值后，我们将这个权值乘上原输入特征层即可。 123456789101112131415161718192021import torchimport torch.nn as nnimport mathclass se_block(nn.Module): def __init__(self, channel, ratio=16): super(se_block, self).__init__() self.avg_pool = nn.AdaptiveAvgPool2d(1) self.fc = nn.Sequential( nn.Linear(channel, channel // ratio, bias=False), nn.ReLU(inplace=True), nn.Linear(channel // ratio, channel, bias=False), nn.Sigmoid() ) def forward(self, x): b, c, _, _ = x.size() y = self.avg_pool(x).view(b, c) y = self.fc(y).view(b, c, 1, 1) return x * y 2.CBAM CBAM将通道注意力机制和空间注意力机制进行一个结合，相比于SENet只关注通道的注意力机制可以取得更好的效果。其实现示意图如下所示，CBAM会对输入进来的特征层，分别进行通道注意力机制的处理和空间注意力机制的处理。 下图是通道注意力机制和空间注意力机制的具体实现方式：图像的上半部分为通道注意力机制，通道注意力机制的实现可以分为两个部分，我们会对输入进来的单个特征层，分别进行全局平均池化和全局最大池化。之后对平均池化和最大池化的结果，利用共享的全连接层进行处理，我们会对处理后的两个结果进行相加，然后取一个sigmoid，此时我们获得了输入特征层每一个通道的权值（0-1之间）。在获得这个权值后，我们将这个权值乘上原输入特征层即可。 图像的下半部分为空间注意力机制，我们会对输入进来的特征层，在每一个特征点的通道上取最大值和平均值。之后将这两个结果进行一个堆叠，利用一次通道数为1的卷积调整通道数，然后取一个sigmoid，此时我们获得了输入特征层每一个特征点的权值（0-1之间）。在获得这个权值后，我们将这个权值乘上原输入特征层即可。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class ChannelAttention(nn.Module): def __init__(self, in_planes, ratio=8): super(ChannelAttention, self).__init__() self.avg_pool = nn.AdaptiveAvgPool2d(1) self.max_pool = nn.AdaptiveMaxPool2d(1) # 利用1x1卷积代替全连接 self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False) self.relu1 = nn.ReLU() self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False) self.sigmoid = nn.Sigmoid() def forward(self, x): avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x)))) max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x)))) out = avg_out + max_out return self.sigmoid(out)class SpatialAttention(nn.Module): def __init__(self, kernel_size=7): super(SpatialAttention, self).__init__() assert kernel_size in (3, 7), &#x27;kernel size must be 3 or 7&#x27; padding = 3 if kernel_size == 7 else 1 self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False) self.sigmoid = nn.Sigmoid() def forward(self, x): avg_out = torch.mean(x, dim=1, keepdim=True) max_out, _ = torch.max(x, dim=1, keepdim=True) x = torch.cat([avg_out, max_out], dim=1) x = self.conv1(x) return self.sigmoid(x)class cbam_block(nn.Module): def __init__(self, channel, ratio=8, kernel_size=7): super(cbam_block, self).__init__() self.channelattention = ChannelAttention(channel, ratio=ratio) self.spatialattention = SpatialAttention(kernel_size=kernel_size) def forward(self, x): x = x * self.channelattention(x) x = x * self.spatialattention(x) return x 3.ECANet ECANet是也是通道注意力机制的一种实现形式。ECANet可以看作是SENet的改进版。ECANet的作者认为SENet对通道注意力机制的预测带来了副作用，捕获所有通道的依赖关系是低效并且是不必要的。在ECANet的论文中，作者认为卷积具有良好的跨通道信息获取能力。 ECA模块的思想是非常简单的，它去除了原来SE模块中的全连接层，直接在全局平均池化之后的特征上通过一个1D卷积进行学习。 既然使用到了1D卷积，那么1D卷积的卷积核大小的选择就变得非常重要了，了解过卷积原理的同学很快就可以明白，1D卷积的卷积核大小会影响注意力机制每个权重的计算要考虑的通道数量。用更专业的名词就是跨通道交互的覆盖率。 如下图所示，左图是常规的SE模块，右图是ECA模块。ECA模块用1D卷积替换两次全连接。 12345678910111213141516class eca_block(nn.Module): def __init__(self, channel, b=1, gamma=2): super(eca_block, self).__init__() kernel_size = int(abs((math.log(channel, 2) + b) / gamma)) kernel_size = kernel_size if kernel_size % 2 else kernel_size + 1 self.avg_pool = nn.AdaptiveAvgPool2d(1) self.conv = nn.Conv1d(1, 1, kernel_size=kernel_size, padding=(kernel_size - 1) // 2, bias=False) self.sigmoid = nn.Sigmoid() def forward(self, x): y = self.avg_pool(x) y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1) y = self.sigmoid(y) return x * y.expand_as(x) 注意力机制的应用注意力机制是一个即插即用的模块，理论上可以放在任何一个特征层后面，可以放在主干网络，也可以放在加强特征提取网络。 由于放置在主干会导致网络的预训练权重无法使用，本文以YoloV4-tiny为例，将注意力机制应用加强特征提取网络上。 如下图所示，我们在主干网络提取出来的两个有效特征层上增加了注意力机制，同时对上采样后的结果增加了注意力机制。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253attention_block = [se_block, cbam_block, eca_block]#---------------------------------------------------## 特征层-&gt;最后的输出#---------------------------------------------------#class YoloBody(nn.Module): def __init__(self, anchors_mask, num_classes, phi=0): super(YoloBody, self).__init__() self.phi = phi self.backbone = darknet53_tiny(None) self.conv_for_P5 = BasicConv(512,256,1) self.yolo_headP5 = yolo_head([512, len(anchors_mask[0]) * (5 + num_classes)],256) self.upsample = Upsample(256,128) self.yolo_headP4 = yolo_head([256, len(anchors_mask[1]) * (5 + num_classes)],384) if 1 &lt;= self.phi and self.phi &lt;= 3: self.feat1_att = attention_block[self.phi - 1](256) self.feat2_att = attention_block[self.phi - 1](512) self.upsample_att = attention_block[self.phi - 1](128) def forward(self, x): #---------------------------------------------------# # 生成CSPdarknet53_tiny的主干模型 # feat1的shape为26,26,256 # feat2的shape为13,13,512 #---------------------------------------------------# feat1, feat2 = self.backbone(x) if 1 &lt;= self.phi and self.phi &lt;= 3: feat1 = self.feat1_att(feat1) feat2 = self.feat2_att(feat2) # 13,13,512 -&gt; 13,13,256 P5 = self.conv_for_P5(feat2) # 13,13,256 -&gt; 13,13,512 -&gt; 13,13,255 out0 = self.yolo_headP5(P5) # 13,13,256 -&gt; 13,13,128 -&gt; 26,26,128 P5_Upsample = self.upsample(P5) # 26,26,256 + 26,26,128 -&gt; 26,26,384 if 1 &lt;= self.phi and self.phi &lt;= 3: P5_Upsample = self.upsample_att(P5_Upsample) P4 = torch.cat([P5_Upsample,feat1],axis=1) # 26,26,384 -&gt; 26,26,256 -&gt; 26,26,255 out1 = self.yolo_headP4(P4) return out0, out1# 研究方向为CV的可以关注Bubbliiiing,也可以顺道关注一下博主心系五道口，谢谢！！！————————————————版权声明：本文为CSDN博主「Bubbliiiing」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/weixin_44791964/article/details/121371986","categories":[{"name":"CV","slug":"CV","permalink":"http://pistachio0812.github.io/categories/CV/"}],"tags":[{"name":"Attention","slug":"Attention","permalink":"http://pistachio0812.github.io/tags/Attention/"}]},{"title":"MySQL学习笔记","slug":"MySQL学习笔记","date":"2022-03-26T11:07:11.619Z","updated":"2022-04-07T00:32:13.014Z","comments":true,"path":"2022/03/26/CN/MySQL学习笔记/","link":"","permalink":"http://pistachio0812.github.io/2022/03/26/CN/MySQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"MySQL入门教程什么是数据库数据库是按照数据结构来组织、存储和管理数据的仓库 关系型数据库：建立在关系模型基础上的数据库，借助于集合代数等数学概念和方法来处理数据库中的数据 RDBMS即关系数据库管理系统的特点： 1.数据以表格的形式出现 2.每行为各种记录名称 3.每列为记录名称所对应的数据域 4.许多行和列组成一张表单 5.若干的表单组成数据库 RDBMS相关概念· MySQL创建数据表语法CREATE TABLE table_name (column_name column_type) 举例：在W3CSCHOOL数据库中创建数据表w3cschool_tbl: 1234567CREATE TABLE IF NOT EXISTS tutorials_tbl( tutorial_id INT NOT NULL AUTO_INCREMENT, tutorial_title VARCHAR(100) NOT NULL, tutorial_author VARCHAR(40) NOT NULL, submission_date DATE, PRIMARY KEY (tutorial_id) ); 注： ·如果你不想字段为NULL可以设置字段的属性为NOT NULL,在操作数据库如果输入该字段的数据为NULL,则会报错。 ·AUTO_INCREMENT定义列为自增的属性，一般用于主键，数值会自动加1。 ·PRIMARY KEY关键字用于定义列为主键。你可以使用多列来定义主键，列间以逗号分隔。 MySQL删除数据表语法DROP TABLE table_name MySQL插入数据语法123INSERT INTO table_name(field1, field2, ...fieldN) VALUES (value1, value2, ...valueN); 举例：使用SQL INSERT INTO语句向MySQL数据表w3cschool_tbl插入数据： 1234INSERT INTO w3cschool_tbl(w3cschool_title, w3cschool_author, submission_date)VALUES(&quot;Learn PHP&quot;, &quot;John Poul&quot;, NOW()); MySQL查询数据语法1234SELECT column_name, column_nameFROM table_name[WHERE Clause][OFFSET M][LIMIT N] 注： ·查询语句中你可以使用一个或者多个表，表之间使用逗号(,)分隔，并使用WHERE语句来设定查询条件。 ·SELECT命令可以读取一条或者多条记录。 ·你可以使用星号(*)来代替其他字段，SELECT语句会返回表的所有字段数据。 ·你可以使用WHERE语句来包含任何条件。 ·你可以通过OFFSET指定SELECT语句开始查询的数据偏移量，默认偏移量为0。 ·你可以使用LIMIT属性来设定返回的记录数。 举例：通过SQL SELECT命令来获取MySQL数据表w3cschool_tbl的数据： SELECT * from w3cschool_tbl; MySQL where子句语法123SELECT field1, field2, ...fieldNFROM table_name1, table_name2...[WHERE condition1 [[AND][OR]] condition2...] 注： ·查询语句中你可以使用一个或者多个表，表之间使用逗号(,)分隔，并使用WHERE语句来设定查询条件。 ·你可以在WHERE子句中指定任何条件。 ·你可以使用AND或者OR指定一个或多个条件。 ·WHERE子句也可以运用于SQL的DELETE或UPDATE命令。 ·WHERE子句类似于程序中的if条件，根据MySQL表中的字段值来读取指定的数据。 操作符列表，实例假定A&#x3D;10,B&#x3D;20: 操作符 描述 实例 &#x3D; 等号，检测两个值是否相等，如果相等返回True (A&#x3D;B)返回false &lt;&gt;或！&#x3D; 不等于，检测两个值是否相等，如果不相等返回True （A!&#x3D;B)返归true &gt; 大于号，检测左边的值是否大于右边的值，如果左边的值大于右边的值返回True (A&gt;B)返回false &lt; 小于号，检测左边的值是否小于右边的值，如果左边的值小于右边的值返回True (A&lt;B)返回true &gt;&#x3D; 大于等于号，检测左边的值是否大于等于右边的值，如果左边的值大于或等于右边的值返回True (A&gt;&#x3D;B)返回false &lt;&#x3D; 小于等于号，检测左边的值是否小于或等于右边的值，如果左边的值小于或等于右边的值返回True (A&lt;&#x3D;B)返回true 举例：读取w3cschool_tbl表中w3cschool_author字段值为Sanjay的所有记录： SELECT * from w3cschool_tbl WHERE w3cschool_author=&#39;Sanjay&#39;; 除非你使用LIKE来比较字符串，否则MySQL的WHERE子句的字符串比较是不区分大小写的。你可以使用BINARY关键字来设定WHERE子句的紫福春是区分大小写的。 SELECT * from w3cschool_tbl WHERE BINARY w3cschool_author=&#39;sanjay&#39;; MySQL UPDATE查询语法123UPDATE table_name SET field1=new-value1, field2=new-value2[WHERE Clause] 注： ·你可以同时更新一个或多个字段 ·你可以在WHERE字句中指定任何条件 ·你可以在一个单独表中同时更新数据 当你需要更新表中指定行的数据时，WHERE子句是非常有用的。 举例：更新数据表中w3cschool_id为3的w3cschool_title字段值： 123UPDATE w3cschool_tblSET w3cschool_title=&#x27;Learning JAVA&#x27;WHERE w3cschool_id=3; MySQL DELETE语句语法DELETE FROM table_name [WHERE Clause] 注： ·如果没有指定WHERE子句，MySQL表中的所有记录将被删除 ·你可以在WHERE字句中指定任何条件 ·你可以在单个表中一次性删除记录 当你想删除数据表中的指定记录时，WHERE子句是非常有用的 举例：删除w3cschool_tbl表中w3cschool_id为3的记录： 1DELETE FROM w3cschool_tbl WHERE w3cschool_id=3; MySQL LIKE子句SQL LIKE子句中使用百分号（%）字符来表示任意字符，类似于UNIX或者正则表达式中的星号（*）。 语法123SELECT field1, field2, ...fieldNFROM table_name1, table_name2...WHERE field1 LIKE condition [[AND][OR]] field2=&#x27;somevalue&#x27; 注： ·你可以在WHERE子句中指定任何条件 ·你可以在WHERE字句中使用LIKE子句 ·你可以使用LIKE子句代替等号 ·LIKE通常与%一同使用，类似于一个元字符的搜索 ·你可以使用AND或OR指定一个或多个条件 ·你可以在DELETE或UPDATE命令中使用WHERE…LIKE子句来指定条件 举例：查询w3cschool_tbl表中的w3cschool_author字段中以’jay’为结尾的所有记录： 12SELECT * from w3cschool_tblWHERE w3cschool_author LIKE &#x27;%jay&#x27;; MySQL排序语法12SELECT field1, field2,...fieldN FROM table_name1, table_name2...ORDER BY field1, [field2...] [ASC[DESC]] 注： ·你可以使用任何字段来作为排序的条件，从而返回排序后的查询结果 ·你可以设定多个字段来排序 ·你可以使用ASC或DESC关键字来设置查询结果是按升序或者降序排列。默认情况下，它是按升序排列 ·你可以添加WHERE…LIKE子句来设置条件 举例：使用ORDER BY子句来读取MySQL数据表w3cschool_tbl中的数据： SELECT * from w3cschool_tbl ORDER BY w3cschool_author ASC; SELECT * from w3cschool_tbl ORDER BY w3cschool_author DESC; MySQL 分组GROUP BY语句根据一个或者多个列对结果集进行分组，在分组的列上我们可以使用COUNT,SUM,AVG等函数。 语法1234SELECT column_name, function(column_name)FROM table_nameWHERE column_name operator valueGROUP BY column_name; employee_tbl表格信息如下： id name date singin 1 小明 2016-04-22 15:25:33 1 2 小王 2016-04-20 15:25:47 3 3 小丽 2016-04-19 15:26:02 2 4 小王 2016-04-07 15:26:14 4 5 小明 2016-04-11 15:26:40 4 6 小明 2016-04-04 15:26:54 2 举例：将数据表按名字进行分组，并统计每个人有多少条记录： SELECT name, COUNT(*) FROM employ_tbl GROUP BY name; 使用WITH ROLLUPWITH ROLLUP可以实现在分组统计数据基础上再进行相同的统计（SUM.AVG,COUNT). 举例：将以上的数据表按名字进行分组，再统计每个人登录的次数： 123SELECT name, SUM(singin) as singin_countFROM employee_tblGROUP BY name WITH ROLLUP; 其中结果如下： name singin_out 小丽 2 小明 7 小王 7 NULL 16 其中记录NULL表示所有人的登录次数，我们可以使用coalesce来设置一个可以取代NULL的名称。 语法select coalesce(a, b, c); 参数说明：如果a&#x3D;&#x3D;null,则选择b;如果b&#x3D;&#x3D;null,则选择c;如果a!&#x3D;null,则选择a;如果abc都为null,则返回null(没意义)。 举例：如果名字为空，使用总数代替： 123SELECT coalesce(name, &#x27;总数&#x27;), SUM(singin) as singin_outFROM employee_tblGROUP BY name WITH ROLLUP; MySQL连接的使用JOIN按照功能大致分为如下三类： ·INNER JOIN(内连接，或等值连接)：获取两个表中字段匹配关系的记录 ·LEFT JOIN（左连接）：获取左表所有记录，即使右表没有对应匹配的记录 ·RIGHT JOIN(右连接)：用于获取右表所有记录，即使左表没有对应匹配的记录 SQL JOINS 假设W3CSCHOOL数据库中有两张表tcount_tbl和w3cschool_tbl,两张数据表数据如下： 1.tcount_tbl w3cschool_author w3cschool_count mahran 20 mahnaz NULL Jen NULL Gill 20 John Poul 1 Sanjay 1 2.w3cschool_tbl w3cschool_id w3cschool_title w3cschool_author submission_date 1 Learn PHP John Poul 2007-05-24 2 Learn MyQL Abdul S 2007-05-24 3 JAVA Tutorial Sanjay 2007-05-06 举例：使用INNER JOIN来连接以上两张表来读取w3cschool_tbl表中所有w3cschool_author字段在tcount_tbl表中对应的w3cschool_count字段值。 123SELECT a.w3cschool_id, a.w3cschool_author, b.w3cschool_countFROM w3cschool_tbl a INNER JOIN tcount_tbl bON a.w3cschool_author = b.w3cschool_author 等价于： 123SELECT a.w3cschool_id, a_w3cschool_author, b.w3cschool_countFROM w3cschool_tbl a, tcount_tbl bWHERE a.w3cschool_author = b.w3cschool_author; 举例：以w3cschool_tbl为左表， t_count_tbl为右表，理解MySQL LEFT JOIN的应用： 123SELECT a.w3cschool_id, a.w3cschool_author, b.w3cschool_countFROM w3cschool_tbl a LEFT JOIN tcount_tbl bON a.w3cschool_author = b.w3cschool_author; 举例：以tcount_tbl为左表， w3cschool_tbl为右表，理解MySQL RIGHT JOIN的应用： 123SELECT b.w3cschool_id, b.w3cschool_author, a.w3cschool_countFROM tcount_tbl a RIGHT JOIN w3cschool_tbl bON a.w3cschool_author = b.w3cschool_author; MySQL NULL值处理查询条件字段为NULL时，该命令可能无法正常工作，为了处理这种情况，MySQL提供了三大运算符： ·IS NULL:当列的值为NULL,此运算符返回True ·IS NOT NULL:当列的值不为NULL,运算符返回True ·&lt;&#x3D;&gt;:比较运算符，当比较的两个值为NULL时返回True 关于NULL的条件比较运算是比较特殊的，你不能够使用&#x3D;NULL或！&#x3D;NULL在列中查找NULL值，在MySQL中，NULL值与任何其他值的比较永远返回false,即NULL&#x3D;NULL返回false。 在命令提示符中使用NULL值假设数据库W3CSCHOOL中的表tcount_tbl含有两列w3cschool_author和w3cschool_count, w3cschool_count中设置插入NULL值。 假设表如下所示： w3cschool_author w3cschool_count mahran 20 mahnaz NULL Jen NULL Gill 20 查询数据表中w3cschool_count列是否为NULL,必须使用IS NULL和IS NOT NULL,如下实例： 12SELECT * FROM tcount_tblWHERE w3cschool_count IS NULL; 12SELECT * FROM tcount_tblWHERE w3cschool_count IS NOT NULL; MySQL正则表达式下表中的正则模式可应用于REGEXP操作符中。 ^ 匹配输入字符串的开始位置。如果设置了RegExp对象的Multiline属性，^也匹配’\\n’或’\\r’之后的位置。 $ 匹配输入字符串的结束位置。如果设置了RegExp对象的Multiline属性，^也匹配’\\n’或’\\r’之前的位置。 . 匹配除’\\n’之外的任何单个字符。要匹配包括’\\n’在内的任何字符，请使用’[.\\n]’的模式。 […] 字符集合。匹配所包含的任何一个字符。例如’[abc]’可以匹配’plain’中的’a’。 [^…] 负值字符集合。匹配未包含的任意字符。例如，’[^abc]’可以匹配’plain’中的’p’。 p1|p2|p3 匹配p1或p2或p3.例如，’z|food’能匹配’z’或’food’。，’(z|f)food’能匹配’zood’或’food’ * 匹配前面的子表达式零次或多次。例如，zo能匹配’z’以及’zoo’.*等价于{0，}。 + 匹配前面的子表达式一次或多次。例如，’zo+’能匹配’zo’以及’zoo’,但不能匹配’z’。+等价于{1，} {n} n是一个非负整数。匹配确定的n次。例如，’o{2}’不能匹配’Bob’中的’o’,但是能匹配’food’中的两个o。 {n, m} m和n均为非负整数，其中n&lt;&#x3D;m。最少匹配n次且最多匹配m次。 举例： 1.查找name字段中以’st’为开头的所有数据： 1SELECT name FROM person_tbl WHERE name REGEXP &#x27;^st&#x27;; 2.查找name字段中以’ok’为结尾的所有数据： 1SELECT name FROM person_tbl WHERE name REGEXP &#x27;ok$&#x27;; 3.查找name字段中包含’mar’字符串的所有数据： 1SELECT name FROM person_tbl WHERE name REGEXP &#x27;mar&#x27; 4.查找name字段中以元音字符开头或以’ok’字符串结尾的所有数据： 1SELECT name FROM person_tbl WHERE name REGEXP &#x27;^[aeiou]|ok$&#x27; MySQL事务MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你即需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！ 在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。 事务处理可以用来维护数据库的完整性，保证成批的SQL语句要么全部执行，要么全部不执行。 事务用来管理 insert , update , delete 语句。 一般来说，事务是必须满足4个条件（ACID）： Atomicity（原子性或不可分割性）、Consistency（一致性）、Isolation（隔离性或独立性）、Durability（持久性） 1、原子性：一组事务，要么成功；要么撤回，即事务在执行过程中出错会回滚到事务开始前的状态。 2、一致性 ： 一个事务不论是开始前还是结束后，数据库的完整性都没有被破坏。因此写入的数据必须完全符合所有预设规则（资料精确度、串联性以及后续数据库能够自发完成预定工作）。 3、隔离性：数据库允许多个事务并发的同时对其数据进行读写修改等操作，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离可分为：Read uncommitted（读未提交）、Read committed（读提交）、Repeatable read（可重复读）、Serializable（串行化）。 4、持久性：事务在处理结束后对数据做出的修改是永久的，无法丢失 事务控制语句1.显式的开始一个事务： start transaction或者begin 2.做保存点，一个事务中可以有多个保存点： savepoint [savepoint_name] 3.提交事务，并使数据库中进行的修改成为永久性的： commit或commit work 4.回滚结束用户的事务，并撤销正在进行的所有未提交的修改： rollback或rollback work 5.删除一个事务的保存点，若没有指定保存点，执行该语句操作则会抛错： release savepoint [savepoint_name] 6.将事务滚回标记点： rollback to 标记点 7.设置事务的隔离级别。InnoDB 存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ 和 SERIALIZABLE。 1set transaction 事务处理方法1.用 begin ， rollback ， commit 来实现事务处理。 2.用 set 来改变 MySQL 的自动提交模式。 set autocommit &#x3D; 0 （禁止自动提交）。 set autocommit &#x3D; 1 （开启自动提交）。 MySQL ALTER命令当我们需要修改数据表名或者修改数据表字段时，就需要使用到MySQL ALTER命令。 开始本章教程前让我们先创建一张表，表名为：testalter_tbl。 12345create table testalter_tbl( i INT, c CHAR(1) ); SHOW COLUMNS FROM testalter_tbl; Field Type Null Key Default Extra i int(11) YES NULL c char(1) YES NULL 删除、添加或修改表字段如下命令使用了 ALTER 命令及 DROP 子句来删除以上创建表的 i 字段： mysql&gt; ALTER TABLE testalter_tbl DROP i; 如果数据表中只剩余一个字段则无法使用DROP来删除字段。 MySQL 中使用 ADD 子句来想数据表中添加列，如下实例在表 testalter_tbl 中添加 i 字段，并定义数据类型: mysql&gt; ALTER TABLE testalter_tbl ADD i INT; 执行以上命令后，i 字段会自动添加到数据表字段的末尾。 &#96;mysql&gt; SHOW COLUMNS FROM testalter_tbl; +-------+---------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+---------+------+-----+---------+-------+ | c | char(1) | YES | | NULL | | | i | int(11) | YES | | NULL | | +-------+---------+------+-----+---------+-------+ 2 rows in set (0.00 sec) 如果你需要指定新增字段的位置，可以使用MySQL提供的关键字 FIRST (设定位第一列)， AFTER 字段名（设定位于某个字段之后）。 尝试以下 ALTER TABLE 语句, 在执行成功后，使用 SHOW COLUMNS 查看表结构的变化： ALTER TABLE testalter_tbl DROP i; ALTER TABLE testalter_tbl ADD i INT FIRST; ALTER TABLE testalter_tbl DROP i; ALTER TABLE testalter_tbl ADD i INT AFTER c; FIRST 和 AFTER 关键字只占用于 ADD 子句，所以如果你想重置数据表字段的位置就需要先使用 DROP 删除字段然后使用 ADD 来添加字段并设置位置。 修改字段类型及名称如果需要修改字段类型及名称, 你可以在ALTER命令中使用 MODIFY 或 CHANGE 子句 。 例如，把字段 c 的类型从 CHAR(1) 改为 CHAR(10)，可以执行以下命令: mysql&gt; ALTER TABLE testalter_tbl MODIFY c CHAR(10); 使用 CHANGE 子句, 语法有很大的不同。 在 CHANGE 关键字之后，紧跟着的是你要修改的字段名，然后指定新字段的类型及名称。尝试如下实例： mysql&gt; ALTER TABLE testalter_tbl CHANGE i j BIGINT; 如果你现在想把字段 j 从 BIGINT 修改为 INT，SQL语句如下： mysql&gt; ALTER TABLE testalter_tbl CHANGE j j INT; ALTER TABLE 对 Null 值和默认值的影响当你修改字段时，你可以指定是否包含只或者是否设置默认值。以下实例，指定字段 j 为 NOT NULL 且默认值为100 。 mysql&gt; ALTER TABLE testalter_tbl ​ -&gt; MODIFY j BIGINT NOT NULL DEFAULT 100; 如果你不设置默认值，MySQL会自动设置该字段默认为 NULL。 修改字段默认值你可以使用 ALTER 来修改字段的默认值，尝试以下实例： mysql&gt; ALTER TABLE testalter_tbl ALTER i SET DEFAULT 1000; mysql&gt; SHOW COLUMNS FROM testalter_tbl; +-------+---------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+---------+------+-----+---------+-------+ | c | char(1) | YES | | NULL | | | i | int(11) | YES | | 1000 | | +-------+---------+------+-----+---------+-------+ 2 rows in set (0.00 sec) 你也可以使用 ALTER 命令及 DROP子句来删除字段的默认值，如下实例： mysql&gt; ALTER TABLE testalter_tbl ALTER i DROP DEFAULT; mysql&gt; SHOW COLUMNS FROM testalter_tbl; +-------+---------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+---------+------+-----+---------+-------+ | c | char(1) | YES | | NULL | | | i | int(11) | YES | | NULL | | +-------+---------+------+-----+---------+-------+ 2 rows in set (0.00 sec) Changing a Table Type: 修改数据表类型，可以使用 ALTER 命令及 TYPE 子句来完成。尝试以下实例，我们将表 testalter_tbl 的类型修改为 MYISAM ：注意：查看数据表类型可以使用 SHOW TABLE STATUS 语句。* 12345678910111213141516171819mysql&gt; ALTER TABLE testalter_tbl TYPE = MYISAM;mysql&gt; SHOW TABLE STATUS LIKE &#x27;testalter_tbl&#x27;\\G 1. row ** Name: testalter_tbl Type: MyISAM Row_format: Fixed Rows: 0 Avg_row_length: 0 Data_length: 0Max_data_length: 25769803775 Index_length: 1024 Data_free: 0 Auto_increment: NULL Create_time: 2007-06-03 08:04:36 Update_time: 2007-06-03 08:04:36 Check_time: NULL Create_options: Comment:1 row in set (0.00 sec) 修改表名如果需要修改数据表的名称，可以在 ALTER TABLE 语句中使用 RENAME 子句来实现。 尝试以下实例将数据表 testalter_tbl 重命名为 alter_tbl： 1mysql&gt; ALTER TABLE testalter_tbl RENAME TO alter_tbl; MySQL索引MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。 打个比方，如果合理的设计且使用索引的MySQL是一辆兰博基尼的话，那么没有设计和使用索引的MySQL就是一个人力三轮车。 拿汉语字典的目录页（索引）打比方，我们可以按拼音、笔画、偏旁部首等排序的目录（索引）快速查找到需要的字。 索引分单列索引和组合索引。单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。组合索引，即一个索引包含多个列。 创建索引时，你需要确保该索引是应用在 SQL 查询语句的条件(一般作为 WHERE 子句的条件)。 实际上，索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录。 上面都在说使用索引的好处，但过多的使用索引将会造成滥用。因此索引也会有它的缺点：虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。 建立索引会占用磁盘空间的索引文件。 普通索引创建索引 这是最基本的索引，它没有任何限制。它有以下几种创建方式： 1CREATE INDEX indexName ON mytable(username(length)); 如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length。 修改表结构(添加索引) 1ALTER table tableName ADD INDEX indexName(columnName) 创建表的时候直接指定 123456789CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, INDEX [indexName] (username(length)) ); 删除索引的语法 1DROP INDEX [indexName] ON mytable; 唯一索引它与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。它有以下几种创建方式： 创建索引 1CREATE UNIQUE INDEX indexName ON mytable(username(length)) 修改表结构 1ALTER table mytable ADD UNIQUE [indexName] (username(length)) 创建表的时候直接指定 123456789CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, UNIQUE [indexName] (username(length)) ); 使用ALTER 命令添加和删除索引 有四种方式来添加数据表的索引： ALTER TABLE tbl_name ADD PRIMARY KEY (column_list): 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。 ALTER TABLE tbl_name ADD UNIQUE index_name (column_list): 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。 ALTER TABLE tbl_name ADD INDEX index_name (column_list): 添加普通索引，索引值可出现多次。 ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list):该语句指定了索引为 FULLTEXT ，用于全文索引。 以下实例为在表中添加索引。 1mysql&gt; ALTER TABLE testalter_tbl ADD INDEX (c); 你还可以在 ALTER 命令中使用 DROP 子句来删除索引。尝试以下实例删除索引: 1mysql&gt; ALTER TABLE testalter_tbl DROP INDEX c; 使用 ALTER 命令添加和删除主键 主键只能作用于一个列上，添加主键索引时，你需要确保该主键默认不为空（NOT NULL）。实例如下： 12mysql&gt; ALTER TABLE testalter_tbl MODIFY i INT NOT NULL;mysql&gt; ALTER TABLE testalter_tbl ADD PRIMARY KEY (i); 你也可以使用 ALTER 命令删除主键： 1mysql&gt; ALTER TABLE testalter_tbl DROP PRIMARY KEY; 删除主键时只需指定PRIMARY KEY，但在删除索引时，你必须知道索引名。 显示索引信息 你可以使用 SHOW INDEX 命令来列出表中的相关的索引信息。可以通过添加 \\G 来格式化输出信息。 尝试以下实例: 12mysql&gt; SHOW INDEX FROM table_name; \\G........ MySQL临时表MySQL 临时表在我们需要保存一些临时数据时是非常有用的。临时表只在当前连接可见，当关闭连接时，MySQL会自动删除表并释放所有空间。 临时表在MySQL 3.23版本中添加，如果你的MySQL版本低于 3.23版本就无法使用MySQL的临时表。不过现在一般很少有再使用这么低版本的MySQL数据库服务了。 MySQL临时表只在当前连接可见，如果你使用PHP脚本来创建MySQL临时表，那每当PHP脚本执行完成后，该临时表也会自动销毁。 如果你使用了其他MySQL客户端程序连接MySQL数据库服务器来创建临时表，那么只有在关闭客户端程序时才会销毁临时表，当然你也可以手动销毁。 实例 以下展示了使用MySQL 临时表的简单实例，以下的SQL代码可以适用于PHP脚本的mysql_query()函数。 1234567891011121314151617181920mysql&gt; CREATE TEMPORARY TABLE SalesSummary ( -&gt; product_name VARCHAR(50) NOT NULL -&gt; , total_sales DECIMAL(12,2) NOT NULL DEFAULT 0.00 -&gt; , avg_unit_price DECIMAL(7,2) NOT NULL DEFAULT 0.00 -&gt; , total_units_sold INT UNSIGNED NOT NULL DEFAULT 0);Query OK, 0 rows affected (0.00 sec)mysql&gt; INSERT INTO SalesSummary -&gt; (product_name, total_sales, avg_unit_price, total_units_sold) -&gt; VALUES -&gt; (&#x27;cucumber&#x27;, 100.25, 90, 2);mysql&gt; SELECT * FROM SalesSummary;+--------------+-------------+----------------+------------------+| product_name | total_sales | avg_unit_price | total_units_sold |+--------------+-------------+----------------+------------------+| cucumber | 100.25 | 90.00 | 2 |+--------------+-------------+----------------+------------------+1 row in set (0.00 sec) 当你使用 SHOW TABLES命令显示数据表列表时，你将无法看到 SalesSummary表。 如果你退出当前MySQL会话，再使用 SELECT命令来读取原先创建的临时表数据，那你会发现数据库中没有该表的存在，因为在你退出时该临时表已经被销毁了。 删除MySQL 临时表 默认情况下，当你断开与数据库的连接后，临时表就会自动被销毁。当然你也可以在当前MySQL会话使用 DROP TABLE 命令来手动删除临时表。 以下是手动删除临时表的实例： 1234567891011121314151617181920212223mysql&gt; CREATE TEMPORARY TABLE SalesSummary ( -&gt; product_name VARCHAR(50) NOT NULL -&gt; , total_sales DECIMAL(12,2) NOT NULL DEFAULT 0.00 -&gt; , avg_unit_price DECIMAL(7,2) NOT NULL DEFAULT 0.00 -&gt; , total_units_sold INT UNSIGNED NOT NULL DEFAULT 0);Query OK, 0 rows affected (0.00 sec)mysql&gt; INSERT INTO SalesSummary -&gt; (product_name, total_sales, avg_unit_price, total_units_sold) -&gt; VALUES -&gt; (&#x27;cucumber&#x27;, 100.25, 90, 2);mysql&gt; SELECT * FROM SalesSummary;+--------------+-------------+----------------+------------------+| product_name | total_sales | avg_unit_price | total_units_sold |+--------------+-------------+----------------+------------------+| cucumber | 100.25 | 90.00 | 2 |+--------------+-------------+----------------+------------------+1 row in set (0.00 sec)mysql&gt; DROP TABLE SalesSummary;mysql&gt; SELECT * FROM SalesSummary;ERROR 1146: Table &#x27;W3CSCHOOL.SalesSummary&#x27; doesn&#x27;t exist","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://pistachio0812.github.io/categories/MySQL/"}],"tags":[{"name":"Note","slug":"Note","permalink":"http://pistachio0812.github.io/tags/Note/"}]},{"title":"pytorch官方文档中文版","slug":"pytorch官方文档","date":"2022-03-25T13:26:45.398Z","updated":"2022-03-25T15:20:56.859Z","comments":true,"path":"2022/03/25/en/pytorch官方文档/","link":"","permalink":"http://pistachio0812.github.io/2022/03/25/en/pytorch%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3/","excerpt":"","text":"torch.nnContainerModuleCLASS torch.nn.Module SOURCE 它是所有神经网络模型的基类，你的模块应该继承于该类。 模块还能包含其他模块，允许把它们嵌套在一个树结构中。你可以分配子模块作为常规属性： 123456789101112import torch.nn as nnimport torch.nn.functional as Fclass Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x)) return F.relu(self.conv2(x)) 用这种方式分配的模块将会显示，并且当你调用to( )等等方法，它们的参数也将被转换。 注： 正如上面的例子一样，一个__init__()调用父类必须在子类赋值之前完成。 变量 training(bool)-布尔值代表这个模块是训练模式还是评估模式 add_module(name, module) SOURCE ​ 添加一个子模块到当前模块 ​ 这个模块可以用给定的名称作为属性访问模块 ​ 参数： ​ ·name(string)-子模块的名字，这个子模块可以用给定的名称作为属性访问。 ​ ·module(Module)-子模块添加到模块上","categories":[{"name":"pytorch","slug":"pytorch","permalink":"http://pistachio0812.github.io/categories/pytorch/"}],"tags":[{"name":"文档","slug":"文档","permalink":"http://pistachio0812.github.io/tags/%E6%96%87%E6%A1%A3/"}]},{"title":"github使用指南","slug":"github使用指南","date":"2022-03-25T10:46:42.593Z","updated":"2022-03-25T12:48:07.362Z","comments":true,"path":"2022/03/25/en/github使用指南/","link":"","permalink":"http://pistachio0812.github.io/2022/03/25/en/github%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","excerpt":"","text":"git安装1.安装git OSX版 下载地址：http://git-scm.com/download/mac 2.安装git Windows版 下载地址：http://book.git-scm.com/download/win 3.安装git Linux版 下载地址：http://book.git-scm.com/download/linux 创建新仓库创建新文件夹，打开，然后执行git init以创建新的git仓库 检出仓库执行如下命令以创建一个本地仓库的克隆版本： git clone /path/to/repository 如果是远端服务器上的仓库，则使用如下命令： git clone username@host:/path/to/repository 工作流你的本地仓库由git维护的三棵“树”组成。第一个是你的工作目录，它持有实际文件；第二个是暂存区（index),它像个缓存区域，临时保存你的改动；最后是HEAD,它指向你最后一次提交的结果。 添加和提交你可以提出更改（把它们添加到暂存区），使用如下命令： git add &lt;filename&gt; git add * 这是git基本工作流程的第一步；使用如下命令以实际提交改动： git commit -m &quot;代码提交信息&quot; 现在，你的改动已经提交到了HEAD,但是还没到你的远端仓库。 推送改动你的改动现在已经在本地仓库的HEAD中了。执行如下命令以将这些改动提交到远端仓库： git push origin master 可以把master换成你想要推送的任何分支。 如果你还没有克隆现有仓库，并欲将你的仓库连接到某个远程服务器，你可以使用如下命令添加： git remote add origin &lt;server&gt; 如此你就能够将你的改动推送到所添加的服务器上去了。 分支分支是用来将特性开发绝缘开来的。在你创建仓库的时候，master是默认的分支。在其他分支上进行开发，完成后再将它们合并到主分支上。 创建一个叫做“feature_x”的分支，并切换过去： git checkout -b feature_x 切换回主分支： git checkout master 再把新建的分支删掉： git branch -d feature_x 除非你将分支推送到远端仓库，不然该分支就是不为他人所见的： git push origin &lt;branch&gt; 更新与合并要更新你的本地仓库至最新改动，执行：git pull以在你的工作目录中 获取（fetch） 并 合并（merge） 远端的改动。要合并其他分支到你的当前分支（例如 master），执行：git merge &lt;branch&gt;在这两种情况下，git 都会尝试去自动合并改动。遗憾的是，这可能并非每次都成功，并可能出现冲突（conflicts）。 这时候就需要你修改这些文件来手动合并这些冲突（conflicts）。改完之后，你需要执行如下命令以将它们标记为合并成功： git add &lt;filename&gt;在合并改动之前，你可以使用如下命令预览差异：git diff &lt;source_branch&gt; &lt;target_branch&gt; 标签为软件发布创建标签是推荐的。这个概念早已存在，在 SVN 中也有。你可以执行如下命令创建一个叫做 1.0.0 的标签：git tag 1.0.0 1b2e1d63ff1b2e1d63ff 是你想要标记的提交 ID 的前 10 位字符。可以使用下列命令获取提交 ID：git log你也可以使用少一点的提交 ID 前几位，只要它的指向具有唯一性。 log如果你想了解本地仓库的历史记录，最简单的命令就是使用:git log你可以添加一些参数来修改他的输出，从而得到自己想要的结果。 只看某一个人的提交记录:git log --author=bob一个压缩后的每一条提交记录只占一行的输出:git log --pretty=oneline或者你想通过 ASCII 艺术的树形结构来展示所有的分支, 每个分支都标示了他的名字和标签:git log --graph --oneline --decorate --all看看哪些文件改变了:git log --name-status这些只是你可以使用的参数中很小的一部分。更多的信息，参考：git log --help 替换本地改动假如你操作失误（当然，这最好永远不要发生），你可以使用如下命令替换掉本地改动：git checkout -- &lt;filename&gt;此命令会使用 HEAD 中的最新内容替换掉你的工作目录中的文件。已添加到暂存区的改动以及新文件都不会受到影响。 假如你想丢弃你在本地的所有改动与提交，可以到服务器上获取最新的版本历史，并将你本地主分支指向它：git fetch origingit reset --hard origin/master 实用小贴士内建的图形化 git：gitk彩色的 git 输出：git config color.ui true显示历史记录时，每个提交的信息只显示一行：git config format.pretty oneline交互式添加文件到暂存区：git add -i 更多内容请参考：git - 简明指南","categories":[{"name":"github","slug":"github","permalink":"http://pistachio0812.github.io/categories/github/"}],"tags":[{"name":"使用指南","slug":"使用指南","permalink":"http://pistachio0812.github.io/tags/%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"},{"name":"github","slug":"github","permalink":"http://pistachio0812.github.io/tags/github/"}]},{"title":"How to use Linux","slug":"Linux系统学习笔记","date":"2022-03-24T02:36:23.299Z","updated":"2022-03-31T12:26:32.299Z","comments":true,"path":"2022/03/24/en/Linux系统学习笔记/","link":"","permalink":"http://pistachio0812.github.io/2022/03/24/en/Linux%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Linux简介UNIX 是一个交互式系统，用于同时处理多进程和多用户同时在线。为什么要说 UNIX，那是因为 Linux 是由 UNIX 发展而来的，UNIX 是由程序员设计，它的主要服务对象也是程序员。Linux 继承了 UNIX 的设计目标。从智能手机到汽车，超级计算机和家用电器，从家用台式机到企业服务器，Linux 操作系统无处不在。 大多数程序员都喜欢让系统尽量简单，优雅并具有一致性。举个例子，从最底层的角度来讲，一个文件应该只是一个字节集合。为了实现顺序存取、随机存取、按键存取、远程存取只能是妨碍你的工作。相同的，如果命令 ls A*意味着只列出以 A 为开头的所有文件，那么命令 rm A*应该会移除所有以 A 为开头的文件而不是只删除文件名是 A* 的文件。这个特性也是最小吃惊原则(principle of least surprise) 最小吃惊原则一般常用于用户界面和软件设计。它的原型是：该功能或者特征应该符合用户的预期，不应该使用户感到惊讶和震惊。 一些有经验的程序员通常希望系统具有较强的功能性和灵活性。设计 Linux 的一个基本目标是每个应用程序只做一件事情并把他做好。所以编译器只负责编译的工作，编译器不会产生列表，因为有其他应用比编译器做的更好。 很多人都不喜欢冗余，为什么在 cp 就能描述清楚你想干什么时候还使用 copy？这完全是在浪费宝贵的 hacking time。为了从文件中提取所有包含字符串 ard 的行，Linux 程序员应该输入 grep ard f","categories":[{"name":"Linux","slug":"Linux","permalink":"http://pistachio0812.github.io/categories/Linux/"}],"tags":[{"name":"Liunx system","slug":"Liunx-system","permalink":"http://pistachio0812.github.io/tags/Liunx-system/"}]},{"title":"色彩搭配","slug":"教你学会色彩搭配","date":"2022-03-22T10:22:49.177Z","updated":"2022-03-24T03:05:11.564Z","comments":true,"path":"2022/03/22/en/教你学会色彩搭配/","link":"","permalink":"http://pistachio0812.github.io/2022/03/22/en/%E6%95%99%E4%BD%A0%E5%AD%A6%E4%BC%9A%E8%89%B2%E5%BD%A9%E6%90%AD%E9%85%8D/","excerpt":"","text":"中国色中国色 COULEURcouleur color spacecolor space hyper colorHypercolor colorableColorable brandcolorsBrandColors 九月ppt九月PPT huemintHuemint - AI color palette generator Adobe Color色輪、調色盤產生器 | Adobe Color","categories":[],"tags":[]},{"title":"Q & A","slug":"遇到的问题","date":"2022-03-17T11:30:56.879Z","updated":"2022-04-07T02:28:02.876Z","comments":true,"path":"2022/03/17/CN/遇到的问题/","link":"","permalink":"http://pistachio0812.github.io/2022/03/17/CN/%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"就地操作问题来源：看代码发现self.relu=nn.ReLU(inplace=True)不明白inplace=True什么意思。 解答：查看pytorch官网关于ReLU定义，ReLU其中inplace参数表示可以选择就地执行操作，默认为False,就地执行操作是指图像处理函数的输入图像和输出图像是同一对象，即同一张图像，常规的图像处理函数是不支持输入图像和输出图像是同一图像的。 eg:中值滤波函数 medianBlur(src, dst, 7); //常规操作 medianBlur(src, src, 7); //就地操作 就地操作直接更改张量的内容，而无需复制它。由于它不创建输入的副本，因此在处理高维数据时减少了内存使用，就地操作有助于使用更少的GPU内存，详情请看该博客如何在Pytorch中执行就地操作 torch.max中keepdim的作用torch.max的用法： (max, max_indices) &#x3D; torch.max(input, dim, keepdim&#x3D;False) 输入： input 是输入的tensor。 dim 是索引的维度，dim&#x3D;0寻找每一列的最大值，dim&#x3D;1寻找每一行的最大值。 keepdim 表示是否需要保持输出的维度与输入一样，keepdim&#x3D;True表示输出和输入的维度一样，keepdim&#x3D;False表示输出的维度被压缩了，也就是输出会比输入低一个维度。 输出： max 表示取最大值后的结果。 2max_indices 表示最大值的索引 import torch import numpy as np x = torch.randint(0,9,(2,4)) print(x) tensor([[7, 8, 7, 2], [6, 0, 3, 0]]) #取每一行的最大值，torch.max的输出结果 y = torch.max(x, 1) print(y) torch.return_types.max(values=tensor([8, 6]),indices=tensor([1, 0])) #索引值 y = torch.max(x, 1, keepdim=True)[0]print(y)print(np.shape(y)) # keepdim=True，输出仍然是二维的tensor([[8], [6]])torch.Size([2, 1])y = torch.max(x, 1, keepdim=False)[0]print(y)print(np.shape(y)) keepdim=False # 输出变成了一维 tensor([8, 6])torch.Size([2]) ConstantPad2d的用法torch.nn.ConstantPad2d(padding, value) 参数：padding(int, tuple)-padding的尺寸，如果是整型，那么所有的边界都使用相同的填充，如果是四元组，使用（padding_left, padding_right, padding_top, padding_bottom) 形状： 输入：$$(N, C, H_{in}, W_{in}) or (C, H_{in}, W_{in})$$ 输出：$$(N, C, H_{out}, W_{out}) or (C, H_{out}, W_{out})$$其中，$$H_{out} &#x3D; H_{in}+padding_{top}+padding_{bottom}$$ $$W_{out}&#x3D;W_{in}+padding_{left}+padding_{right}$$ 测试用例： 1234567891011121314import torchimport torch.nn as nnn1 = nn.ConstantPad2d(2, 0)n2 = nn.ConstantPad2d((0, 1, 0, 1), 0)n3 = nn.ConstantPad2d((-1, 0, -1, 0), 0)input = torch.randn(1, 2, 2)print(input)t = n1(input)print(t)x = n2(input)y = n3(x)print(x)print(y) 结果： tensor([[[ 1.0826, 0.1191], [-0.3506, 0.1677]]])tensor([[[ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, 1.0826, 0.1191, 0.0000, 0.0000], [ 0.0000, 0.0000, -0.3506, 0.1677, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])tensor([[[ 1.0826, 0.1191, 0.0000], [-0.3506, 0.1677, 0.0000], [ 0.0000, 0.0000, 0.0000]]])tensor([[[0.1677, 0.0000], [0.0000, 0.0000]]]) 更多详情参考ConstantPad2d enumerate()函数描述enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。Python 2.3. 以上版本可用，2.6 添加 start 参数。 语法enumerate(sequence, [start=0]) 参数·sequence–一个序列、迭代器或其他支持迭代对象 ·start–下标起始位置的值 返回值返回enumerate(枚举)对象 实例以下展示了使用enumerate()方法的实例： seasons &#x3D; [‘Spring’, ‘Summer’, ‘Fall’, ‘Winter’] list(enumerate(seasons)) [(0, &#39;Spring&#39;), (1, &#39;Summer&#39;), (2, &#39;Fall&#39;), (3, &#39;Winter&#39;)] list(enumerate(seasons, start&#x3D;1)) # 下标从1开始 [(1, &#39;Spring&#39;), (2, &#39;Summer&#39;), (3, &#39;Fall&#39;), (4, &#39;Winter&#39;)] 普通的for循环 12345678910i = 0seq = [&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;]for i in enumerate(seq): print(i, seq[i]) i += 1result:0 one1 two2 three for循环使用enumerate 12345678seq = [&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;]for i, element in enumerate(seq): print(i, element)result:0 one1 two2 three torch.clamptorch.clamp(input, min=None, max=None, *, out=None)-&gt;Tensor Clamps中所有输入的元素都在[min, max]范围内，让最小值和最大值分别是min和max，将会返回：$$y_i&#x3D;min(max(x_i,min_value_i),max_value_i)$$如果min为空，就没有下界。或者，如果max为空，没有上界。 注： 如果min大于max,torch.clamp(...,min,max)设置输入的所有元素为max的值。 参数： ·input(Tensor)-输入张量 ·min(Number或Tensor,可选)-被限制范围的下界 ·max(Number或Tensor,可选)-被限制范围的上界 关键字参数： out(Tensor, 可选)-输出的张量 举例： 123456789&gt;&gt;&gt;a = torch.randn(4)&gt;&gt;&gt;atensor([-1.7120, 0.1734, -0.0478, -0.0922])&gt;&gt;&gt;torch.clamp(a, min=-0.5, max=0.5)tensor([-0.5000, 0.1734, -0.0478, -0.0922])&gt;&gt;&gt;min = torch.linspace(-1, 1, steps=4)&gt;&gt;&gt;torch.clamp(a, min=min)tensor([-1.000, 0.1734, 0.3333, 1.0000]) FPPI(68条消息) Recall&#x2F;Precision&#x2F;FPPI评价方式详解_Bruce_0712的博客-CSDN博客 torchvision.ops.box_iou语法torchvision.ops.box_iou(boxes1:torch.Tensor, boxes2:torch.Tensor)-&gt;torch.TensorSOURCE 返回两个框的交并比，这两个框的形式都是$$(x_1,y_1,x_2,y_2)$$并且$$0&lt;&#x3D;x_1&lt;x_2,0&lt;&#x3D;y_1&lt;y_2$$ 参数·boxes1(Tensor[N, 4])-&gt;第一个框 ·boxes2(Tensor[N, 4])-&gt;第二个框 返回返回boxes1和boxes2逐元素的配对IOU矩阵（N×M) 返回类型Tensor(N,M) torch.argmax（）函数torch.argmax(input)-&gt;LongTensor 返回input张量所有元素的最大值序号，这是torch.max()返回的第二个值。 注： 如果这里有多个最大值，则会返回第一个最大值的序号。 参数input(Tensor)-&gt;输入的张量 举例： 12345678&gt;&gt;&gt; a = torch.randn(4, 4)&gt;&gt;&gt; atensor([[ 1.3398, 0.2663, -0.2686, 0.2450], [-0.7401, -0.8805, -0.3402, -1.1936], [ 0.4907, -1.3948, -1.0691, -0.3132], [-1.6092, 0.5419, -0.2993, 0.3195]])&gt;&gt;&gt; torch.argmax(a)tensor(0) torch.argmax(input, dim, keppdim=False)-&gt;LongTensor 通过指定维度返回张量最大值的序号，这个最大值将会通过torch.max()返回 参数·input(Tensor):输入的张量 ·dim(int):减少的维度，如果没有，将返回平铺后的张量的argmax. ·keepdim(bool):输出的张量是否保持维度,如果dim=None将忽略。 举例： 12345678&gt;&gt;&gt; a = torch.randn(4, 4)&gt;&gt;&gt; atensor([[ 1.3398, 0.2663, -0.2686, 0.2450], [-0.7401, -0.8805, -0.3402, -1.1936], [ 0.4907, -1.3948, -1.0691, -0.3132], [-1.6092, 0.5419, -0.2993, 0.3195]])&gt;&gt;&gt; torch.argmax(a, dim=1)tensor([ 0, 2, 0, 1]) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import torcha = torch.tensor([ [ [1, 5, 5, 2], [9, -6, 2, 8], [-3, 7, -9, 1] ], [ [-1, 7, -5, 2], [9, 6, 2, 8], [3, 7, 9, 1] ]])b = torch.argmax(a, dim=0)print(b)print(a.shape) &quot;&quot;&quot;tensor([[0, 1, 0, 1], [1, 1, 1, 1], [1, 1, 1, 1]])torch.Size([2, 3, 4])&quot;&quot;&quot; # dim=0,即将第一个维度消除，也就是将两个[3*4]矩阵只保留一个，因此要在两组中作比较，即将上下两个[3*4]的矩阵分别在对应的位置上比较大小 b = torch.argmax(a, dim=1)&quot;&quot;&quot;tensor([[1, 2, 0, 1], [1, 2, 2, 1]])torch.Size([2, 3, 4])&quot;&quot;&quot;# dim=1，即将第二个维度消除,这么理解：矩阵维度变为[2*4];&quot;&quot;&quot;[1, 5, 5, 2],[9, -6, 2, 8],[-3, 7, -9, 1];纵向压缩成一维，因此变为[1,2,0,1];同理得到[1,2,2,1];&quot;&quot;&quot;b = torch.argmax(a,dim=2)&quot;&quot;&quot;tensor([[2, 0, 1], [1, 0, 2]])&quot;&quot;&quot;# dim=2,即将第三个维度消除，这么理解：矩阵维度变为[2*3]&quot;&quot;&quot; [1, 5, 5, 2], [9, -6, 2, 8], [-3, 7, -9, 1];横向压缩成一维[2,0,1],同理得到下面的&quot;&quot;&quot; python _call_()方法本节再介绍 Python 类中一个非常特殊的实例方法，即 _call_()。该方法的功能类似于在类中重载 () 运算符，使得类实例对象可以像调用普通函数那样，以“对象名()”的形式使用。 12345678# 引用来自C语言中文网，详情请参考：http://c.biancheng.net/view/2380.htmlclass CLanguage: # 定义__call__方法 def __call__(self,name,add): print(&quot;调用__call__()方法&quot;,name,add)clangs = CLanguage()clangs(&quot;C语言中文网&quot;,&quot;http://c.biancheng.net&quot;) 程序执行结果： 1调用__call__()方法 C语言中文网 http://c.biancheng.net 可以看到，通过在 CLanguage 类中实现 _call_() 方法，使的 clangs 实例对象变为了可调用对象。 Python 中，凡是可以将 () 直接应用到自身并执行，都称为可调用对象。可调用对象包括自定义的函数、Python 内置函数以及本节所讲的类实例对象。 对于可调用对象，实际上“名称()”可以理解为是“名称.call()”的简写。仍以上面程序中定义的 clangs 实例对象为例，其最后一行代码还可以改写为如下形式： 1clangs.__call__(&quot;C语言中文网&quot;,&quot;http://c.biancheng.net&quot;) 运行程序会发现，其运行结果和之前完全相同。 自定义函数： 1234def say(): print(&quot;Python教程：http://c.biancheng.net/python&quot;)say()say.__call__() 程序执行结果： 12Python教程：http://c.biancheng.net/pythonPython教程：http://c.biancheng.net/python 用 call() 弥补 hasattr() 函数的短板前面章节介绍了 hasattr() 函数的用法，该函数的功能是查找类的实例对象中是否包含指定名称的属性或者方法，但该函数有一个缺陷，即它无法判断该指定的名称，到底是类属性还是类方法。 要解决这个问题，我们可以借助可调用对象的概念。要知道，类实例对象包含的方法，其实也属于可调用对象，但类属性却不是。举个例子： 12345678910111213class CLanguage: def __init__ (self): self.name = &quot;C语言中文网&quot; self.add = &quot;http://c.biancheng.net&quot; def say(self): print(&quot;我正在学Python&quot;)clangs = CLanguage()if hasattr(clangs,&quot;name&quot;): print(hasattr(clangs.name,&quot;__call__&quot;))print(&quot;**********&quot;)if hasattr(clangs,&quot;say&quot;): print(hasattr(clangs.say,&quot;__call__&quot;)) 程序执行结果： 123False**********True 可以看到，由于 name 是类属性，它没有以 call 为名的 call() 方法；而 say 是类方法，它是可调用对象，因此它有 call() 方法。 argparse()函数argparse 模块可以让人轻松编写用户友好的命令行接口。程序定义它需要的参数，然后 argparse 将弄清如何从 sys.argv 解析出那些参数。 argparse 模块还会自动生成帮助和使用手册，并在用户给程序传入无效参数时报出错误信息。 以下代码是一个 Python 程序，它获取一个整数列表并计算总和或者最大值： 1234567891011import argparseparser = argparse.ArgumentParser(description=&#x27;Process some integers.&#x27;)parser.add_argument(&#x27;integers&#x27;, metavar=&#x27;N&#x27;, type=int, nargs=&#x27;+&#x27;, help=&#x27;an integer for the accumulator&#x27;)parser.add_argument(&#x27;--sum&#x27;, dest=&#x27;accumulate&#x27;, action=&#x27;store_const&#x27;, const=sum, default=max, help=&#x27;sum the integers (default: find the max)&#x27;)args = parser.parse_args()print args.accumulate(args.integers) 假设上面的 Python 代码保存在名为 prog.py 的文件中，它可以在命令行运行并提供有用的帮助信息： 1234567891011$ python prog.py -husage: prog.py [-h] [--sum] N [N ...]Process some integers.positional arguments: N an integer for the accumulatoroptional arguments: -h, --help show this help message and exit --sum sum the integers (default: find the max) 当使用适当的参数运行时，它会输出命令行传入整数的总和或者最大值： 12345$ python prog.py 1 2 3 44$ python prog.py 1 2 3 4 --sum10 如果传入无效参数，则会报出错误： 123$ python prog.py a b cusage: prog.py [-h] [--sum] N [N ...]prog.py: error: argument N: invalid int value: &#x27;a&#x27; 更多详情参考python文档，网址：15.4. argparse — 命令行选项、参数和子命令解析器 — Python 2.7.18 文档 Distuils大部分Python程序员都知道，有很多第三方包管理器供选择，包括setuptools、distribute等等。 有些是为了替代标准库中的distutils。 1.1概念和术语 对于模块开发者以及需要安装模块的使用者来说，Distutils的使用都很简单，作为一个开发者，除了编写源码之外，还需要： ·编写setup脚本（一般是setup.py）； ·编写一个setup配置文件（可选）； ·创建一个源码发布； ·创建一个或多个构建（二进制）发布（可选）; 有些模块开发者在开发时不会考虑多个平台发布，所以就有了packagers的角色，它们从模块开发者那取得源码发布，然后在多个平台上面进行构建，并发布多个平台的构建版本。 1.2简单例子 由python编写的setup脚本一般都非常简单。作为autoconf类型的配置脚本，setup脚本可以在构建和安装模块发布时运行多次。 比如，如果需要发布一个叫做foo的模块，它包含在一个文件foo.py，那setup脚本可以这样写： 12345from distutils.core import setup setup(name=&#x27;foo&#x27;, version=&#x27;1.0&#x27;, py_modules=[&#x27;foo&#x27;], ) setup函数的参数表示提供给Distutils的信息，这些参数分为两类：包的元数据（包名、版本号）以及包的信息（本例中是一个Python模块的列表）；模块由模块名表示，而不是文件名（对于包和扩展而言也是这样）；建议可以提供更多的元数据，比如你的名字，email地址和项目的URL地址。 编写好setup.py之后，就可以创建该模块的源码发布了： 1python setup.py sdist sdist命令会创建一个archive 文件（比如Unix上的tar文件，Windows上的zip文件），它包含setup.py， foo.py。该archive文件命名为foo-1.0.tar.gz(zip)，解压之后的目录名是foo-1.0。 如果一个用户希望安装foo模块，他只需要下载foo-1.0.tar.gz，解压，进入foo-1.0目录，然后运行： 1python setup.py install 该命令最终会将foo.py复制到Python环境存放第三方模块的目录中。在linux环境下，运行该命令的输出是： 123456789101112# python setup.py install running install running build running build_py creating build creating build/lib copying foo.py -&gt; build/lib running install_lib copying build/lib/foo.py -&gt; /usr/lib/python2.7/site-packages byte-compiling /usr/lib/python2.7/site-packages/foo.py to foo.pyc running install_egg_info Writing /usr/lib/python2.7/site-packages/foo-1.0-py2.7.egg-info 该命令生成的文件是： /usr/lib/python2.7/site-packages/foo-1.0-py2.7.egg-info /usr/lib/python2.7/site-packages/foo.py /usr/lib/python2.7/site-packages/foo.pyc 图片缩放方式对图像进行预处理操作的时候，一般有两种缩放方式。 一种是直接宽、高缩放至想要的宽、高，这种方式快捷，但可能会导致图像变形 step1: 计算宽高缩放比例，选择较小的那个缩放系数； step2: 计算缩放后的尺寸: 原始图片的长宽都乘以较小的缩放系数； step3：计算短边需要填充的灰边数，将短边的两边各自填充一半的灰行即可。 一种是等比例缩放，然后用灰色边缘填充 直接缩放代码实现如下： new_image = image.resize((target_w, target_h), Image.BICUBIC) 不变形缩放，两端填充灰边 不变形缩放，一端填充灰边 很多图片的长宽比不同导致缩放填充后，两端的黑边大小都不同。而如果填充的比较多，则存在信息冗余，影响推理速度。YOLOv5作者对letterbox的缩放策略进行了修改，对原图自适应的添加最少的黑边。 计算方法： 1.计算原始图片宽高与输入尺寸的缩放比例rw和rh，选取r &#x3D; min(rw,rh)后把原图按r进行缩放 2.原图宽和高中一定有一边完全贴合输入尺寸，没有达到输入尺寸的一边计算与输入尺寸的差值，然后进行上下（or左右）的填充。 代码如下： 1234567891011121314151617181920212223242526272829303132333435import matplotlib.pyplot as pltfrom PIL import Image# ---------------------------------------------------## 对输入图像进行resize,他人测试发现，不用letterbox_image直接resize的效果更好# ---------------------------------------------------#def resize_image(image, size, letterbox_image): iw, ih = image.size w, h = size # w=200, h=300 if letterbox_image: scale = min(w/iw, h/ih) nw = int(iw*scale) nh = int(ih*scale) image = image.resize((nw,nh), Image.BICUBIC) new_image = Image.new(&#x27;RGB&#x27;, size, (128,128,128)) # 新建一张image，第二个参数表示尺寸，第三个参数表示颜色 # --------------------------------------------------# # image.paste函数表示将一张图片覆盖到另一张图片的指定位置去 # a.paste(b, (50,50)) 将b的左上顶点贴到a的坐标为（50，50）的位置，左上顶点为(0,0), b超出a的部分会被自动舍弃 # ---------------------------------------------------# # new_image.paste(image, ((w-nw)//2, (h-nh)//2)) # 不变形resize，两端填充灰边 new_image.paste(image, (0, 0)) # 不变形resize，一端填充灰边 else: new_image = image.resize((w, h), Image.BICUBIC) return new_imageimg_PIL = Image.open(&quot;Avatar.jpg&quot;)img = resize_image(img_PIL, (200, 300), True) # 第二参数表示目标尺寸，第三参数表示是否使用letterboxplt.imshow(img)plt.show()# 作者：寻找永不遗憾# 链接：https://www.jianshu.com/p/2ae3a497f5f4# 来源：简书# 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 图像resize插值方式比较resize函数说明： void resize(InputArray src, OutputArray dst, Size dsize, double fx=0, double fy=0, int interpolation=INTER_LINEAR) 参数说明： src：输入，原图像，即待改变大小的图像；dst：输出，改变大小之后的图像，这个图像和原图像具有相同的内容，只是大小和原图像不一样而已；dsize：输出图像的大小。如果这个参数不为0，那么就代表将原图像缩放到这个Size(width，height)指定的大小；如果这个参数为0，那么原图像缩放之后的大小就要通过下面的公式来计算：$$dsize &#x3D; Size(round(fxsrc.cols), round(fysrc.rows))$$ 其中，fx和fy就是下面要说的两个参数，是图像width方向和height方向的缩放比例。 fx：width方向的缩放比例，如果它是0，那么它就会按照(double)dsize.width&#x2F;src.cols来计算；fy：height方向的缩放比例，如果它是0，那么它就会按照(double)dsize.height&#x2F;src.rows来计算；interpolation：这个是指定插值的方式，图像缩放之后，肯定像素要进行重新计算的，就靠这个参数来指定重新计算像素的方式，有以下几种： ·INTER_NEAREST - 最邻近插值 ·INTER_LINEAR - 双线性插值，如果最后一个参数你不指定，默认使用这种方法 ·INTER_AREA -区域插值 ·INTER_CUBIC - 4x4像素邻域内的双立方插值 ·INTER_LANCZOS4- 8x8像素邻域内的Lanczos插值 各种插值方式比较： 每种插值算法的前部分代码是相同的，如下： 12345678cv::Mat matSrc, matDst1, matDst2;matSrc = cv::imread(&quot;lena.jpg&quot;, 2 | 4);matDst1 = cv::Mat(cv::Size(800, 1000), matSrc.type(), cv::Scalar::all(0));matDst2 = cv::Mat(matDst1.size(), matSrc.type(), cv::Scalar::all(0));double scale_x = (double)matSrc.cols / matDst1.cols;double scale_y = (double)matSrc.rows / matDst1.rows; 最近邻：$$X_{src}&#x3D;X_{dst}(Width_{src}&#x2F;Width_{dst})\\Y_{src}&#x3D;Y_{dst}(Height_{src}&#x2F;Height_{dst})$$实现代码如下： 123456789101112131415for (int i = 0; i &lt; matDst1.cols; ++i)&#123; int sx = cvFloor(i * scale_x); sx = std::min(sx, matSrc.cols - 1); for (int j = 0; j &lt; matDst1.rows; ++j) &#123; int sy = cvFloor(j * scale_y); sy = std::min(sy, matSrc.rows - 1); matDst1.at&lt;cv::Vec3b&gt;(j, i) = matSrc.at&lt;cv::Vec3b&gt;(sy, sx); &#125;&#125;cv::imwrite(&quot;nearest_1.jpg&quot;, matDst1);cv::resize(matSrc, matDst2, matDst1.size(), 0, 0, 0);cv::imwrite(&quot;nearest_2.jpg&quot;, matDst2); 双线性：$$Dst(X, Y)&#x3D;(1-u)(1-v)Src(X’,Y’)+(1-u)vSrc(X’, Y’+1)+\\ u(1-v)Src(X’+1, Y’)+uvSrc(X’+1, Y’+1)$$ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849uchar* dataDst = matDst1.data;int stepDst = matDst1.step;uchar* dataSrc = matSrc.data;int stepSrc = matSrc.step;int iWidthSrc = matSrc.cols;int iHiehgtSrc = matSrc.rows;for (int j = 0; j &lt; matDst1.rows; ++j)&#123; float fy = (float)((j + 0.5) * scale_y - 0.5); int sy = cvFloor(fy); fy -= sy; sy = std::min(sy, iHiehgtSrc - 2); sy = std::max(0, sy); short cbufy[2]; cbufy[0] = cv::saturate_cast&lt;short&gt;((1.f - fy) * 2048); cbufy[1] = 2048 - cbufy[0]; for (int i = 0; i &lt; matDst1.cols; ++i) &#123; float fx = (float)((i + 0.5) * scale_x - 0.5); int sx = cvFloor(fx); fx -= sx; if (sx &lt; 0) &#123; fx = 0, sx = 0; &#125; if (sx &gt;= iWidthSrc - 1) &#123; fx = 0, sx = iWidthSrc - 2; &#125; short cbufx[2]; cbufx[0] = cv::saturate_cast&lt;short&gt;((1.f - fx) * 2048); cbufx[1] = 2048 - cbufx[0]; for (int k = 0; k &lt; matSrc.channels(); ++k) &#123; *(dataDst+ j*stepDst + 3*i + k) = (*(dataSrc + sy*stepSrc + 3*sx + k) * cbufx[0] * cbufy[0] + *(dataSrc + (sy+1)*stepSrc + 3*sx + k) * cbufx[0] * cbufy[1] + *(dataSrc + sy*stepSrc + 3*(sx+1) + k) * cbufx[1] * cbufy[0] + *(dataSrc + (sy+1)*stepSrc + 3*(sx+1) + k) * cbufx[1] * cbufy[1]) &gt;&gt; 22; &#125; &#125;&#125;cv::imwrite(&quot;linear_1.jpg&quot;, matDst1);cv::resize(matSrc, matDst2, matDst1.size(), 0, 0, 1);cv::imwrite(&quot;linear_2.jpg&quot;, matDst2); 双三次： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667int iscale_x = cv::saturate_cast&lt;int&gt;(scale_x);int iscale_y = cv::saturate_cast&lt;int&gt;(scale_y); for (int j = 0; j &lt; matDst1.rows; ++j)&#123; float fy = (float)((j + 0.5) * scale_y - 0.5); int sy = cvFloor(fy); fy -= sy; sy = std::min(sy, matSrc.rows - 3); sy = std::max(1, sy); const float A = -0.75f; float coeffsY[4]; coeffsY[0] = ((A*(fy + 1) - 5*A)*(fy + 1) + 8*A)*(fy + 1) - 4*A; coeffsY[1] = ((A + 2)*fy - (A + 3))*fy*fy + 1; coeffsY[2] = ((A + 2)*(1 - fy) - (A + 3))*(1 - fy)*(1 - fy) + 1; coeffsY[3] = 1.f - coeffsY[0] - coeffsY[1] - coeffsY[2]; short cbufY[4]; cbufY[0] = cv::saturate_cast&lt;short&gt;(coeffsY[0] * 2048); cbufY[1] = cv::saturate_cast&lt;short&gt;(coeffsY[1] * 2048); cbufY[2] = cv::saturate_cast&lt;short&gt;(coeffsY[2] * 2048); cbufY[3] = cv::saturate_cast&lt;short&gt;(coeffsY[3] * 2048); for (int i = 0; i &lt; matDst1.cols; ++i) &#123; float fx = (float)((i + 0.5) * scale_x - 0.5); int sx = cvFloor(fx); fx -= sx; if (sx &lt; 1) &#123; fx = 0, sx = 1; &#125; if (sx &gt;= matSrc.cols - 3) &#123; fx = 0, sx = matSrc.cols - 3; &#125; float coeffsX[4]; coeffsX[0] = ((A*(fx + 1) - 5*A)*(fx + 1) + 8*A)*(fx + 1) - 4*A; coeffsX[1] = ((A + 2)*fx - (A + 3))*fx*fx + 1; coeffsX[2] = ((A + 2)*(1 - fx) - (A + 3))*(1 - fx)*(1 - fx) + 1; coeffsX[3] = 1.f - coeffsX[0] - coeffsX[1] - coeffsX[2]; short cbufX[4]; cbufX[0] = cv::saturate_cast&lt;short&gt;(coeffsX[0] * 2048); cbufX[1] = cv::saturate_cast&lt;short&gt;(coeffsX[1] * 2048); cbufX[2] = cv::saturate_cast&lt;short&gt;(coeffsX[2] * 2048); cbufX[3] = cv::saturate_cast&lt;short&gt;(coeffsX[3] * 2048); for (int k = 0; k &lt; matSrc.channels(); ++k) &#123; matDst1.at&lt;cv::Vec3b&gt;(j, i)[k] = abs((matSrc.at&lt;cv::Vec3b&gt;(sy-1, sx-1)[k] * cbufX[0] * cbufY[0] + matSrc.at&lt;cv::Vec3b&gt;(sy, sx-1)[k] * cbufX[0] * cbufY[1] + matSrc.at&lt;cv::Vec3b&gt;(sy+1, sx-1)[k] * cbufX[0] * cbufY[2] + matSrc.at&lt;cv::Vec3b&gt;(sy+2, sx-1)[k] * cbufX[0] * cbufY[3] + matSrc.at&lt;cv::Vec3b&gt;(sy-1, sx)[k] * cbufX[1] * cbufY[0] + matSrc.at&lt;cv::Vec3b&gt;(sy, sx)[k] * cbufX[1] * cbufY[1] + matSrc.at&lt;cv::Vec3b&gt;(sy+1, sx)[k] * cbufX[1] * cbufY[2] + matSrc.at&lt;cv::Vec3b&gt;(sy+2, sx)[k] * cbufX[1] * cbufY[3] + matSrc.at&lt;cv::Vec3b&gt;(sy-1, sx+1)[k] * cbufX[2] * cbufY[0] + matSrc.at&lt;cv::Vec3b&gt;(sy, sx+1)[k] * cbufX[2] * cbufY[1] + matSrc.at&lt;cv::Vec3b&gt;(sy+1, sx+1)[k] * cbufX[2] * cbufY[2] + matSrc.at&lt;cv::Vec3b&gt;(sy+2, sx+1)[k] * cbufX[2] * cbufY[3] + matSrc.at&lt;cv::Vec3b&gt;(sy-1, sx+2)[k] * cbufX[3] * cbufY[0] + matSrc.at&lt;cv::Vec3b&gt;(sy, sx+2)[k] * cbufX[3] * cbufY[1] + matSrc.at&lt;cv::Vec3b&gt;(sy+1, sx+2)[k] * cbufX[3] * cbufY[2] + matSrc.at&lt;cv::Vec3b&gt;(sy+2, sx+2)[k] * cbufX[3] * cbufY[3] ) &gt;&gt; 22); &#125; &#125;&#125;cv::imwrite(&quot;cubic_1.jpg&quot;, matDst1); cv::resize(matSrc, matDst2, matDst1.size(), 0, 0, 2);cv::imwrite(&quot;cubic_2.jpg&quot;, matDst2); 基于像素区域关系：共分三种情况，图像放大时类似于双线性插值，图像缩小(x轴、y轴同时缩小)又分两种情况，此情况下可以避免波纹出现 具体实现代码可以参考https://github.com/fengbingchun/OpenCV_Test/blob/master/src/fbc_cv/include/resize.hpp，用法如下： 123fbc::Mat3BGR src(matSrc.rows, matSrc.cols, matSrc.data);fbc::Mat3BGR dst(matDst1.rows, matDst1.cols, matDst1.data);fbc::resize(src, dst, 3); 兰索斯插值：略 测试代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include &lt;chrono&gt;#include &lt;opencv2/opencv.hpp&gt;#define millisecond 1000000#define DEBUG_PRINT(...) printf( __VA_ARGS__); printf(&quot;\\n&quot;)#define DEBUG_TIME(time_) auto time_ =std::chrono::high_resolution_clock::now()#define RUN_TIME(time_) (double)(time_).count()/millisecondusing namespace std; cv::Mat image_resize(cv::Mat image, int width, int height, int interpolation, int num) &#123; cv::Mat dest; for (int i = 0; i &lt; num; ++i) &#123; cv::resize(image, dest, cv::Size(width, height), 0, 0, interpolation);//最近邻插值 &#125; return dest;&#125; int main() &#123; string path = &quot;../1.jpg&quot;; cv::Mat image = cv::imread(path); cv::resize(image, image, cv::Size(1000, 1000)); int re_width = 900; int re_height = 900; int num=10; cv::Mat image2X_INTER_NEAREST; cv::Mat image2X_INTER_LINEAR; cv::Mat image2X_INTER_AREA; cv::Mat image2X_INTER_CUBIC; cv::Mat initMat; DEBUG_PRINT(&quot;image input size:%dx%d&quot;, image.rows, image.cols); DEBUG_TIME(T0); image2X_INTER_NEAREST=image_resize(image, re_width, re_height, cv::INTER_NEAREST, num); DEBUG_TIME(T1); image2X_INTER_LINEAR=image_resize(image, re_width, re_height, cv::INTER_LINEAR, num); DEBUG_TIME(T2); image2X_INTER_AREA=image_resize(image, re_width, re_height, cv::INTER_AREA, num); DEBUG_TIME(T3); image2X_INTER_CUBIC=image_resize(image, re_width, re_height, cv::INTER_CUBIC, num); DEBUG_TIME(T4); DEBUG_PRINT(&quot;resize_image:%dx%d,INTER_NEAREST:%3.3fms&quot;, image2X_INTER_NEAREST.rows, image2X_INTER_NEAREST.cols, RUN_TIME(T1 - T0)/num); DEBUG_PRINT(&quot;resize_image:%dx%d,INTER_LINEAR :%3.3fms&quot;, image2X_INTER_LINEAR.rows, image2X_INTER_LINEAR.cols, RUN_TIME(T2 - T1)/num); DEBUG_PRINT(&quot;resize_image:%dx%d,INTER_AREA :%3.3fms&quot;, image2X_INTER_AREA.rows, image2X_INTER_AREA.cols, RUN_TIME(T3 - T2)/num); DEBUG_PRINT(&quot;resize_image:%dx%d,INTER_CUBIC :%3.3fms&quot;, image2X_INTER_CUBIC.rows, image2X_INTER_CUBIC.cols, RUN_TIME(T4 - T3)/num); return 0;&#125;版权声明：本文为CSDN博主「pan_jinquan」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/guyuealian/article/details/85097633 运行结果： 123456image input size:1000x1000resize_image:900x900,INTER_NEAREST:0.389msresize_image:900x900,INTER_LINEAR :0.605msresize_image:900x900,INTER_AREA :2.611msresize_image:900x900,INTER_CUBIC :1.920ms 总结： 1234 速度比较：INTER_NEAREST（最近邻插值)&gt;INTER_LINEAR(线性插值)&gt;INTER_CUBIC(三次样条插值)&gt;INTER_AREA (区域插值)对图像进行缩小时，为了避免出现波纹现象，推荐采用INTER_AREA 区域插值方法。OpenCV推荐：如果要缩小图像，通常推荐使用#INTER_AREA插值效果最好，而要放大图像，通常使用INTER_CUBIC(速度较慢，但效果最好)，或者使用INTER_LINEAR(速度较快，效果还可以)。至于最近邻插值INTER_NEAREST，一般不推荐使用 更多详情参考：OpenCV: Geometric Image Transformations","categories":[],"tags":[]},{"title":"学习笔记","slug":"学习笔记","date":"2022-03-17T01:30:47.993Z","updated":"2022-03-24T03:05:35.837Z","comments":true,"path":"2022/03/17/en/学习笔记/","link":"","permalink":"http://pistachio0812.github.io/2022/03/17/en/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"tf中矩阵量存在形式常用有三种，具体如下：1.tf.Variable()表示神经网络中可变化的量（可以通过trainable&#x3D;False设置成不可变),可在运行中赋值，可以通过constant或者其他方式进行初始化。2.tf.constant()可以通过numpy中的array或者list,还有给定的shape和数值进行赋值3.tf.placeholder()相当于占位符，也是有shape的量，因为训练过程中需要不断赋值和替换值，而整体计算的结构是不变的。代码：&#x2F;&#x2F;导包 import tensorflow as tf &#x2F;&#x2F;定义变量A = tf.Variable(tf.ones([4,4])) &#x2F;&#x2F;变量初始化import numpy as np cst = tf.constant(np.ones([4,4]),dtype=tf.float32) #需要指定类型dtype&#x3D;tf.float32,tf中不能隐式转换浮点和整型#cst &#x3D; tf.constant(1.0,shape&#x3D;[4,4],dtype&#x3D;tf.float32)也是可以的A = tf.Variable(cst) &#x2F;&#x2F;定义placeholderX = tf.placeholder(dtype=tf.float32,shape=[4,1]) &#x2F;&#x2F;矩阵相乘C = tf.matmul(A,X) &#x2F;&#x2F;定义Sessionsess = tf.Session() &#x2F;&#x2F;初始化变量init = tf.global_variables_initializer() &#x2F;&#x2F;执行初始化sess.run(init) &#x2F;&#x2F;运行矩阵相乘sess.run(C,feed_dict=&#123;X:[[1],[1],[1],[1]]&#125;) &#x2F;&#x2F;获取变量值A_val = A.value() Avalue = sess.run(A_val) &#x2F;&#x2F;完整矩形相乘代码import tensorflow as tf import numpy as np X = tf.placeholder(dtype=tf.float32,shape=[4,1]) A = tf.Variable(tf.zeros([4,4])) C = tf.matmul(A,X) sess = tf.session() init = tf.global_variables_initializer() sess.run(init) print(sess.run(A)) &#x2F;&#x2F;为了使计算图更加清晰，可以使用variable_scope()&#x2F;&#x2F;定义变量名称with tf.variable_scope(&quot;first-nn-layer&quot;): W = tf.Variable(tf.zeros([784,10]),name=&quot;W&quot;) b = tf.Variable(tf.zeros([10]),name=&quot;b&quot;) y = tf.matmul(x,W)+b variable_summaries(W) &#x2F;&#x2F;标识不同的变量&#x2F;&#x2F;不同作用域下的同名变量with tf.variable_scope(&quot;first-nn-layer&quot;): W = tf.Variable(tf.zeros([784,10]),name=&quot;W&quot;) b = tf.Variable(tf.zeros([10]),name=&quot;b&quot;) W1 = tf.Variable(tf.zeros([784,10]),name=&quot;W&quot;) print(W.name) print(W1.name)#w、w1虽然name一样，但是计算中依然当成不同的变量，让同一个scope的同一变量可以通过get_variable()函数 &#x2F;&#x2F;获取变量with tf.variable_scope(&quot;first-nn-layer&quot;) as scope: W = tf.get_variable(&quot;W&quot;,[784, 10]) b = tf.get_variable(&quot;b&quot;,[10]) scope.reuse_variables()#缺少则会报错 W1 = tf.get_variables(&quot;W&quot;,shape=[784,10]) print(W.name) print(W1.name)#w、w1属于同一个变量 注：若此时缺少了scope.reuse_variables()则会报错，因为同时引用了同一个变量，对于不同层的变量，可以利用variable_scope进行区分，在再次引入相关变量时，需要加上reuse&#x3D;True,否则依然会报错。如果变量不存在时加上reuse&#x3D;True,依然会报错，因为该变量不存在 with tf.variable_scope(&quot;first-nn-layer&quot;) as scope: W = tf.get_variable(&quot;W&quot;,[784, 10]) b = tf.get_variable(&quot;b&quot;,[10]) with tf.variable_scope(&quot;second-nn-layer&quot;) as scope: W = tf.get_variable(&quot;W&quot;,[784, 10]) b = tf.get_variable(&quot;b&quot;,[10]) with tf.variable_scope(&quot;second-nn-layer&quot;, reuse=True) as scope: W3 = tf.get_variable(&quot;W&quot;,[784, 10]) b3 = tf.get_variable(&quot;b&quot;,[10]) print(W.name) print(W3.name) &#x2F;&#x2F;保存模型&#x2F;&#x2F;定义saversaver = tf.train.Saver() &#x2F;&#x2F;在训练过程中进行保存，保存为训练过程中的变量&#x2F;&#x2F;变量保存for itr in range(1000): ... saver.save(sess,&quot;model/al&quot;,global_step=itr) &#x2F;&#x2F;加载计算&#x2F;&#x2F;变量载入saver.restore(sess,&quot;model/v2-200&quot;) 3.4构建计算图&#x2F;&#x2F;前面在描述计算图，这里观察所建立的计算图&#x2F;&#x2F;定义summarytrain_writer = tf.summary.FileWriter(&quot;logdir&quot;,sess.graph) 注：sess.graph就是描绘的计算图，”logdir”是log的存储文件夹。在Shell中运行Tensorboard,在浏览器中输入localhost:6006,然后点击graph就可以看到设计的网络模型了。 &#x2F;&#x2F;问题：描绘的计算图非常杂乱无章，变量命名的可读性很差，需要进行整理。&#x2F;&#x2F;变量命名x = tf.placeholder(tf.float32,[None,784],name=&quot;input_x&quot;) label = tf.placeholder(tf.float32,[None,10],name=&quot;input_label&quot;) W = tf.Variable(tf.zeros([874,10]),name=&quot;W&quot;) b = tf.Variable(tf.zeros([10]),name=&quot;b&quot;) &#x2F;&#x2F;问题：依然不够清楚，可以将输入层的x和label归为一类&#x2F;&#x2F;定义作用域with tf.variable_scope(&quot;input&quot;): x = tf.placeholder(tf.float32,[None,784],name=&quot;input_x&quot;) label = tf.placeholder(tf.float32,[None,10],name=&quot;input_label&quot;) with tf.variable_scope(&quot;first-nn-layer&quot;): W = tf.Variable(tf.zeros([784,10]), name=&quot;W&quot;) b = tf.Variable(tf.zeros([10]),name=&quot;b&quot;) y = tf.matmul(x,W)+b with tf.variable_scope(&quot;loss&quot;): loss = tf.reduce_mean(tf.square(y-label)) &#x2F;&#x2F;同一作用域下的同名变量是相同的，涉及到变量复用的问题，以及后续变量的获取，为了观察变量的变化，需要观察的变量加入summary函数&#x2F;&#x2F;定义summary函数def variable_summaries(var): with tf.name_scope(&#39;summaries&#39;): mean = tf.reduce_mean(var) tf.summary.scalar(&#39;mean&#39;,mean) with tf.name_scope(&#39;stddev&#39;): stddev = tf.sqrt(tf.reduce_mean(tf.square(var-mean))) tf.summary.scalar(&#39;stddev&#39;,stddev) tf.summary.scalar(&#39;max&#39;,tf.reduce_max(var)) tf.summary.scalar(&#39;min&#39;,tf.reduce_min(var)) tf.summary.histogram(&#39;histogram&#39;,var) &#x2F;&#x2F;若要观测W的相关情况，调用summary函数&#x2F;&#x2F;调用summary函数variable_summaries(W) &#x2F;&#x2F;再用merge_all函数收集summary信息&#x2F;&#x2F;获取summary信息merged = tf.summary.merge_all() &#x2F;&#x2F;summary保存summary = sess.run(merged, feed_dict=&#123;x:batch_xs,label:batch_ys&#125;) train_writer.add_summary(summary,itr) 注：此时可以在网页中访问，观察变量随迭代变化的情况，可以通过不同的方式对变量进行观测，比如时序统计、histogram,这些统计信息对于分析训练过程是非常重要的 3.5全连接网络构建&#x2F;&#x2F;tf官方手写识别版本的简化版本&#x2F;&#x2F;单层全连接网络#引入库from tensorflow.examples.tutorials.mnist import input_data#产生数据，手写识别的图片和标签 import tensorflow as tf #获取数据mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;,one_hot=True)#构建网络模型#x,label分别为图形数据和标签数据x = tf.placeholder(tf.float32,[None,784]) label = tf.placeholder(tf.float32,[None,10])#构建单层网络中的权值和偏置W = tf.Variable(tf.zeros([784,10])) b = tf.Variable(tf.zeros([10])#本例中无非线性激活函数y = tf.matmul(x,W)+b#定义损失函数为欧氏距离，但这并不是最好的，多分类问题通常使用交叉熵loss = tf.reduce_mean(tf.square(y-label))#若使用交叉熵损失函数soft_max = tf.nn.softmax(logit, axis=1) loss = tf.reduce_mean(-label*tf.log(soft_max))#用梯度迭代算法train_step = tf.train.GradientDescentOptimizer(0.005).minimize(loss)#用于验证correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(label,1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float.32))#定义会话sess = tf.Session()#初始化所有变量sess.run(tf.global_variable_initializer())#迭代过程for itr in range(3000): batch_xs,batch_ys = mnist.train.next_batch(100) sess.run(train_step, feed_dict=&#123;x:batch_xs,label:batch_ys&#125;) if itr%10==0: print(&quot;step:%6d accuracy:&quot;%iter, sess.run(accuracy, feed_dict=&#123;x:mnist.test.images, label:mnist.test.labels&#125;)) #获取W取值W_value = sess.run(W.value()) &#x2F;&#x2F;定义一个单层全连接函数def full_layer(input_tensor, out_dim, name=&quot;full&quot;): with tf.variable_scope(name): shape = input_tensor.get_shape()as_list() W = tf.get_variable(&#39;W&#39;,(shape[1],out_dim),dtype=tf.float32, initalizer=tf.truncated_normal_initializer(stddev=0.1)) b = tf.get_variable(&#39;b&#39;,[out_dim], dtype=tf.float32, initializer=tf.constant_initializer(0)) out = tf.matmul(input_tensor, W)+b return tf.nn.sigmoid(nn) 3.6CNN构建&#x2F;&#x2F;CNN手写识别#预读取MNIST手写字库from tensorflow.examples.tutorials.mnist import input_data mnist = input_data.read_data_sets(&quot;MNIST_data&quot;,one_hot=True) import tensorflow as tf#用正态分布随机数初始化变量，本例中仅作为权值def weight_variable(shape): initial=tf.truncated_normal(shape,stddev=0.1) #正态分布 return tf.Variable(initial)#用常量方式初始化偏置def bias_variable(shape): initial=tf.constant(0.1,shape=shape) #常数分布 return tf.Variable(initial)#定义二维卷积的过程def conv2d(x,W): return tf.nn.conv2d(x,W,strides&#x3D;[1,1,1,1],padding&#x3D;’SAME’)#定义池化层，简单地说就是选个最大的数，进一步降低自由参数的个数def max_pool_2x2(x): return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=&#39;SAME&#39;) x = tf.placeholder(tf.float32,shape=[100,784]) y = tf.placeholder(tf.float32,shape=[100,10]) W_conv1 = weight_variable([5,5,1,32]) b_conv1 = bias_variable([32]) x_image = tf.reshape(x,[-1,28,28,1]) y_conv1 = tf.nn.relu(conv2d(x_iamge,W_conv1)+b_conv1) y_pool1 = max_pool_2x2(y_conv1) W_conv2 = weight_variable([5,5,32,64]) b_conv2 = weight_variable([64]) y_conv2 = tf.nn.relu(conv2d(y_pool1,W_conv2)+b_conv2) y_pool2 = max_pool_2x2(y_conv2) y_fc_flat = tf.reshape(y_pool2,[-1,7*7*64]) W_fc1 = weight_variable([7*7*64,10]) b_fc1 = bias_variable([10]) y_fc1 = tf.nn.relu(tf.matmul(y_fc_flat,W_fc1)+b_fc1) cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=y_fc1)) train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) sess = tf.Session() init = tf.global_variables_initializer() sess.run(init) for i in range(1000): bx,by = mnist.train.next_batch(100) sess.run(train_step,feed_dict=&#123;x:bx,y:by&#125;) import numpy as np import matplotlib.pyplot as plt#设置输出风格，为画图美观import matplotlib as mpl mpl.style.use(&#39;seaborn-darkgrid&#39;) val = W_conv1.value() convVal = np.array(sess.run(val)) convVal = np.reshape(convVal,[5,5,32]) plt.imshow(convVal[:,:,6]) plt.show() 3.8多架构运行&#x2F;&#x2F;GPU使用GPU可以加速深度学习作业的训练速度，如果服务器有多个GPU,那么tensorflow默认使用全部使用部分GPU: python程序启动时调用：CUDA_VISIBLE_DEVICES=0.2.3 python script.py python代码内进行调用：import os os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;]=&quot;1&quot; &#x2F;&#x2F;配置GPU显存某些情况下，多作业或者共享GPU的场景中，可以控制tf使用GPU显存大小gpuOptions = tf.GPUOptions(per_process_gpu_memory_fraction=0.8) sess = tf.Session(config=tf.ConfigProto(gpu_options=gpuOptions)) &#x2F;&#x2F;GPU运行代码#将变量的定义和分配定义到GPU上进行with tf.device(&#39;/gpu:0&#39;): W = tf.get_variable(&#39;W&#39;,(in_dim,out_dim),dtype=tf.float32,initializer=tf.truncated_normal_initializer(stddev=0.1)) b = tf.get_variable(&#39;b&#39;),[out_dim],dtype=tf.float32,initializer=tf.constant_initializer(0)) net = tf.matmul(input_tensor,W)+b#在CPU上计算激活函数with tf.device(&#39;/cpu:0&#39;): net = tf.nn.sigmoid(net) &#x2F;&#x2F;多CPU使用，多设备计算&#x2F;&#x2F;利用标号简单的区分并运行#在CPU0上计算with tf.device(&#39;/cpu:0&#39;) ... net = tf.nn.sigmoid(net)#在CPU1上计算with tf.device(&#39;/cpu:1&#39;) ... net = tf.nn.sigmoid(net) &#x2F;&#x2F;在集群上运行，需要在多个主机上准备多份代码，代码前面部分相同，后续有所不同&#x2F;&#x2F;定义多主机运行参数#这里的地址形式为IP:Portcluster = tf.train.ClusterSpectf.train.ClusterSpec(&#123; &quot;worker&quot;:[ &quot;xx.xx.xx.xx:2222&quot;, #/job:worker/task:0 &quot;xx.xx.xx.xx:2222&quot;, #这里job的名称为自定义 &quot;xx.xx.xx.xx:2222&quot; #task编号同样需在Server中定义 ], &quot;ps&quot;:[ &quot;xx.xx.xx.xx:2222&quot;, &quot;xx.xx.xx.xx:2222&quot; ]&#125;) server = tf.train.Server(cluster, job_name=&quot;worker&quot;, task_index=0) &#x2F;&#x2F;定义第二个主机参数#这里的地址形式为IP:Portcluster = tf.train.ClusterSpectf.train.ClusterSpec(&#123; &quot;worker&quot;:[ &quot;xx.xx.xx.xx:2222&quot;, #/job:worker/task:0 &quot;xx.xx.xx.xx:2222&quot;, #这里job的名称为自定义 &quot;xx.xx.xx.xx:2222&quot; #task编号同样需在Server中定义 ], &quot;ps&quot;:[ &quot;xx.xx.xx.xx:2222&quot;, &quot;xx.xx.xx.xx:2222&quot; ]&#125;) server = tf.train.Server(cluster, job_name=&quot;worker&quot;, task_index=1) &#x2F;&#x2F;不同设备的运行代码with tf.device(&#39;/job:worker/task:0/cpu:0&#39;): ... &#x2F;&#x2F;将不同的任务分配到不同的计算节点上&#x2F;&#x2F;分配计算任务with tf.device(tf.train.replica_device_setter( worker_device=&quot;/job:worker/task:%d&quot; %task_index,cluster=cluster) &#x2F;&#x2F;函数replica_device_setter会将变量参数的定义部分自动定义到ps服务中，后续需要定义Session,用于执行这个过程&#x2F;&#x2F;多主机运行#定义句柄，迭代多少步后停止迭代hooks = [tf.train.StopAtStepHook(last_step=1000000)]#MonitoredTrainingSession函数会完成会话初始化工作#保存checkpoint,恢复checkpoint,异常判断等#这里需要定义master主机，定义保存、控制操作的masterwith tf.train.MonitroedTrainingSession( master=server.target, is_chief=(task_index==0), checkpoint_dir=&quot;dir/to/cp&quot;, hooks=hooks) as mon_sess: ... 注：在程序运行过程中，需要认为将程序分配到各个主机上，依次运行各个主机 &#x2F;&#x2F;队列用于数据读取和处理，队列可以是先进先出队列，也可以是随机队列，用于随机化输出&#x2F;&#x2F;tf中队列的操作是对于训练前的过程而言的，有以下作用1.多线程数据预处理并将其推入队列2.在执行过程中，队列不断提供训练数据&#x2F;&#x2F;简单实例说明队列使用def simple_shuffle_batch(source,capacity,batch_size=10): #定义随机序列 queue = tf.RandomShuffleQueue( capacity=capacity, min_after_dequeue=int(0.9*capacity), shapes=source.shape, dtypes=source.dtype) #定义enqueue过程 enqueue = queue.enqueue(source) #定义执行进程个数 num_threads = 4 qr = tf.train.QueueRunner(queue,[enqueue]*num_threads) #声明Queue runner,使得其可以被执行 tf.train.add_queue_runner(qr) #获取数据 return queue.dequeue_many(batch_size)#产生测试数据input = tf.constant(list(range(100))) input = tf.data.Dataset.from_tensor_slices(input) input = input.make_one_shot_iterator().get_next() #定义函数get_batch = simple_shuffle_batch(input,capacity=20) #定义sessionwith tf.train.MonitoredSession() as sess: while not sess.should_stop(): print(sess.run(get_batch)) 注：队列操作可以使得数据读取过程得到并行的优化，这对于提升程序的运行速度是很有利的。 &#x2F;&#x2F;tf相关扩展4.2.1 tf Layers&#x2F;&#x2F;全连接网络#layers定义全连接网络net = tf.layers.dense(inputs=net, units=units, activation=tf.nn.relu) #卷积网络net = tf.layers.conv2d( inputs=net, #输入 filters=n_features, #输出特征数 kernel-size=[5, 5], #卷积核心大小 padding=&quot;same&quot;, #边界 activation=tf.nn.relu #激活函数 ) &#x2F;&#x2F;前馈神经网络函数#二维最大池化net = tf.layers.max_pooling2d(...)#二维平均池化net = tf.layers.average_pooling2d(...)#二维卷积net = tf.layers.conv2d(...)#dropoutnet = tf.layers.dropout(...)#展开net = tf.layers.flatten(...)#BNnet = tf.layers.batch_normalization(...) 4.2.2 tf Slim#卷积函数def conv2d_layer(input_tensor, size=1, feature=128, name=&#39;conv1d&#39;): with tf.variable_scope(name): shape = input_tensor.get_shape.as_list() kernel = tf.get_variable(&#39;kernel&#39;, (size, size, shape[-1], feature), dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.1)) b = tf.get_variable(&#39;b&#39;, [feature], dtype=tf.float32, initializer=tf.constant_initializer(0)) out = tf.nn.conv2d(input_tensor, kernel, strides=[1,2,2,1],padding=&#39;SAME&#39;)+b return tf.nn.relu(out)#全连接函数def full_layer(input_tensor, out_dim, name=&#39;full&#39;): with tf.variable_scope(name): shape = input_tensor.get_shape.as_list() W = tf.get_variable(&#39;W&#39;, (shape[1], out_dim), dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.1)) b = tf.get_variabel(&#39;b&#39;, [out_dim], dtype=tf.float32, initializer=tf.constant_initializer(0)) out = tf.matmul(input_tensor, W)+b return out &#x2F;&#x2F;slim实现卷积，tfv2取消该库#引入slim库import tensorflow.contrib.slim as slim#定义卷积层net = slim.conv2d(inputs, 16, 4, strides=2, activation_fn=tf.nn.relu, scope=&#39;conv1&#39;)#加入池化层net = tf.nn.max_pool(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;SAME&#39;) net = slim.conv2d(net, 32, 4, strides=2, activation_fn=tf.nn.relu, scope=&#39;conv2&#39;) net = tf.nn.max_pool(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;SAME&#39;) #flatten层，用于将三维的图形数据展开成一维数据，用于全连接层net = slim.flatten(net)#全连接层y = slim.fully_connected(net, 10, activation_fn=line, scope=&#39;full&#39;, reuse=False) 4.2.3 tfLearn&#x2F;&#x2F;tflearn抽象层次更高，代码可读性更好,其是一个完整的生态&#x2F;&#x2F;基础网络架构#全连接net = tflearn.fully_connected(...)#卷积net = tflearn.conv_2d(...)#LSTMnet = tflearn.lstm(...)#dropoutnet = tflearn.dropout(...) &#x2F;&#x2F;输入函数network = tflearn.input_data(shape=[None, 28, 28, 1], name=&#39;input&#39;) &#x2F;&#x2F;优化部分#定义优化过程network = tflearn.layers.estimator.regression( network, optimizer=&#39;adam&#39;, #优化方法 learning_rate=0.01, #学习率 loss=&#39;categorical_crossentropy&#39;, #损失函数 name=&#39;target&#39;) &#x2F;&#x2F;利用tflearn完成手写数字的识别任务import tflearn from tflearn.layers.core import input_data,dropout, fully_connected from tflearn.layers.conv import conv_2d, , max_pool_2d from tflearn.layers.normalization import local_response_normalization from tflearn.layers.estimator import regression #载入并处理数据import tflearn.datasets.mnist as mnist X, Y, testX, testY = mnist.load_data(one_hot=True)#转换为二维图形X = X.reshape([-1, 28, 28, 1]) testX = testX.reshape([-1, 28, 28, 1]) #建立神经网络network = tflearn.input_data(shape=[None, 28, 28, 1], name=&#39;input&#39;) network = conv_2d(network, 32, 3, activation=&#39;relu&#39;, regularizer=&#39;L2&#39;) network = max_pool_2d(network) network = local_response_normalization(network) network = fully_connected(network, 128, activation=&#39;tanh&#39;) network = dropout(network, 0.8) network = fully_connected(network, 256, activation=&#39;tanh&#39;) network = dropout(network, 0.8) network = fully_connected(network, 10, activation=&#39;softmax&#39;) #定义优化过程network = regression( network, optimizer=&#39;adam&#39;, learning_rate=0.01, loss=&#39;categorical_crossentropy&#39;, name=&#39;target&#39;) #训练过程model = tflearn.DNN(network, tensorboard_verbose=0) model.fit(&#123;&#39;input&#39;:X&#125;, &#123;&#39;target&#39;:Y&#125;, n_epoch=20, validation_set=(&#123;&#39;input&#39;:testX&#125;, &#123;&#39;target&#39;:testY&#125;), snapshot_step=100, show_metric=True, run_id=&#39;convnet_mnist&#39;) &#x2F;&#x2F;Keras代码可读性好，并且横跨多个机器学习框架，但其扩展性较差&#x2F;&#x2F;引入库from keras.layers import Dense, Dropout, Flatten from keras.layers import Conv2D, MaxPooling2D &#x2F;&#x2F;Keras直接顺序加入模型，无需通过数据方式进行传递&#x2F;&#x2F;基础网络层from keras.models import Sequential model = Sequential()#加入卷积层model.add(Conv2D(...))#加入池化层model.add(MaxPooling2D(...))#加入全连接层model.add(Dense(...))#dropoutmodel.add(Dropout(0.25)) &#x2F;&#x2F;定义model后可直接加入多种层进行操作，同样其需要定义训练函数&#x2F;&#x2F;定义优化过程from keras.optimizers import SGD#定义迭代算法sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=sgd)#训练过程model.fit(x_train, y_train, batch_szie=32, epochs=10)#评估训练效果score = model.evaluate(x_test, y_test, batch_size=32) &#x2F;&#x2F;完整代码import keras from keras.models import Sequential from keras.layers import Dense, Dropout, Flatten from keras.layers import Conv2D, MaxPooling2D from keras.optimizers import SGD #这里utils为自己定义的库函数，用于载入数据import utils X, Y, testX, testY = utils.load_data(one_hot=True) model = Sequential()#定义神经网络过程model.add(Conv2D(32, (3, 3), activation=&#39;relu&#39;, input_shape=(100, 100, 3))) model.add(Conv2D(32, (3, 3), activation=&#39;relu&#39;)) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Conv2D(64, (3, 3), activation=&#39;relu&#39;)) model.add(Conv2D(64, (3, 3), activatin=&#39;relu&#39;)) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) #展开为一维数据用于全连接层model.add(Flatten()) model.add(Dense(256, activation=&#39;relu&#39;)) model.add(Dropout(0.5)) model.add(Dense(10, activation=&#39;softmax&#39;))#梯度迭代算法sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=sgd)#训练过程model.fit(x_train, y_train, batch_size=32, epochs=10)#效果评估score = model.evaluate(x_test, y_test, batch_size=32) 4.3 Tensorboard与问题监控&#x2F;&#x2F;tensorboard最重要的作用就在于观察训练过程中的各种问题并改善，包括梯度消失、过拟合等问题&#x2F;&#x2F;获取所有可训练的参数var_list_w = [var for var in tf.trainable_variables() if &#39;w&#39; in var.name] var_list_b = [var for var in tf.trainable_variables() if &#39;b&#39; in var.name] &#x2F;&#x2F;利用定义的梯度算法来计算梯度gradient_w = optimizer.compute_gradients(loss, var_list=var_list_w) gradient_b = optimizer.compute_gradients(loss, var_list=var_list_b) &#x2F;&#x2F;返回的梯度是一个列表，可对其进行各种列表操作&#x2F;&#x2F;加入summary操作for idx, itr_g in enumerate(gradient_w): variable_summaries(itr_g[0], &#39;layer%d-w-grad&#39;%idx) for idx, itr_g in enumerate(gradient_b): variable_summaries(itr_g[0], &#39;layer%d-b-grad&#39;%idx for idx, itr_g in enumerate(var_list_w): variable_summaries(itr_g, &#39;layer%d-w-grad&#39;%idx) for idx, itr_g in enumerate(var_list_b): variable_summaries(itr_g, &#39;layer%d-b-grad&#39;%idx) 4.4改善深度神经网络&#x2F;&#x2F;出现梯度消失一种最有效的方式就是进行BN操作&#x2F;&#x2F;batchnorm层net = tf.contrib.layers.batch_norm(net) &#x2F;&#x2F;加入BN层的神经网络#对于sigmoid激活函数来讲，BN操作效果可能不理想net = slim.fully_connected(x, 4, activation_fn=tf.nn.sigmoid, scope=&#39;full1&#39;, reuse=False) net = tf.contrib.layers.batch_norm(net) net = slim.fully_connected(net, 8, activation_fn=tf.nn.sigmoid, scope=&#39;full2&#39;, reuse=False) net = tf.contrib.layers.batch_norm(net) net = slim.fully_connected(net, 8, activation_fn=tf.nn.sigmoid, scope=&#39;full3&#39;, reuse=False) net = tf.contrib.layers.batch_norm(net) net = slim.fully_connected(net, 4, activation_fn=tf.nn.sigmoid, scope=&#39;full4&#39;, reuse=False) net = tf.contrib.layers.batch_norm(net) net = slim.fully_connected(net, 3, activation_fn=tf.nn.sigmoid, scope=&#39;full5&#39;, reuse=False) loss = tf.reduce_mean(tf.square(y-label)) 4.5性能优化建议&#x2F;&#x2F;训练前的优化技巧1.网络结构优化Relu和BN能够有效加快神经网络训练速度卷积核心的选取可以从大的卷积核心修改为多个小的卷积核心将nxn修改为nx1+1xn，减少参数量，不同的输出内容之间可以进行concat引入跨层支路解决梯度问题（ResNet)2.初始值的选取不好的初始值对训练的影响非常大，有效的初始化方法包括xavier初始化方法和He初始化方法3.数据预处理包括去均值和方差均衡&#x2F;&#x2F;训练过程中的优化技巧1）优化算法的选择Adam2）学习率的选取从大的步长开始进行迭代，逐步减少学习率3）Batchsize选择4）model ensembles使用不同初始值同时训练多个模型，预测过程中将多个模型输出结果做平均，有效提升结果精度5)dropout选择从0.5附近进行调整，调整步长为0.05左右 &#x2F;&#x2F;物体检测1.传统检测方法2001年，基于Haar特征和Adaboost检测方法引起轰动2012年之前，三方面不断创新与优化：特征的设计更新、检测窗口的选择、分类器的设计更新 2.深度学习的物体检测1）基于分类的物体检测处理过程：图像被分解成多个小区域，每个小区域将运行一个分类算法以确定区域是否包含待检测物体，之后再在这个小区域的周围确认物体的边界框。代表算法：R-CNN、Fast-RCNN、Faster-RCNN2) 基于回归的物体检测将问题建模为回归问题，通过深度神经网络直接预测出边界框和所属类别的置信度。代表算法：SSD、YOLO模型 &#x2F;&#x2F;YOLO模型官网：https://pjreddie.com/darknet/yolo/&#x2F;&#x2F;选讲tiny YOLO v1模型，由9个卷积层和3个全连接层组成，每个卷积层都由卷积层、LeakyRelu和Max Pooling操作组成，前9个卷积层可被理解为特征提取器，最后三个全连接层可被理解为预测边界框的回归器。参考论文：You Only Look Once:Unified, Real-Time Object Detection参考实例：https://github.com/xslittlegrass/CarND-Vehicle-Detection模型参数：45089374深度学习框架：Keras 1.2.2 &#x2F;&#x2F;构建YOLO模型网络结构import keras from keras.models import Sequential from keras.layers.convolutional import Convlution2D, MaxPooling2D from keras.layers.advanced_activations import LeakyReLU from keras.layers.core import Flatten, Dense, Activation, Reshape from utils import load_weights, Box, yolo_net_out_to_car_boxes, draw_box def construct_yolo_model(): keras.backend.set_image_dim_ordering(&#39;th&#39;) model = Sequential() model.add(Convolution2D(16, 3, 3, input_shape=(3, 448, 448), border_mode=&#39;same&#39;, subsample=(1, 1))) model.add(LeakyReLU(alpha=0.1)) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Convolution2D(32, 3, 3, border_mode=&#39;same&#39;)) model.add(LeakyReLU(alpha=0.1)) model.add(MaxPooling2D(pool_size=(2, 2), border_mode=&#39;valid&#39;)) model.add(Convolution2D(32, 3, 3, border_mode=&#39;same&#39;)) model.add(LeakyReLU(alpha=0.1)) model.add(MaxPooling2D(pool_size=(2, 2), border_mode=&#39;valid&#39;)) model.add(Convolution2D(64, 3, 3, border_mode=&#39;same&#39;)) model.add(LeakyReLU(alpha=0.1)) model.add(MaxPooling2D(pool_size=(2, 2), border_mode=&#39;valid&#39;)) model.add(Convolution2D(128, 3, 3, border_mode=&#39;same&#39;)) model.add(LeakyReLU(alpha=0.1)) model.add(MaxPooling2D(pool_size=(2, 2), border_mode=&#39;valid&#39;)) model.add(Convolution2D(256, 3, 3, border_mode=&#39;same&#39;)) model.add(LeakyReLU(alpha=0.1)) model.add(MaxPooling2D(pool_size=(2, 2), border_mode=&#39;valid&#39;)) model.add(Convolution2D(512, 3, 3, border_mode=&#39;same&#39;)) model.add(LeakyReLU(alpha=0.1)) model.add(MaxPooling2D(pool_size=(2, 2), border_mode=&#39;valid&#39;)) model.add(Convolution2D(1024, 3, 3, border_mode=&#39;same&#39;)) model.add(LeakyReLU(alpha=0.1)) model.add(Convolution2D(1024, 3, 3, border_mode=&#39;same&#39;)) model.add(LeakyReLU(alpha=0.1)) model.add(Convolution2D(1024, 3, 3, border_mode=&#39;same&#39;)) model.add(LeakyReLU(alpha=0.1 model.add(Flatten()) model.add(Dense(256)) model.add(Dense(4096)) model.add(LeakyReLU(alpha=0.1)) model.add(Dense(1470)) model.summary() return model 注：网络的输入是形状为（3,448,448)的图像，其输出是一个1470维度的向量，它包含预测边界框、物体类别信息。1470矢量被分成三个部分，分别给出了所属类别概率、置信度和边框坐标。这三个部分进一步划分为49个小区域，与每个单元的预测相对应。输出向量信息组织方式：probability:49*20=980判断类别，20个类别confidence:49*2=98是否包含物体（0,1）box coordinates:49*8=392 (x_min,y_min,x_max,y_max),(c_x,c_y,w,h) 8.4.3车辆图像数据探索1.车辆视频数据预处理&#x2F;&#x2F;预处理及可视化图像def visualize_images(): imagePath = &#39;./test_images/test1.jpg&#39; image = plt.imread(imagePath) #去除顶部和底部图片 image_crop = image[300:650,500:,:] #将图片转换为模型所需要的输入格式 resized = cv2.resize(image_crop, (448, 448)) f1,(ax11,ax22,ax33) = plt.subplot(1, 3, figsize=(16, 6)) ax11.imshow(image) ax22.imshow(image_crop) ax33.imshow(resized) pylab.show() return resized 8.4.5迁移学习通过迁移学习加载使用Pre-trained YOLO模型进行行车检测。具体做法是将pre-trained模型中的权重加载进之前构造的模型结构中，官网提供的权重，可以通过脚本解析成Keras能够加载的格式。&#x2F;&#x2F;加载YOLO模型权重def load_model_weights(model): #预训练权重网址：https://pjreddie.com/darknet/yolo/ load_weights(model, &#39;./yolo-tiny.weights&#39;) &#x2F;&#x2F;加载模型权重的具体逻辑def load_weights(model, yolo_weight_file): data = np.fromfile(yolo_weight_file, np.float32) data = data[4:] index = 0 for layer in model.layers: shape = [w.shape for w in layer.get_weights()] if shape !=[]: kshape, bshape = shape bia = data[index:index+np.prod(bshape)].reshape(bshape) index += np.prod(bshape) ker = data[index:index:index+np.prod(kshape)].reshape(kshape) index += np.prod(kshape) layer.set_weights([ker, bia]) &#x2F;&#x2F;模型推断&#x2F;&#x2F;使用模型进行在线推断，预测出车辆区域def inference_image(model, resized): #转置 batch = np.transpose(resized, (2, 0, 1)) #将像素值变换到-1~1 batch = 2*(batch/255.) - 1 #将一张图片转为数组 batch = np.expand_dims(batch, axis=0） out = model.predict(batch) return out &#x2F;&#x2F;绘制检测结果&#x2F;&#x2F;将上述的预测结果转换为边框坐标，同时基于阈值进行预测th = 0.17 boxes = yolo_net_to_out_to_car_boxes(out[0], threshold=th) &#x2F;&#x2F;定义box边框对象，判断是否保留预测的边框结果通过c,在图像上绘制车辆位置通过对象中的坐标信息#定义box类，存储边框信息和物体检测类别等信息class Box: def __init__(self): #x, y轴坐标 self.x, self.y = float(), float() #边框宽度和长度 self.w, self.h = float(), float() #置信度 self.c = float() #所属类别概率 self.prob = float() &#x2F;&#x2F;通过yolo_net_to_out_to_car_boxes方法，将预测出的Vector转换为Box对象信息。其核心逻辑是解析模型预测输出向量中的坐标、类别和置信度信息&#x2F;&#x2F;置信度大于阈值边界框则进行保留class_num = 6 #yolo模型可以预测多种类别，6为车辆所属类别 p = probs[grid, :] *bx.c if p[class_num]&gt;=threshold: bx.prob = p[class_num] boxes.append(bx) &#x2F;&#x2F;将结果绘制在图像上def visualize_image_car_detection(boxes): imagePath = &#39;./test_images/test1.jpg&#39; image = plt.imread(imagePath) f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6)) ax1.imshow(image) ax2.imshow(draw_box(boxes, plt.imread(imagePath), [[500, 1280],[300,650]])) pylab.show() &#x2F;&#x2F;将边框绘制在图像上def draw_box(boxes, im, crop_dim): imgcv = im [xmin, xmax] = crop_dim[0] [ymin, ymax] = crop_dim[1] for b in boxes: h, w, _ = imgcv.shape left = int((b.x-b.w/2.)*w) right = int((b.x+b.w/2.)*w) top = int((b.y-b.h/2.)*h) bot = int((b.y+b.h/2.)*h) left = int(left*(xmax-xmin)/w+xmin) right = int(right*(xmax-xmin)/w+xmin) top = int(top*(ymax-ymin)/h+ymin) bot = int(bot*(ymax-ymin)/h+ymin) if left&lt;0 : left=0 if right&gt;w-1 : right=w-1 if top&lt;0 : top=0 if bot&gt;h-1 : bot=h-1 thick = int((h+w)//150) cv2.rectangle(imgcv, (left, top), (right, bot), (255,0,0), thick) return imgcv 8.5.1英伟达End to End模型End to End的好处：通过缩减人工预处理和后续处理，尽可能使模型从原始输入到输出，使得其根据网络模型能够有足够多的空间进行自动调节，从而减少基于规则的复杂变化。缺点：可解释性较差，准确度和精度不容易受控制。&#x2F;&#x2F;构建英伟达模型import tensorflow as tf import keras from keras.models import Sequential from keras.layers import Dense, Activation, Flatten, Lambda from keras.layers import Conv2D, Dropout from keras import losses def nvida_model(): model = Sequential() model.add(Lambda(lambda x: x/127.5-1., input_shape=(img_height, img_width, img_channels))) model.add(Conv2D(24, kernel_size=(5, 5), strides=(2, 2), padding=&#39;valid&#39;, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;)) model.add(Conv2D(36, kernel_size=(5, 5), strides=(2, 2), padding=&#39;valid&#39;, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;)) model.add(Conv2D(48, kernel_size=(5, 5), strides=(2, 2), padding=&#39;valid&#39;, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;)) model.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding=&#39;valid&#39;, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;)) model.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding=&#39;valid&#39;, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu model.add(Flatten()) model.add(Dense(1164, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;)) model.add(Dense(100, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;)) model.add(Dense(50, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;)) model.add(Dense(10, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;)) model.add(Dense(1, kernel_initializer=&#39;he_normal&#39;)) model.compile(loss=&#39;mse&#39;, optimizer=&#39;Adadelta&#39;) return model &#x2F;&#x2F;8.5.3数据分析1）转向控制数据分布#绘制转向分布def steering_distribution(): wheel_sig = pd.read_csv(params.data_dir+&#39;/epoch01_steering.csv&#39;) wheel_sig.head() wheel_sig.wheel.hist(bins=50) 2)数据变化幅度#绘制转向变化幅度def angel_visualize(): wheel_sig = pd.read_csv(params.data_dir+&#39;/epoch01_steering.csv&#39;) wheel_sig.plot(x=&#39;frame&#39;, y=&#39;wheel&#39;) plt.show() 8.5.4读入视频，并处理图像&#x2F;&#x2F;使用OpenCV从视频中提取图像，以及与其对应的转向角度并返回#提取图像并处理imgs = [] wheels = [] epochs = [10] for epoch in epochs: vid_path = utils.join_dir(params.data_dir, &#39;epoch&#123;:0&gt;2&#125;_front.mp4&#39;.format(epoch)) assert os.path.isfile(vid_path) frame_count = frame_count_func(vid_path) cap = cv2.VideoCapture(vid_path) for frame_id in range(frame_count): while True: #通过OpenCV中的VideoCapture进行视频中图像的提取 ret, img = cap.read() if not ret: break #用户可以自定义对图像的处理、扩展和增强操作 img = a_image_convert.img_preprocess(img, color_mode, flip=False) imgs.append(img) csv.path = os.path.join(data_dir, &#39;epoch&#123;:0&gt;2&#125;_steering.csv&#39;.format(epoch)) rows = pd.read_csv(csv.path) yy = rows[&#39;wheel&#39;].values wheels.extend(yy) cap.release() imgs = np.array(imgs) wheels = np.array(wheels) wheels = np.reshape(wheels, (len(wheels), 1) return imgs, wheels 8.5.5深度学习模型构建与训练&#x2F;&#x2F;训练模型def training(model, X_train_RGB, y_train_RGB): RGB_model = model time_start = time.time() #fit the model RGB_history = RGB_model.fit(X_train_RGB, y_train_RGB, epochs=30, batch_size=batch_size) return RGB_model, RGB_history &#x2F;&#x2F;可视化结果#将训练过程中的loss误差进行可视化def visualize_label(RGB_history): print(RGB_history.history[&#39;loss&#39;] plt.figure(figsize=(9, 6)) plt.plot(RGB_history.history[&#39;loss&#39;]) plt.title(&#39;model loss&#39;) plt.ylabel(&#39;Loss&#39;, fontsize=12) plt.xlabel(&#39;Epoch&#39;, fontsize=12) plt.legend([&#39;train RGB&#39;], loc=&#39;upper right&#39;) plt.grid() plt.show() &#x2F;&#x2F;可视化&#x2F;&#x2F;数据的绘图过程就是将前面所得到的一系列数据，通过静态、动态的二维、三维图形进行展示1.Matplotlib&#x2F;&#x2F;绘制y&#x3D;sinx图像import numpy as np import matplotlib.pyplot as plt x = np.linspace(0, 4*np.pi, 1000) y = np.sin(x) plt.plot(x,y) &#x2F;&#x2F;利用API,绘制更加审美要求的图像import numpy as np import matplotlib.pyplot as plt import matplotlib as mpl #设置图片风格 mpl.style.use(&#39;seaborn-darkgrid&#39;) #定义曲线 x = np.linspace(0, 4*np.pi, 100) y1 = np.sin(x) y2 = np.sin(x+1) y3 = np.sin(x+2) #绘图 plt.plot(x, y1, color=&#39;#009900&#39;, lw=6, alpha=0.6) plt.plot(x, y2, color=&#39;#990000&#39;, lw=6, alpha=0.6) plt.plot(x, y3, color=&#39;#000099&#39;, lw=6, alpha=0.6) #展示 plt.show() 9.4ECharts&#x2F;&#x2F;ECharts提供了常规的折线图、柱状图、散点图、饼图、K线图等等，功能强大。&#x2F;&#x2F;ECharts图形绘制略 &#x2F;&#x2F;文本向量化&#x2F;&#x2F;文本向量化函数#文本TfIdf向量化from sklearn.feature_extraction.text import TfidfVectorizer vectorizer = TfidVectorizer() vectors = vectorizer.fit_transform(datas) &#x2F;&#x2F;文本向量化的数据进行降维&#x2F;&#x2F;LDA降维from sklearn.decomposition import LatentDirichletAllocation lda = LatenDirichletAllocation(n_components=n_topic, max_iter=5, learning_method = &#39;online&#39;, learning_offset = 50., radom_state = 0)#用LDA方法降维数据dr_vectors = lad.fit_transform(vectors) 9.6三维可视化&#x2F;&#x2F;ECharts地图柱状图myChart.setOption(&#123; visualMap: &#123; show: flase, calculable: true, realtime: false, inRange: &#123; color: [&#39;#313695&#39;, &#39;#4575b4&#39;, &#39;#74add1&#39;, &#39;#abd9e9&#39;, &#39;#e0f3f8&#39;, &#39;#ffffbf&#39;, &#39;#fee090&#39;, &#39;#fdae61&#39;, &#39;#f46d43&#39;, &#39;#d73027&#39;, &#39;#d73027&#39;, &#39;a50026&#39;] &#125;, outOfRange: &#123; colorAlpha: 0 &#125;, max: linedata[1] &#125;, ... series: [&#123; type: &#39;bar3D&#39;, shading: &#39;realistic&#39;, coordinateSystem: &#39;mapbox&#39;, barSize: 0.2, silent: true, data: linedata[0] &#125;] &#125;); &#x2F;&#x2F;利用Matplotlib完成对三维数据的可视化任务from mpl_toolkits.mplot3d import axes3d import matplotlib.pyplot as plt from matplotlib import cm import matplotlib.style as style style.use(&#39;seaborn-darkgrid&#39;) #定义三维画布fig = plt.figure() ax = fig.gca(projection=&#39;3d&#39;)#获取数据X, Y, Z = axes3d.get_test_data(0.05)#绘制surfaceax.plot_surface(X, Y, Z, rstride=8, cstride=8, alpha=0.3)#绘制等值线cst = ax.contourf(X, Y, Z, zdir=&#39;z&#39;, offset=-100, cmap=cm.coolwarm) cst = ax.contourf(X, Y, Z, zdir=&#39;x&#39;, offset=-40, cmap=cm.coolwarm) cst = ax.contourf(X, Y, Z, zdir=&#39;y&#39;, offset=40, cmap=cm.coolwarm) plt.show() 9.7动态可视化&#x2F;&#x2F;Matplotlib中用于数据动态演示的方法为animation,其可以通过函数进行简单的调用，以进行动态图形的演示工作&#x2F;&#x2F;动画展示import matplotlib.animation as animation animation.FuncAniamtion( ... ) &#x2F;&#x2F;动态可视化的展示方式是在普通的图表之上通过不断地修改数据并进行展示，这种修改可以通过setOption而得到的，在实现上可以通过函数递归的方式实现动态数据的可视化工作function update()&#123; myChart.setOption(...); setTimeout(update, UPDATE_DURATION); &#125; update(); &#x2F;&#x2F;优化实践10.1通用深度神经网络训练优化建议 1）通用的较为优化的训练过程1.将问题转换为相似的经典问题场景，参照paper中的配置和调优技巧进行最初的实验与优化2.优化算法：选用随机梯度下降（SGD)算法，虽然批量梯度下降（BGD)相比SGD有一些优势，但是在处理大规模数据时，SGD及其优化变种更加简单和快速。3.随机Shuffle样本：应尽量避免连续处理的样本属于同一类别的情况。尽量选择当前样本能让模型产生较大的误差，而不是较小的误差4.规范化数据：输入的每个变量均值最好趋近于0.变换输入变量，使其协方差相近，变量间尽量不要相关5.激活函数的选取：相比Sigmoid函数，tanh和Relu有更好的收敛速度。6.权重初始化：可以随机通过一种分布，均值为0.7.选择学习率：每个权重都可以选取属于自己的学习率。处于低层的权重学习率最好大于高层的权重学习率。学习率最好正比于每个单元的输入数量。 2）CNN训练过程中通常关注的优化点和参数一般比较关注：Learning Rate,Weight Decay,Momentum,Batchsize,Init Weights,数据增强eg:在Resnet中，使用SGD优化算法优化方法训练，mini-batch的大小设置为256，学习率初始化为0.1.随着训练进行，当Loss不再下降，会每次自适应以10倍进行缩减学习率。模型训练用了60x10^4轮迭代。Weight Decay设置为0.0001，同时设置momentum为0.9 3)RNN训练过程中通常关注的优化点和参数一般比较关注：SGD,正则化，规范化梯度，Pad Sentence,Init Weight, Batch Size, Embedding输入，输出控制，Vacabulary Size, Sampled Softmaxeg:Google发布的TTS模型TACOTRON为例 10.1.1 过拟合和欠拟合欠拟合：若训练集和测试集的误差有收敛但很高时，则为高偏差过拟合：若训练集和测试集的误差较大时，则为高方差 解决过拟合的方法：正则化，数据增强，Early Stop, Dropout, Batch Normalization 解决欠拟合的方法：1.使用更加复杂的深度学习网络架构2.添加其他特征项，有时候模型出现欠拟合的情况是因为特征项不够导致的，可以添加其他特征项来很好的解决这个问题3.减少正则化参数和组件，正则化的目的是用来防止过拟合。 10.1.2数据增强&#x2F;&#x2F;数据增强的根本原因在于机器在学习的过程中会在模型中遇到大量的参数，同时为了防止过拟合1）对于图像数据，可采取：1.图像平移：使得网络学习到平移不变的特性2.图像旋转：使得网络学习到旋转不变的特性3.图像亮度变化4.裁剪5.缩放6.图像模糊:用不同的卷积模板产生模糊图像2）语音识别中对输入数据添加随机噪声等方式3）NLP中最常用的方式就是进行近义词替换等方式4）噪声注入，可以对输入添加噪声，也可以对隐藏层或者输出层添加噪声 10.1.3梯度消失&#x2F;&#x2F;实验数据显示了深度神经网络在训练过程中，随着epoch的增加各隐藏层的学习率变化。前面隐藏层的学习速度要低于后面的隐藏层&#x2F;&#x2F;梯度消失的原因：根据链式法则，如果每一层神经元对上一层输出的偏导乘上权重结果都小于1的话，那么即使这个结果是0.99，在经过足够多层的传播后，误差对输入层的偏导也会趋近于0解决梯度消失的策略：1.BN2.RNN中使用LSTM:适用于RNN,门控制和长时记忆可缓解和解决梯度消失问题3.激活函数Relu:新的激活函数解析性质更好，其在一定程度上克服了sigmoid函数和tanh函数的梯度消失问题。4.在RNN反向传播过程中减少时间步长度。 10.1.4初始化权重&#x2F;&#x2F;在参数解空间内，好的权重初始化方式，意味着离全局最小值更近。1.高斯初始化，为权重初始化较小的值，权重按照高斯分布随机进行初始化，固定均值和方差2.Xaiver更新方法，使用tanh为激活函数，效果较好。进行梯度更新时，收敛速度较快，然而没有考虑Relu3.MSRA方法，适用于从头训练深层深度神经网络的网络结构。权重以高斯分布随机进行初始化，方差需要考虑空间过滤器的大小和过滤器数量的影响。 10.1.5优化算法近些年最常用的是采用Adam优化算法，也可以采用自适应学习率的方法实现快速收敛。 10.1.6超参数选择一些实践经验：1.在验证集上进行调参2.优先调Learning Rate3.通过初期设计卷积层尽量深、卷积核尽量多的模型，强行让模型拟合训练集，这时会出现过拟合，之后通过Dropout、正则化和Data Augument等等方式去改善模型结果4.调整模型的层数和卷积核数量 &#x2F;&#x2F;通过Scikit-learn的网格搜索库进行参数调优实例1.常见搜索参数学习率、Dropout、Epochs和神经元数量2.数据集下载数据集为Pima Indians Onset of Diabetes分类数据集下载地址：https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/3.搜索最优batchsize和epochs&#x2F;&#x2F;以20的步长，从10到100逐步评估不同的微型批尺寸，epochs分别设置为10、50、100import numpy from sklearn.grida_search import GridSearchCV from keras.models import Sequential from keras.layers import Dense from keras.wrappers.scikit_learn import KerasClassifier #Function to create model, required for KerasClassifierdef create_model(): #create model model = Sequential() model.add(Dense(12, input_dim=8, activation=&#39;relu&#39;)) model.add(Dense(1, activation=&#39;sigmoid&#39;)) #compile model model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;]) return model #fix random seed for reproducibility seed = 7 numpy.random.seed(seed) #load dataset dataset = numpy.loadtxt(&quot;pima-indians-diabetes.csv&quot;, delimiter=&#39;,&#39;) #split into input (x) and output (Y) variables X = [:, 0:8] Y = [:, 8] #create model model = KerasClassifier(build_fn=create_model, verbose=0) #define the grid search parameters batch_size = [10, 20, 40, 60, 80, 100] epochs = [10, 50, 100] param_grid = dict(batch_size=batch_size, nb_epoch=epochs) grid = GridSearchCV(estimator=model, param_grid=parm_grid, n_jobs=-1) grid_result = grid_fit(X,Y) #summarize results print(&quot;Best: %f using %s&quot; % (grid_result.best_score_, grid_result.best_params)) for params, mean_score, scores in grid_result.grid_scores_: print(&quot;%f (%f) with: %r&quot; % (scores.mean(), scores.std(), params)) 10.2深度学习系统性能优化建议10.2.1输入及预处理流水线优化输入流水线：从磁盘读取图像，将JPEG预处理为张量，进行数据预处理裁剪、翻转等，然后进行批处理操作1.在CPU端进行预处理&#x2F;&#x2F;在CPU端上放置输入预处理操作可以显著提高性能，GPU专注训练&#x2F;&#x2F;控制代码在CPU端执行with tf.device(&quot;/cpu:0&quot;): # function to get and process data. ​ distored_inputs = load_and_preprocess_images() 2.使用大文件读取大量的小文件会显著影响I&#x2F;O性能1）转换为TFRecord格式2）小数据集加载到内存 10.2.2数据格式NHWC的方存局部性更好（每三个输入像素即可得到一个输出像素），NCHW则必须等所有通道输入都准备好后才能得到最终的输出结果，需要占用较大的临时空间。tf默认NHWC格式，Nvidia cuDNN默认NCHW格式注：设计网络时充分考虑这两种格式，最好能够灵活切换，在GPU上训练时使用NCHW格式，在CPU上做预测时使用NHWC格式 10.2.3编译优化&#x2F;&#x2F;通过bazel命令对特定平台对tf进行编译bazel build -c opt --copt=-march=&quot;brodewell&quot; --config=cuda //tensorflow/tools/pip_package:build_pip_package 10.2.4GPU性能瓶颈诊断&#x2F;&#x2F;参考如下分析步骤对作业进行优化1）对代码进行性能分析2）找到运行慢的阶段3）分析慢的原因4）修改成更快的实现5）再次对代码进行性能分析 &#x2F;&#x2F;处理器有两个关键的性能瓶颈：浮点计算量和内存吞吐量。&#x2F;&#x2F;可通过以下工具进行深度学习作业的性能分析1.Tensorflow性能分析工具Timeline(获取执行图中每个节点的执行时间）1）创建metadata运行时对象2）获取运行时信息创建Timeline对象3）将Timeline对象写入json文件4）Chrome加载trace的json文件 &#x2F;&#x2F;tensorflow使用Timeline进行性能分析import tensorflow as tf from tensorflow.python.client import timeline x = tf.random_normal([1000, 1000]) y = tf.random_normal([1000, 1000]) res = tf.matmul(x, y) #run the graph with full trace option with tf.Session() as sess: run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE) run_metadata = tf.RunMetadata() sess.run(res, options=run_options, run_metadata=run_metadata) #create Timeline variable，then write it into json file t1 = timeline.Timeline(run_metadata.step_stats) ctf = t1.generate_chrome_trace_format() with open(&#39;timeline.json&#39;, &#39;w&#39;) as f: f.write(ctf) 可以打开谷歌chrome浏览器，转到chrome:&#x2F;&#x2F;tracing页并加载timeline.json文件，接下来，可以进行程序的profiling 2.常用的GPU分析工具1）nvprof是英伟达性能分析工具2）nvvp则是带GUI的英伟达可视化性能分析工具 10.2.5CPU瓶颈优化1）多线程方式优化以下两个针对tensorflow的配置可以通过适配线程池进行CPU的性能优化intra_op_parallelism_threads：对tf操作符内部的任务进行并行化inter_op_parallelism_threads: 控制多个运算符之间的并行化运算&#x2F;&#x2F;多线程优化config = tf.ConfigProto() config.intra_op_parallelism_threads = 22 config.inter_op_parallelism_threads = 22 tf.session(config=config) 2)使用SIMD高级指令集参考tf官方文档的”Performance Guide”章节 10.2.6模型压缩模型小型化：从模型权重的角度进行压缩和从网络架构的角度进行压缩网络架构角度：提出新的网络结构或卷积方法进行压缩优化，如SqueezeNet, MobileNets等模型权重角度：一般是在已经训练好的模型上进行裁剪，然后fine-tuning到原有模型的准确率，一般的优化方式包括剪枝、权值共享、神经网络二值化等。 10.3工程实践建议10.3.1Model格式转换框架间的模型转换参考链接：1.https://github.com/ysh329/deep-learning-model-convertor2.https://github.com/Microsoft/MMdnn 10.3.2迁移学习（Transfer Learning)其思想是将训练好的模型参数迁移到新的模型来帮助新模型的训练和预测。 &#x2F;&#x2F;通过MNIST数据集04的数字训练一个模型，然后将模型迁移到59数据集上进行迁移学习1）在MNIST数据集上训练一个简单的卷积神经网络，只预测04的数字2）将训练好的预测04数据集的模型，应用到5~9数据集上。对模型冻结卷积层参数，Fine-Tuning全连接层。&#x2F;&#x2F;keras迁移学习实例from __future__ import print_function import datetime import keras from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Dropout, Activation, Flatten from keras.layers import Conv2D, MaxPooling2D from keras import backend as K now = datetime.datetime.now batch_size = 128 num_classes = 5 epochs = 5 #input images dimensions img_rows, img_cols = 28, 28 #number of convolutional filters to use filters = 32 #size of pooling area for max pooling pool_size = 2 #convolution kernel size kernel_size = 3 if K.image_data_format()==&#39;channels_first&#39;: input_shape = (1, img_rows, img_cols) else: input_shape = (img_rows, img_cols, 1) def train_model(model, train, test, num_classes): x_train = train[0].reshape((train[0].shape[0],)+input_shape) x_test = test[0].reshape((test[0].shape[0],)+input_shape) x_train = x_train.astype(&#39;float32&#39;) x_test = x_test.astype(&#39;float32&#39;) x_train /= 255 x_test /= 255 print(&#39;x_train shape:&#39;, x_train.shape) print(x_train.shape[0], &#39;train samples&#39;) print(x_test.shape[0], &#39;test samples&#39;) #convert class vectors to binary class matrics y_train = keras.utils.to_categorical(train[1], num_classes) y_test = keras.utils.to_categorical(test[1], num_classes) model.compile( loss = &#39;categorical_crossentropy&#39;, optimizer = &#39;adadelta&#39;, metrics = [&#39;accuracy&#39;] ) t = now() model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, verbose = 1, validation_data = (x_test, y_test)) print(&#39;Training time: %s&#39; %(now() -t)) score = model.evaluate(x_test, y_test, verbose=0) print(&#39;Test score:&#39;, score[0]) #the data,shuffled and spilt between train and test sets (x_train, y_train), (x_test, y_test) = mnist.load-data() #create two datasets one with digits below 5 and one with 5 and above x_train_lt5 = x_train[y_train&lt;5] y_train_lt5 = x_train[y_train&lt;5] x_test_lt5 = x_test[y_test&lt;5] y_test_lt5 = y_test[y_test&lt;5] x_train_get5 = x_train[y_train&gt;=5] y_train_get5 = y_train[y_train&gt;=5]-5 x_test_get5 = x_test[y_test&gt;=5] y_test_get5 = y_test[y_test&gt;=5]-5 #define two groups of layers:feature(convolutions) and classification(dense) feature_layers = [ Conv2D(filters, kernel_size, padding=&#39;valid&#39;, input_shape=input_shape), Activation(&#39;relu&#39;), Conv2D(filters, kernel_size), Activation(&#39;relu&#39;), MaxPooling2D(pool_size=pool_size), Dropout(0.5), Flatten()] classification_layers=[ Dense(128), Activation(&#39;relu&#39;), Dropout(0.5), Dense(num_classes), Activation(&#39;softmax&#39;)] #create complete model model = Sequential(feature_layers+classification_layers) #train model for 5-digit classification(0~4) train_model(model, (x_train_lt5, y_train_lt5), (x_test_lt5, y_test_lt5), num_classes) #freeze feature layers and rebuild model for l in feature_layers: l.trainable = False #transfer: train dense layers for new classification task(5~9) train_model(model, (x_train_gte5, y_train_get5), (x_test_get5, y_test_get5), num_classes) ​​​","categories":[],"tags":[]},{"title":"学术搜索网站集合","slug":"学术搜索网站导航","date":"2022-03-15T01:58:59.113Z","updated":"2022-03-26T01:55:30.522Z","comments":true,"path":"2022/03/15/CN/学术搜索网站导航/","link":"","permalink":"http://pistachio0812.github.io/2022/03/15/CN/%E5%AD%A6%E6%9C%AF%E6%90%9C%E7%B4%A2%E7%BD%91%E7%AB%99%E5%AF%BC%E8%88%AA/","excerpt":"","text":"搞学术研究的必不可少的就是论文，而且是大量的论文。因此，在这里我特意把我平时用到的积累到的论文搜索网站集中到了这里，后续遇到了其他的还会继续补充。 谷歌学术谷歌学术是一个可以免费搜索学术文章的Google网络应用。2004年11月，Google第一次发布了Google学术搜索的试用版。该项索引包括了世界上绝大部分出版的学术期刊， 可广泛搜索学术文献的简便方法。您可以从一个位置搜索众多学科和资料来源：来自学术著作出版商、专业性社团、预印本、各大学及其他学术组织的经同行评论的文章、论文、图书、摘要和文章。Google 学术搜索可帮助您在整个学术领域中确定相关性最强的研究。 相关页面如下： githubgithub于2008年4月10日正式上线，除了代码仓库托管及基本的Web管理界面以外，还提供了订阅、讨论组、文本渲染、在线文件编辑器、协作图谱（报表）、代码片段分享（Gist）等功能。目前，其注册用户已经超过350万，托管版本数量也是非常之多，其中不乏知名开源项目Ruby on Rails、jQuery、python等。 相关页面如下： CVPR国际计算机视觉与模式识别会议（CVPR）是IEEE一年一度的学术性会议，会议的主要内容是计算机视觉与模式识别技术。CVPR是世界顶级的计算机视觉会议（三大顶会之一，另外两个是ICCV和ECCV，近年来每年有约1500名参加者，收录的论文数量一般300篇左右。本会议每年都会有固定的研讨主题，而每一年都会有公司赞助该会议并获得在会场展示的机会。 相关页面如下： CVFCVF研究论文是由计算机视觉基金会提供的开放获取版本。除水印外，它们与接受的版本相同;最后发表的论文集可以在IEEE Xplore上找到。本材料的提出，以确保及时传播学术和技术工作。版权和其中的所有权利由作者或其他版权持有人保留。所有复制此信息的人都应遵守每个作者的版权所援引的条款和约束。 arXivarXiv是一个免费分发服务和开放获取的档案，涵盖物理、数学、计算机科学、定量生物学、定量金融学、统计学、电气工程和系统科学以及经济学领域的2,040,232篇学术文章。 paperswithcodePapers With Code代码论文的任务是创建一个免费和开放的资源与机器学习论文，代码，数据集，方法和评估表。我们相信，在NLP和ML的支持下，与社区合作是最好的。这个网站上的所有内容都是公开许可的CC-BY-SA(与维基百科一样)，每个人都可以贡献——寻找“编辑”按钮!我们还运营专门的门户网站，提供天文学、物理学、计算机科学、数学和统计学的论文代码。","categories":[],"tags":[]},{"title":"学习网站集合","slug":"学习网站集合","date":"2022-03-14T05:07:01.833Z","updated":"2022-03-26T10:51:27.449Z","comments":true,"path":"2022/03/14/en/学习网站集合/","link":"","permalink":"http://pistachio0812.github.io/2022/03/14/en/%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99%E9%9B%86%E5%90%88/","excerpt":"","text":"万门好课万门好课是一家提供多品类原创精品课程的在线教育平台 ，课程覆盖IT与互联网类、职业成长类、经济金融类、本科学习类等领域 。 整体课程定位侧重于“用户刚需”类课程，如语言版块的出国英语考试类课程、小语种培训课程，本科学习版块的各学科基础大课，以及特色的万门通识课程包括PS、化妆等。 网易云课堂网易云课堂立足于实用性的要求，网易云课堂与多家教育、培训机构建立合作，课程数量已达4100+，课时总数超50000,涵盖实用软件、IT与互联网、外语学习、生活家居、兴趣爱好、职场技能、金融管理、考试认证、中小学、亲子教育等十余大门类。 网易公开课网易公开课首批1200集课程上线，其中有200多集配有中文字幕。用户可以在线免费观看来自于哈佛大学等世界级名校的公开课课程，可汗学院，TED等教育性组织的精彩视频，内容涵盖人文、社会、艺术、科学、金融等领域。 力求为爱学习的网友创造一个公开的免费课程平台，借此向外界公开招聘兼职字幕翻译。 爱课程网爱课程网利用现代信息技术和网络技术， 面向高校师生和社会大众。提供优质教育资源共享和个性化教学资源服务，具有资源浏览、搜索、重组、评价、课程包的导入导出、发布、互动参与和“教”“学”兼备等功能。 粉笔网粉笔网是一个互联网教育平台，业务包含：公务员考试，考研、教师资格、事业单位、英语、建造、财会等技能培训；利用技术手段实现智能批改功能，并提供免费题库，供用户查阅学习，利用网络直播，进行线上授课，同时提供实物图书、试卷以及客户服务。","categories":[{"name":"学习网站","slug":"学习网站","permalink":"http://pistachio0812.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99/"}],"tags":[{"name":"学习网站","slug":"学习网站","permalink":"http://pistachio0812.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99/"}]},{"title":"计算机视觉单词","slug":"计算机视觉单词表","date":"2022-03-12T08:48:16.114Z","updated":"2022-04-09T14:21:45.562Z","comments":true,"path":"2022/03/12/CN/计算机视觉单词表/","link":"","permalink":"http://pistachio0812.github.io/2022/03/12/CN/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%8D%95%E8%AF%8D%E8%A1%A8/","excerpt":"","text":"计算机视觉单词表 artificial neural network,ANN 人工神经网络 perceptron 感知机，人工神经元 activation function 激活函数 rectified linear unit,RELU 修正线性单元 bias 偏置 loss function 损失函数 universal approximation theorem 万能逼近定理 one-hot encoding 独热编码 cross-entropy 交叉熵 dropout 丢弃 bagging 装袋 model averaging 模型平均 batch normalization 批归一化 backpropagation 反向传播 stochastic gradient descent,SGD 随机梯度下降 acquisition 学习，获得 integrate 整合，集成，合并 diverse 多样化的，不同的 tune 调优 curation 内容管理 projection 投影，预测 coherent 有条理的，连贯的 redundant 冗余的 entity 实体 synthetic 合成的，虚假的，不诚恳的 spammy 垃圾邮件式的，无聊的 crowdsourcing 众包 continuity 连续性，连贯性 manifold 多种多样的 inherent 固有的，内在的 pseudo 假的，仿冒的 ensemble 套 heuristic 启发式的；启发式教育法 erroneous 错误的，不正确的 resilient 有弹性的，可迅速恢复的 degraded 堕落的，退化的 converge 收敛，集中 outlier 离群值，异常值 violate 违反，违背 syntactic 语法的 cartesian 笛卡尔的 categorical 分类，绝对的 prune 修剪 param 停止 translation invariance 平移不变性 suppress 抑制，镇压，阻止 bidirectional 双向 tabular 扁平的，列成表格的 revenue 收入，税收 latency 延迟 harmonic 和声的，谐和的，音乐般的 harmonic mean 调和平均数 harmonic series 调和级数 rote 死记硬背，生搬硬套 bid 出价，投标 leaderboard 排行榜，通栏广告 minor 较小的，次要的，轻微的 contaminated 受污染的，弄脏的 tradeoff 权衡，折中 ensemble learning 集成学习 decompose 分解，使腐烂 intrinsic 内在的，固有的 notable 显要的，值得注意的；非常成功的，令人尊敬的 camouflaged 伪装的 facilitate 促进，使便利 overlap 与……重叠，部分地相同；重叠的部分，互搭量 threshold 入口，门槛，开始，极限，临界值 conjecture 猜测，推测 within 在……之内 oversample:过采样 trade off:权衡，卖掉，折中方案 ultimately:最后，根本，基本上 robotics：机器人学 areial:空中的，航空的，空气的 underperform:表现不佳，工作不如预期 crucial:重要的，决定性的 high-resolution:高分辨率的 deploy:配置，展开，部署 barely:仅仅，勉强，几乎不 tumor:肿瘤，肿块 diagnosis:诊断 inspection:检查，视察 defect:缺陷，缺点，不足之处 annotate:注释，作注解 address:地址，编址 potentially:可能地，潜在地 imply:意味，暗示，隐含 diversity:多样性，差异 generalize:概括，推广，使……一般化 portion:部分 crop:裁剪 merge:合并 align:匹配，排列，对齐，对准 mask:掩码，掩膜 cascade:小瀑布，串联，级联 fuse:融合，熔接，熔化 computational:计算的 overhead:经常性费用，运营费用 fraction:分数，部分，小部分，稍微 schematic illustration:示意图 respect to:关于，考虑 validate:验证，确认，使生效 stochastic:随机的，猜测的 decay 衰退，衰减 coefficient 系数，率 explicitly 明确地，明白地 outline 大纲，概要 distillation:蒸馏 curvature:曲率 stochastic 随机 variance 差异，方差 spectrum 光谱，频谱；范围 neat 灵巧的，整洁的；优雅的，平滑的 heterogenerous 由很多种类组成的 intricate 复杂的，错综的 arbitrary 任意的，武断的 vanilla 香草，比较原始的 sketch 示意图 incarnation 化身，典型 waive 放弃，搁置 shrinkage 收缩，皱缩，缩水; 跌价; 抽缩 alleviate 缓解，减轻 de-facto 事实上 corpus 文集，语料库 unprecedented 前所未有的 inductive 归纳的 empirical 经验主义的 allergic 过敏的，反感的 pollen 花粉 badminton 羽毛球运动 pharmacy 药房 jasmine 茉莉 latent 潜在的，潜伏的，潜意识的 prepend 预先考虑 embedding 编码 alternating 交互的 interpolation 插入，篡改，添写 de-duplicate 删除重复数据 suite 一套，套件 geometric 几何图形的，几何的 intermediate 中间的 fine-tuning 微调 appendix 附录 warmup 预热 least-squares regression 最小二乘回归 on-the-fly 匆匆忙忙地；在空中；（计）运行中 literature 文献 outperform 胜过，做的比……好 substantially 实质上；大体上；充分地 standard deviation 标准差 co-training 协同训练 boost 促进，增加 overtake 赶上，压倒，突然来袭 plateau 趋于平稳，进入停滞期 vanish 消失 versus 与 saturate 饱和的 principal 最主要的 plausible 貌似可信的，花言巧语的；貌似真实的，貌似有理的 sinusoidal 正弦曲线的 degree 程度 analogous 类似的 preliminary 初步的 manual 手动的，手工的 insight 洞察力，领悟 exponentially 以指数方式的 holistically 整体论地 unidirectional 单向性的 incorporate 包含，吸收，体现；把……合并 alleviate 减轻 shallow 浅的，肤浅的 discriminate 区分，辨别 coarser 粗糙的 granularity 间隔尺寸，粒度 derived 导出的，衍生的，派生的 predecessor 前任，前辈;(被取代的)原有事物，前身 cloze adj. 完形的；填充测验法的 cloze task 完形填空 recipe 秘诀，处方 distinctive 有特色的，与众不同的 unambiguously 不含糊地，明白地 intuitively 直观地；直觉地 trivially 琐细地，平凡地，无能地 mitigate 使缓和，使减轻 monolingual 单语的；仅用一种语言的；仅懂一种语言的 procedure 程序，手续，步骤 degenerate 使退化，恶化 de-facto (法)实际上的 explicitly 显式地 reformulate 重新构造 ensemble 全体，总效果 nontrivial 重要的，显著的 obstacle 阻碍，障碍 notorious 臭名昭著的，声名狼藉的 vanishing&#x2F;exploding gradients 梯度消失&#x2F;梯度爆炸 hamper 妨碍，束缚 degradation 退化，降级，堕落 thoroughly 完全地，彻底地 counterpart 副本，配对物 feasible 可行的，可能的 akin to 类似于 generic 类的，属性的; 一般的; 不受商标保护的; [生]属的，类的 retrieval 检索 quantization 量化 partial differential equations 偏微分方程 auxiliary 辅助的，备用的 Concurrent 并发的，同时发生的 asymptotically 渐近地 counterintuitive 违反直觉的 perturbations [流]扰动，不安 trial 测试 curse 咒骂，诅咒 estimation 评估，评价，判断 surrogate 代理的 prominent 突出的，显著的，卓越的，杰出的 thes 命题，论文 recalibrate 重新校准 pruning 剪枝 proxy 代理人，代表权 compound 加重; 使复杂化; 混合;混合的 criteria 标准，条件 panoptic 全景的 controversial 有争议的 problematic 有疑问的，有问题的 contrastive 对比的 intuitive 直觉的; 凭直觉获知的; 直观的 preserve 保存；保护；维持；腌；禁猎 intractable 棘手的；难治的；倔强的；不听话的 pretext 借口，托辞; 假象，掩饰 permutation 排列，置换 discrimination 区别对待; 鉴别力; 区别 shuffle 洗牌; 曳脚而行; 搬移; 搁置，随手放 neatness 整洁，干净 blur 模糊 permutation 排列，置换 infrared 红外线的 attenuation 衰减，衰变 tricky 棘手的，难对付的 plethora 过多，过剩 deluge 泛滥，淹没 elaborate 精心制作的，详尽的 repurpose 改换意图，重新 assistive 辅助性的 eliminate 消除 duplicate 重复的 coordinate 坐标 refreshingly 清爽地，有精神地，令人耳目一新地 millisecond 毫秒 implicitly 隐式地 delimiter 分隔符 diverge 分歧，相异 remedy 解决方法，纠正方法 deviation 偏差 coarse 粗糙的 begnign 无有害的，认为无关紧要的 malicious 恶意的，怀恨的 rigorous 严格的 outlier 离群值 deliberate 故意的；深思熟虑的；从容的 susceptible 易受影响的；易感动的；容许…的 leverage 利用 kinda 有点，有几分 centroid 形心，重心 exclusively 专门地，唯一地 collision 碰撞，警告 hint 暗示，示意 stand-alone （计算机）独立运行的；（公司、组织）独立的 photometric distortion 光度失真 geometric 几何失真 hue 色调 saturation 饱和度 superimpose 叠加 adjacent 相邻的 incorporate 包含，吸收；体现；把……合并 mimic 模仿 tentative 初步的 tackle 处理 cortex 皮层 factorization 因子分解，因式分解 compatible 兼容的 substantially 实质上；大体上；充分地 explicitly 明确地；明白地 reformulate v. 再制订；换种方式说（或表达） nontrival 重要的 notorious 声名狼藉的，臭名昭著的 aggregated 聚合的，合计的 cardinality 基数 acquisition 获得物 obscured 遮挡 out-of-view 看不见的 precedent 先前的 intuitive 直观的 overhead 开销 efficacy 功效，效力 hierarchical 分层的 foeval 视网膜中心的 iteratively 迭代地 salient 重点的 modality 形式，形态 in a conditional fashion 有条件的方式 squeeze 挤压 excitation 激励 self-contained 独立的，设备齐全的，沉默寡言的 aggregate 集合，聚集 superscript 上标 an apples to apples comparison 比较两个相近的事物 thoroughly 彻底地，完全地 conjecture 推测，猜测 auxiliary 辅助的 parentheses 圆括号，插入成分 nest 嵌套 the best of both worlds 两全其美 incur 带来（成本、花费）等；招致，遭受 decimal 十进位的，小数的 timestamp 时间戳 clause 从句，分句；（法律文件的）条款 overlap 重叠 coalesce 合并，联合 rollup 归纳，卷曲，袅袅上升 coarse-to-fine 由粗到细，由繁到简 tic-tac-toe 井字棋，圈叉游戏 overlay 覆在……上面，覆盖 cached 贮藏起来，高速缓存 eigen 特征，固有的 tremendous 巨大的，极好的 versus （比赛或诉讼中）以……为对手，与……竞争；与……相对，与……相比 delineating 描述，描绘 primitive 原始的 recalibrating 重新调整 magenta 洋红色 cyan 青绿色 pentagon 五边形 hexagon 六边形 diamond 菱形 line chart 折线图 flip 翻转 alias 别名 incurring 招致，遭受 ellipse 椭圆 tile 平铺，瓷砖 diversity 多样性 discard 丢弃 adequately 充分地，足够地","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2022-03-11T08:11:46.667Z","updated":"2022-03-14T04:42:29.621Z","comments":true,"path":"2022/03/11/CN/hello-world/","link":"","permalink":"http://pistachio0812.github.io/2022/03/11/CN/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"Hexo博客搭建","slug":"Hexo博客搭建","permalink":"http://pistachio0812.github.io/categories/Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://pistachio0812.github.io/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"Hexo","slug":"Hexo","permalink":"http://pistachio0812.github.io/tags/Hexo/"}]}],"categories":[{"name":"CV","slug":"CV","permalink":"http://pistachio0812.github.io/categories/CV/"},{"name":"MySQL","slug":"MySQL","permalink":"http://pistachio0812.github.io/categories/MySQL/"},{"name":"pytorch","slug":"pytorch","permalink":"http://pistachio0812.github.io/categories/pytorch/"},{"name":"github","slug":"github","permalink":"http://pistachio0812.github.io/categories/github/"},{"name":"Linux","slug":"Linux","permalink":"http://pistachio0812.github.io/categories/Linux/"},{"name":"学习网站","slug":"学习网站","permalink":"http://pistachio0812.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99/"},{"name":"Hexo博客搭建","slug":"Hexo博客搭建","permalink":"http://pistachio0812.github.io/categories/Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"Attention","slug":"Attention","permalink":"http://pistachio0812.github.io/tags/Attention/"},{"name":"Note","slug":"Note","permalink":"http://pistachio0812.github.io/tags/Note/"},{"name":"文档","slug":"文档","permalink":"http://pistachio0812.github.io/tags/%E6%96%87%E6%A1%A3/"},{"name":"使用指南","slug":"使用指南","permalink":"http://pistachio0812.github.io/tags/%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"},{"name":"github","slug":"github","permalink":"http://pistachio0812.github.io/tags/github/"},{"name":"Liunx system","slug":"Liunx-system","permalink":"http://pistachio0812.github.io/tags/Liunx-system/"},{"name":"学习网站","slug":"学习网站","permalink":"http://pistachio0812.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99/"},{"name":"博客搭建","slug":"博客搭建","permalink":"http://pistachio0812.github.io/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"Hexo","slug":"Hexo","permalink":"http://pistachio0812.github.io/tags/Hexo/"}]}