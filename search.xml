<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/2022/03/11/CN/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>博客搭建</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机视觉相关单词</title>
    <url>/2022/03/12/CN/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%8D%95%E8%AF%8D%E8%A1%A8/</url>
    <content><![CDATA[<p>artificial neural network,ANN        人工神经网络</p>
<p>perceptron        感知机，人工神经元</p>
<p>activation function        激活函数</p>
<p>rectified linear unit,RELU        修正线性单元</p>
<p>bias        偏置</p>
<p>loss function        损失函数</p>
<p>universal approximation theorem        万能逼近定理</p>
<p>one-hot encoding        独热编码</p>
<p>cross-entropy        交叉熵</p>
<p>dropout        丢弃</p>
<p>bagging        装袋</p>
<p>model averaging        模型平均</p>
<p>batch normalization        批归一化</p>
<p>backpropagation        反向传播</p>
<p>stochastic gradient descent,SGD        随机梯度下降</p>
<p>acquisition         学习，获得</p>
<p>integrate       整合，集成，合并</p>
<p>diverse         多样化的，不同的</p>
<p>tune          调优</p>
<p>curation        内容管理</p>
<p>projection      投影，预测</p>
<p>coherent         有条理的，连贯的</p>
<p>redundant        冗余的</p>
<p>entity          实体</p>
<p>synthetic     合成的，虚假的，不诚恳的</p>
<p>spammy     垃圾邮件式的，无聊的</p>
<p>crowdsourcing          众包</p>
<p>continuity        连续性，连贯性</p>
<p>manifold       多种多样的</p>
<p>inherent        固有的，内在的</p>
<p>pseudo     假的，仿冒的</p>
<p>ensemble         套</p>
<p>heuristic        启发式的；启发式教育法</p>
<p>erroneous        错误的，不正确的</p>
<p>resilient        有弹性的，可迅速恢复的</p>
<p>degraded        堕落的，退化的</p>
<p>converge        收敛，集中</p>
<p>outlier        离群值，异常值</p>
<p>violate        违反，违背</p>
<p>syntactic        语法的</p>
<p>cartesian        笛卡尔的</p>
<p>categorical        分类，绝对的</p>
<p>prune        修剪</p>
<p>param        停止</p>
<p>translation  invariance        平移不变性</p>
<p>suppress        抑制，镇压，阻止</p>
<p>bidirectional        双向</p>
<p>tabular        扁平的，列成表格的</p>
<p>revenue        收入，税收</p>
<p>latency        延迟</p>
<p>harmonic        和声的，谐和的，音乐般的</p>
<p>harmonic mean        调和平均数</p>
<p>harmonic series        调和级数</p>
<p>rote        死记硬背，生搬硬套</p>
<p>bid        出价，投标</p>
<p>leaderboard        排行榜，通栏广告</p>
<p>minor        较小的，次要的，轻微的</p>
<p>contaminated        受污染的，弄脏的</p>
<p>tradeoff        权衡，折中</p>
<p>ensemble learning        集成学习</p>
<p>decompose        分解，使腐烂</p>
<p>intrinsic        内在的，固有的</p>
<p>notable         显要的，值得注意的；非常成功的，令人尊敬的</p>
<p>camouflaged        伪装的</p>
<p>facilitate        促进，使便利</p>
<p>overlap:与……重叠，部分地相同；重叠的部分，互搭量</p>
<p>threshold:入口，门槛，开始，极限，临界值</p>
<p>conjecture:猜测，推测</p>
<p>within:在……之内</p>
<p>oversample:过采样</p>
<p>trade off:权衡，卖掉，折中方案</p>
<p>ultimately:最后，根本，基本上</p>
<p>robotics：机器人学</p>
<p>areial:空中的，航空的，空气的</p>
<p>underperform:表现不佳，工作不如预期</p>
<p>crucial:重要的，决定性的</p>
<p>high-resolution:高分辨率的</p>
<p>deploy:配置，展开，部署</p>
<p>barely:仅仅，勉强，几乎不</p>
<p>tumor:肿瘤，肿块</p>
<p>diagnosis:诊断</p>
<p>inspection:检查，视察</p>
<p>defect:缺陷，缺点，不足之处</p>
<p>annotate:注释，作注解</p>
<p>address:地址，编址</p>
<p>potentially:可能地，潜在地</p>
<p>imply:意味，暗示，隐含</p>
<p>diversity:多样性，差异</p>
<p>generalize:概括，推广，使……一般化</p>
<p>portion:部分</p>
<p>crop:裁剪</p>
<p>merge:合并</p>
<p>align:匹配，排列，对齐，对准</p>
<p>mask:掩码，掩膜</p>
<p>cascade:小瀑布，串联，级联</p>
<p>fuse:融合，熔接，熔化</p>
<p>computational:计算的</p>
<p>overhead:经常性费用，运营费用</p>
<p>fraction:分数，部分，小部分，稍微</p>
<p>schematic illustration:示意图</p>
<p>respect to:关于，考虑</p>
<p>validate:验证，确认，使生效</p>
<p>stochastic:随机的，猜测的</p>
<p>decay:衰退，衰减</p>
<p>coefficient:系数，率</p>
<p>explicitly:明确地，明白地</p>
<p>outline:大纲，概要</p>
<p>distillation:蒸馏</p>
<p>curvature:曲率</p>
<p>stochastic:随机</p>
<p>variance:差异，方差</p>
<p>spectrum:光谱，频谱；范围</p>
<p>neat:灵巧的，整洁的；优雅的，平滑的</p>
<p>heterogenerous:由很多种类组成的</p>
<p>intricate:复杂的，错综的</p>
<p>arbitrary:任意的，武断的</p>
<p>vanilla:香草，比较原始的</p>
<p>sketch:示意图</p>
<p>incarnation:化身，典型</p>
<p>waive:放弃，搁置</p>
<p>shrinkage    收缩，皱缩，缩水; 跌价; 抽缩</p>
<p>alleviate    缓解，减轻</p>
<p>de-facto    事实上</p>
<p>corpus    文集，语料库</p>
<p>unprecedented    前所未有的</p>
<p>inductive    归纳的</p>
<p>empirical    经验主义的</p>
<p>allergic    过敏的，反感的</p>
<p>pollen     花粉</p>
<p>badminton    羽毛球运动</p>
<p>pharmacy    药房</p>
<p>jasmine    茉莉</p>
<p>latent    潜在的，潜伏的，潜意识的</p>
<p>prepend    预先考虑</p>
<p>embedding    编码</p>
<p>alternating    交互的</p>
<p>interpolation    插入，篡改，添写</p>
<p>de-duplicate    删除重复数据</p>
<p>suite    一套，套件</p>
<p>geometric    几何图形的，几何的</p>
<p>intermediate    中间的</p>
<p>fine-tuning    微调</p>
<p>appendix    附录</p>
<p>warmup    预热</p>
<p>least-squares regression    最小二乘回归</p>
<p>on-the-fly    匆匆忙忙地；在空中；（计）运行中</p>
<p>literature    文献</p>
<p>outperform    胜过，做的比……好</p>
<p>substantially    实质上；大体上；充分地</p>
<p>standard deviation    标准差</p>
<p>co-training    协同训练</p>
<p>boost    促进，增加</p>
<p>overtake    赶上，压倒，突然来袭</p>
<p>plateau    趋于平稳，进入停滞期</p>
<p>vanish    消失</p>
<p>versus     与</p>
<p>saturate    饱和的</p>
<p>principal    最主要的</p>
<p>plausible    貌似可信的，花言巧语的；貌似真实的，貌似有理的</p>
<p>sinusoidal    正弦曲线的</p>
<p>degree    程度</p>
<p>analogous    类似的</p>
<p>preliminary    初步的</p>
<p>manual    手动的，手工的</p>
<p>insight    洞察力，领悟</p>
<p>exponentially    以指数方式的</p>
<p>holistically    整体论地</p>
<p>unidirectional    单向性的</p>
<p>incorporate    包含，吸收，体现；把……合并</p>
<p>alleviate    减轻</p>
<p>shallow    浅的，肤浅的</p>
<p>discriminate    区分，辨别</p>
<p>coarser    粗糙的</p>
<p>granularity    间隔尺寸，粒度</p>
<p>derived    导出的，衍生的，派生的</p>
<p>predecessor    前任，前辈;(被取代的)原有事物，前身</p>
<p>cloze    adj. 完形的；填充测验法的</p>
<p>cloze task    完形填空</p>
<p>recipe    秘诀，处方</p>
<p>distinctive    有特色的，与众不同的</p>
<p>unambiguously    不含糊地，明白地</p>
<p>intuitively    直观地；直觉地</p>
<p>trivially    琐细地，平凡地，无能地</p>
<p>mitigate    使缓和，使减轻</p>
<p>monolingual    单语的；仅用一种语言的；仅懂一种语言的</p>
<p>procedure    程序，手续，步骤</p>
<p>degenerate    使退化，恶化</p>
<p>de-facto    (法)实际上的</p>
<p>explicitly    显式地</p>
<p>reformulate    重新构造</p>
<p>ensemble    全体，总效果</p>
<p>nontrivial    重要的，显著的</p>
<p>obstacle    阻碍，障碍</p>
<p>notorious    臭名昭著的，声名狼藉的</p>
<p>vanishing&#x2F;exploding gradients    梯度消失&#x2F;梯度爆炸</p>
<p>hamper    妨碍，束缚</p>
<p>degradation    退化，降级，堕落</p>
<p>thoroughly    完全地，彻底地</p>
<p>counterpart    副本，配对物</p>
<p>feasible    可行的，可能的</p>
<p>akin to     类似于</p>
<p>generic    类的，属性的; 一般的; 不受商标保护的; [生]属的，类的</p>
<p>retrieval    检索</p>
<p>quantization    量化</p>
<p>partial differential equations    偏微分方程</p>
<p>auxiliary    辅助的，备用的</p>
<p>Concurrent    并发的，同时发生的</p>
<p>asymptotically    渐近地</p>
<p>counterintuitive    违反直觉的</p>
<p>perturbations    [流]扰动，不安</p>
<p>trial    测试</p>
<p>curse    咒骂，诅咒</p>
<p>estimation    评估，评价，判断</p>
<p>surrogate    代理的</p>
<p>prominent    突出的，显著的，卓越的，杰出的</p>
<p>thes    命题，论文</p>
<p>recalibrate    重新校准</p>
<p>pruning    剪枝</p>
<p>proxy    代理人，代表权</p>
<p>compound    加重; 使复杂化; 混合;混合的</p>
<p>criteria    标准，条件</p>
<p>panoptic    全景的</p>
<p>controversial    有争议的</p>
<p>problematic    有疑问的，有问题的</p>
<p>contrastive    对比的</p>
<p>intuitive    直觉的; 凭直觉获知的; 直观的</p>
<p>preserve    保存；保护；维持；腌；禁猎</p>
<p>intractable    棘手的；难治的；倔强的；不听话的</p>
<p>pretext    借口，托辞; 假象，掩饰</p>
<p>permutation    排列，置换</p>
<p>discrimination    区别对待; 鉴别力; 区别</p>
<p>shuffle    洗牌; 曳脚而行; 搬移; 搁置，随手放</p>
<p>neatness    整洁，干净</p>
<p>blur    模糊</p>
<p>permutation    排列，置换</p>
<p>infrared    红外线的</p>
<p>attenuation    衰减，衰变</p>
<p>tricky    棘手的，难对付的</p>
<p>plethora    过多，过剩</p>
<p>deluge    泛滥，淹没</p>
<p>elaborate    精心制作的，详尽的</p>
<p>repurpose    改换意图，重新</p>
<p>assistive    辅助性的</p>
<p>eliminate    消除</p>
<p>duplicate    重复的</p>
<p>coordinate    坐标</p>
<p>refreshingly    清爽地，有精神地，令人耳目一新地</p>
<p>millisecond     毫秒</p>
<p>implicitly    隐式地</p>
<p>delimiter    分隔符</p>
<p>diverge    分歧，相异</p>
<p>remedy    解决方法，纠正方法</p>
<p>deviation    偏差</p>
<p>coarse    粗糙的</p>
<p>begnign    无有害的，认为无关紧要的</p>
<p>malicious    恶意的，怀恨的</p>
<p>rigorous    严格的</p>
<p>outlier    离群值</p>
<p>deliberate    故意的；深思熟虑的；从容的</p>
<p>susceptible    易受影响的；易感动的；容许…的</p>
<p>leverage    利用</p>
<p>kinda    有点，有几分</p>
<p>centroid    形心，重心</p>
<p>exclusively    专门地，唯一地</p>
<p>collision    碰撞，警告</p>
<p>hint    暗示，示意</p>
<p>stand-alone    （计算机）独立运行的；（公司、组织）独立的</p>
<p>photometric distortion    光度失真</p>
<p>geometric    几何失真</p>
<p>hue    色调</p>
<p>saturation    饱和度</p>
<p>superimpose    叠加</p>
]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>CV</tag>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>学习网站集合</title>
    <url>/2022/03/14/en/%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99%E9%9B%86%E5%90%88/</url>
    <content><![CDATA[<h2 id="万门好课"><a href="#万门好课" class="headerlink" title="万门好课"></a>万门好课</h2><p><a href="https://www.wanmen.org/" title="加油吧少年">万门好课</a>是一家提供多品类原创精品课程的在线教育平台 ，课程覆盖IT与互联网类、职业成长类、经济金融类、本科学习类等领域 。 整体课程定位侧重于“用户刚需”类课程，如语言版块的出国英语考试类课程、小语种培训课程，本科学习版块的各学科基础大课，以及特色的万门通识课程包括PS、化妆等。</p>
<h2 id="网易云课堂"><a href="#网易云课堂" class="headerlink" title="网易云课堂"></a>网易云课堂</h2><p><a href="https://study.163.com/">网易云课堂</a>立足于实用性的要求，网易云课堂与多家教育、培训机构建立合作，课程数量已达4100+，课时总数超50000,涵盖实用软件、IT与互联网、外语学习、生活家居、兴趣爱好、职场技能、金融管理、考试认证、中小学、亲子教育等十余大门类。</p>
<h2 id="网易公开课"><a href="#网易公开课" class="headerlink" title="网易公开课"></a>网易公开课</h2><p><a href="https://open.163.com/">网易公开课</a>首批1200集课程上线，其中有200多集配有中文字幕。用户可以在线免费观看来自于哈佛大学等世界级名校的公开课课程，可汗学院，TED等教育性组织的精彩视频，内容涵盖人文、社会、艺术、科学、金融等领域。 力求为爱学习的网友创造一个公开的免费课程平台，借此向外界公开招聘兼职字幕翻译。</p>
<h2 id="爱课程网"><a href="#爱课程网" class="headerlink" title="爱课程网"></a>爱课程网</h2><p><a href="https://www.icourses.cn/home">爱课程网</a>利用现代信息技术和网络技术， 面向高校师生和社会大众。提供优质教育资源共享和个性化教学资源服务，具有资源浏览、搜索、重组、评价、课程包的导入导出、发布、互动参与和“教”“学”兼备等功能。</p>
]]></content>
      <categories>
        <category>学习网站</category>
      </categories>
      <tags>
        <tag>学习网站</tag>
      </tags>
  </entry>
  <entry>
    <title>学术搜索网站集合</title>
    <url>/2022/03/15/CN/%E5%AD%A6%E6%9C%AF%E6%90%9C%E7%B4%A2%E7%BD%91%E7%AB%99%E5%AF%BC%E8%88%AA/</url>
    <content><![CDATA[<p>搞学术研究的必不可少的就是论文，而且是大量的论文。因此，在这里我特意把我平时用到的积累到的论文搜索网站集中到了这里，后续遇到了其他的还会继续补充。</p>
<h2 id="谷歌学术"><a href="#谷歌学术" class="headerlink" title="谷歌学术"></a>谷歌学术</h2><p><a href="https://xs.scqylaw.com/">谷歌学术</a>是一个可以免费搜索学术文章的Google网络应用。2004年11月，Google第一次发布了Google学术搜索的试用版。该项索引包括了世界上绝大部分出版的学术期刊， 可广泛搜索学术文献的简便方法。您可以从一个位置搜索众多学科和资料来源：来自学术著作出版商、专业性社团、预印本、各大学及其他学术组织的经同行评论的文章、论文、图书、摘要和文章。Google 学术搜索可帮助您在整个学术领域中确定相关性最强的研究。</p>
<p>相关页面如下：</p>
<p><img src="https://img.99lb.net/images1/logo.png" alt="谷歌学术搜索"></p>
<h2 id="github"><a href="#github" class="headerlink" title="github"></a>github</h2><p><a href="https://github.com/">github</a>于2008年4月10日正式上线，除了代码仓库托管及基本的Web管理界面以外，还提供了订阅、讨论组、文本渲染、在线文件编辑器、协作图谱（报表）、代码片段分享（Gist）等功能。目前，其注册用户已经超过350万，托管版本数量也是非常之多，其中不乏知名开源项目Ruby on Rails、jQuery、python等。</p>
<p>相关页面如下：</p>
<p><img src="https://pic2.zhimg.com/v2-3224a8e2da3f76575baaa77e5768fcb2_1440w.jpg?source=172ae18b" alt="github"></p>
<h2 id="CVPR"><a href="#CVPR" class="headerlink" title="CVPR"></a>CVPR</h2><p>国际计算机视觉与模式识别会议（<a href="http://www.cvpapers.com/">CVPR</a>）是IEEE一年一度的学术性会议，会议的主要内容是计算机视觉与模式识别技术。CVPR是世界顶级的计算机视觉会议（三大顶会之一，另外两个是ICCV和ECCV，近年来每年有约1500名参加者，收录的论文数量一般300篇左右。本会议每年都会有固定的研讨主题，而每一年都会有公司赞助该会议并获得在会场展示的机会。</p>
<p>相关页面如下：</p>
<p><img src="http://www.cvpapers.com/img/cvpapers.png" alt="CVPR"></p>
<h2 id="CVF"><a href="#CVF" class="headerlink" title="CVF"></a>CVF</h2><p><a href="https://openaccess.thecvf.com/">CVF</a>研究论文是由计算机视觉基金会提供的开放获取版本。除水印外，它们与接受的版本相同;最后发表的论文集可以在IEEE Xplore上找到。本材料的提出，以确保及时传播学术和技术工作。版权和其中的所有权利由作者或其他版权持有人保留。所有复制此信息的人都应遵守每个作者的版权所援引的条款和约束。</p>
<p>相关页面如下：</p>
<p><img src="https://raw.githubusercontent.com/pistachio0812/pistachio0812.github.io/main/images/cropped-cvf-s.jpg" alt="CVF"></p>
]]></content>
  </entry>
  <entry>
    <title>学习笔记</title>
    <url>/2022/03/17/en/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>tf中矩阵量存在形式常用有三种，具体如下：<br>1.tf.Variable()<br>表示神经网络中可变化的量（可以通过trainable&#x3D;False设置成不可变),可在运行中赋值，可以通过constant或者其他方式进行初始化。<br>2.tf.constant()<br>可以通过numpy中的array或者list,还有给定的shape和数值进行赋值<br>3.tf.placeholder()<br>相当于占位符，也是有shape的量，因为训练过程中需要不断赋值和替换值，而整体计算的结构是不变的。<br>代码：<br>&#x2F;&#x2F;导包</p>
<p><code>import tensorflow as tf    </code>    </p>
<p>&#x2F;&#x2F;定义变量<br><code>A = tf.Variable(tf.ones([4,4]))    </code></p>
<p>&#x2F;&#x2F;变量初始化<br><code>import numpy as np       cst = tf.constant(np.ones([4,4]),dtype=tf.float32)        </code><br>#需要指定类型dtype&#x3D;tf.float32,tf中不能隐式转换浮点和整型<br>#cst &#x3D; tf.constant(1.0,shape&#x3D;[4,4],dtype&#x3D;tf.float32)也是可以的<br><code>A = tf.Variable(cst)</code></p>
<p>&#x2F;&#x2F;定义placeholder<br><code>X = tf.placeholder(dtype=tf.float32,shape=[4,1])</code></p>
<p>&#x2F;&#x2F;矩阵相乘<br><code>C = tf.matmul(A,X)</code></p>
<p>&#x2F;&#x2F;定义Session<br><code>sess = tf.Session()</code></p>
<p>&#x2F;&#x2F;初始化变量<br><code>init = tf.global_variables_initializer()</code></p>
<p>&#x2F;&#x2F;执行初始化<br><code>sess.run(init)</code></p>
<p>&#x2F;&#x2F;运行矩阵相乘<br><code>sess.run(C,feed_dict=&#123;X:[[1],[1],[1],[1]]&#125;)</code></p>
<p>&#x2F;&#x2F;获取变量值<br><code>A_val = A.value()   Avalue = sess.run(A_val)</code></p>
<p>&#x2F;&#x2F;完整矩形相乘代码<br><code>import tensorflow as tf   import numpy as np</code></p>
<p><code>X = tf.placeholder(dtype=tf.float32,shape=[4,1])   A = tf.Variable(tf.zeros([4,4]))   C = tf.matmul(A,X)   sess = tf.session()   init = tf.global_variables_initializer()   sess.run(init)   print(sess.run(A))  </code></p>
<p>&#x2F;&#x2F;为了使计算图更加清晰，可以使用variable_scope()<br>&#x2F;&#x2F;定义变量名称<br><code>with  tf.variable_scope(&quot;first-nn-layer&quot;):     W = tf.Variable(tf.zeros([784,10]),name=&quot;W&quot;)     b = tf.Variable(tf.zeros([10]),name=&quot;b&quot;)     y = tf.matmul(x,W)+b     variable_summaries(W)</code></p>
<p>&#x2F;&#x2F;标识不同的变量<br>&#x2F;&#x2F;不同作用域下的同名变量<br><code>with tf.variable_scope(&quot;first-nn-layer&quot;):     W = tf.Variable(tf.zeros([784,10]),name=&quot;W&quot;)     b = tf.Variable(tf.zeros([10]),name=&quot;b&quot;)     W1 = tf.Variable(tf.zeros([784,10]),name=&quot;W&quot;) print(W.name) print(W1.name)</code><br>#w、w1虽然name一样，但是计算中依然当成不同的变量，让同一个scope的同一变量可以通过get_variable()函数</p>
<p>&#x2F;&#x2F;获取变量<br><code>with tf.variable_scope(&quot;first-nn-layer&quot;) as scope:     W = tf.get_variable(&quot;W&quot;,[784, 10])     b = tf.get_variable(&quot;b&quot;,[10])     scope.reuse_variables()#缺少则会报错     W1 = tf.get_variables(&quot;W&quot;,shape=[784,10]) print(W.name) print(W1.name)</code><br>#w、w1属于同一个变量</p>
<p>注：若此时缺少了scope.reuse_variables()则会报错，因为同时引用了同一个变量，对于不同层的变量，可以利用variable_scope进行区分，在再次引入相关变量时，需要加上reuse&#x3D;True,否则依然会报错。如果变量不存在时加上reuse&#x3D;True,依然会报错，因为该变量不存在</p>
<p><code>with tf.variable_scope(&quot;first-nn-layer&quot;) as scope:     W = tf.get_variable(&quot;W&quot;,[784, 10])     b = tf.get_variable(&quot;b&quot;,[10]) with tf.variable_scope(&quot;second-nn-layer&quot;) as scope:     W = tf.get_variable(&quot;W&quot;,[784, 10])     b = tf.get_variable(&quot;b&quot;,[10]) with tf.variable_scope(&quot;second-nn-layer&quot;, reuse=True) as scope:     W3 = tf.get_variable(&quot;W&quot;,[784, 10])     b3 = tf.get_variable(&quot;b&quot;,[10]) print(W.name) print(W3.name)</code></p>
<p>&#x2F;&#x2F;保存模型<br>&#x2F;&#x2F;定义saver<br><code>saver = tf.train.Saver()</code></p>
<p>&#x2F;&#x2F;在训练过程中进行保存，保存为训练过程中的变量<br>&#x2F;&#x2F;变量保存<br><code>for itr in range(1000):     ...     saver.save(sess,&quot;model/al&quot;,global_step=itr)</code></p>
<p>&#x2F;&#x2F;加载计算<br>&#x2F;&#x2F;变量载入<br><code>saver.restore(sess,&quot;model/v2-200&quot;)</code></p>
<p>3.4构建计算图<br>&#x2F;&#x2F;前面在描述计算图，这里观察所建立的计算图<br>&#x2F;&#x2F;定义summary<br><code>train_writer = tf.summary.FileWriter(&quot;logdir&quot;,sess.graph)</code></p>
<p>注：sess.graph就是描绘的计算图，”logdir”是log的存储文件夹。在Shell中运行Tensorboard,在浏览器中输入localhost:6006,然后点击graph就可以看到设计的网络模型了。</p>
<p>&#x2F;&#x2F;问题：描绘的计算图非常杂乱无章，变量命名的可读性很差，需要进行整理。<br>&#x2F;&#x2F;变量命名<br><code>x = tf.placeholder(tf.float32,[None,784],name=&quot;input_x&quot;) label = tf.placeholder(tf.float32,[None,10],name=&quot;input_label&quot;) W = tf.Variable(tf.zeros([874,10]),name=&quot;W&quot;) b = tf.Variable(tf.zeros([10]),name=&quot;b&quot;)</code></p>
<p>&#x2F;&#x2F;问题：依然不够清楚，可以将输入层的x和label归为一类<br>&#x2F;&#x2F;定义作用域<br><code>with tf.variable_scope(&quot;input&quot;):     x = tf.placeholder(tf.float32,[None,784],name=&quot;input_x&quot;)     label = tf.placeholder(tf.float32,[None,10],name=&quot;input_label&quot;) with tf.variable_scope(&quot;first-nn-layer&quot;):     W = tf.Variable(tf.zeros([784,10]), name=&quot;W&quot;)     b = tf.Variable(tf.zeros([10]),name=&quot;b&quot;)     y = tf.matmul(x,W)+b with tf.variable_scope(&quot;loss&quot;):     loss = tf.reduce_mean(tf.square(y-label))</code></p>
<p>&#x2F;&#x2F;同一作用域下的同名变量是相同的，涉及到变量复用的问题，以及后续变量的获取，为了观察变量的变化，需要观察的变量加入summary函数<br>&#x2F;&#x2F;定义summary函数<br><code>def variable_summaries(var):     with tf.name_scope(&#39;summaries&#39;):         mean = tf.reduce_mean(var)         tf.summary.scalar(&#39;mean&#39;,mean)         with tf.name_scope(&#39;stddev&#39;):             stddev = tf.sqrt(tf.reduce_mean(tf.square(var-mean)))         tf.summary.scalar(&#39;stddev&#39;,stddev)         tf.summary.scalar(&#39;max&#39;,tf.reduce_max(var))         tf.summary.scalar(&#39;min&#39;,tf.reduce_min(var))         tf.summary.histogram(&#39;histogram&#39;,var)</code></p>
<p>&#x2F;&#x2F;若要观测W的相关情况，调用summary函数<br>&#x2F;&#x2F;调用summary函数<br><code>variable_summaries(W)</code></p>
<p>&#x2F;&#x2F;再用merge_all函数收集summary信息<br>&#x2F;&#x2F;获取summary信息<br><code>merged = tf.summary.merge_all()</code></p>
<p>&#x2F;&#x2F;summary保存<br><code>summary = sess.run(merged, feed_dict=&#123;x:batch_xs,label:batch_ys&#125;) train_writer.add_summary(summary,itr)</code></p>
<p>注：此时可以在网页中访问，观察变量随迭代变化的情况，可以通过不同的方式对变量进行观测，比如时序统计、histogram,这些统计信息对于分析训练过程是非常重要的</p>
<p>3.5全连接网络构建<br>&#x2F;&#x2F;tf官方手写识别版本的简化版本<br>&#x2F;&#x2F;单层全连接网络<br>#引入库<br><code>from tensorflow.examples.tutorials.mnist import input_data#产生数据，手写识别的图片和标签 import tensorflow as tf</code></p>
<p>#获取数据<br><code>mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;,one_hot=True)</code><br>#构建网络模型<br>#x,label分别为图形数据和标签数据<br><code>x = tf.placeholder(tf.float32,[None,784]) label = tf.placeholder(tf.float32,[None,10])</code><br>#构建单层网络中的权值和偏置<br><code>W = tf.Variable(tf.zeros([784,10])) b = tf.Variable(tf.zeros([10])</code><br>#本例中无非线性激活函数<br><code>y = tf.matmul(x,W)+b</code><br>#定义损失函数为欧氏距离，但这并不是最好的，多分类问题通常使用交叉熵<br><code>loss = tf.reduce_mean(tf.square(y-label))</code><br>#若使用交叉熵损失函数<br><code>soft_max = tf.nn.softmax(logit, axis=1) loss = tf.reduce_mean(-label*tf.log(soft_max))</code><br>#用梯度迭代算法<br><code>train_step = tf.train.GradientDescentOptimizer(0.005).minimize(loss)</code><br>#用于验证<br><code>correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(label,1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float.32))</code><br>#定义会话<br><code>sess = tf.Session()</code><br>#初始化所有变量<br><code>sess.run(tf.global_variable_initializer())</code><br>#迭代过程<br><code>for itr in range(3000):     batch_xs,batch_ys = mnist.train.next_batch(100)     sess.run(train_step, feed_dict=&#123;x:batch_xs,label:batch_ys&#125;)     if itr%10==0:         print(&quot;step:%6d accuracy:&quot;%iter, sess.run(accuracy, feed_dict=&#123;x:mnist.test.images, label:mnist.test.labels&#125;))</code></p>
<p>#获取W取值<br><code>W_value = sess.run(W.value())</code></p>
<p>&#x2F;&#x2F;定义一个单层全连接函数<br><code>def full_layer(input_tensor, out_dim, name=&quot;full&quot;):     with tf.variable_scope(name):         shape = input_tensor.get_shape()as_list()         W = tf.get_variable(&#39;W&#39;,(shape[1],out_dim),dtype=tf.float32, initalizer=tf.truncated_normal_initializer(stddev=0.1))         b = tf.get_variable(&#39;b&#39;,[out_dim], dtype=tf.float32, initializer=tf.constant_initializer(0))         out = tf.matmul(input_tensor, W)+b     return tf.nn.sigmoid(nn)</code></p>
<p>3.6CNN构建<br>&#x2F;&#x2F;CNN手写识别<br>#预读取MNIST手写字库<br><code>from tensorflow.examples.tutorials.mnist import input_data   mnist = input_data.read_data_sets(&quot;MNIST_data&quot;,one_hot=True)</code></p>
<p><code>import tensorflow as tf</code><br>#用正态分布随机数初始化变量，本例中仅作为权值<br><code>def weight_variable(shape):     initial=tf.truncated_normal(shape,stddev=0.1)</code><br>    #正态分布<br>    <code>return tf.Variable(initial)</code><br>#用常量方式初始化偏置<br><code>def bias_variable(shape):     initial=tf.constant(0.1,shape=shape)</code><br>    #常数分布<br>       <code>return tf.Variable(initial)</code><br>#定义二维卷积的过程<br>def conv2d(x,W):<br>    return tf.nn.conv2d(x,W,strides&#x3D;[1,1,1,1],padding&#x3D;’SAME’)<br>#定义池化层，简单地说就是选个最大的数，进一步降低自由参数的个数<br><code>def max_pool_2x2(x):     return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=&#39;SAME&#39;)</code></p>
<p><code>x = tf.placeholder(tf.float32,shape=[100,784]) y = tf.placeholder(tf.float32,shape=[100,10])</code></p>
<p><code>W_conv1 = weight_variable([5,5,1,32]) b_conv1 = bias_variable([32]) x_image = tf.reshape(x,[-1,28,28,1]) y_conv1 = tf.nn.relu(conv2d(x_iamge,W_conv1)+b_conv1) y_pool1 = max_pool_2x2(y_conv1)</code></p>
<p><code>W_conv2 = weight_variable([5,5,32,64]) b_conv2 = weight_variable([64]) y_conv2 = tf.nn.relu(conv2d(y_pool1,W_conv2)+b_conv2) y_pool2 = max_pool_2x2(y_conv2)</code></p>
<p><code>y_fc_flat = tf.reshape(y_pool2,[-1,7*7*64]) W_fc1 = weight_variable([7*7*64,10]) b_fc1 = bias_variable([10]) y_fc1 = tf.nn.relu(tf.matmul(y_fc_flat,W_fc1)+b_fc1)</code></p>
<p><code>cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=y_fc1)) train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)</code></p>
<p><code>sess = tf.Session() init = tf.global_variables_initializer() sess.run(init)</code></p>
<p><code>for i in range(1000):     bx,by = mnist.train.next_batch(100)     sess.run(train_step,feed_dict=&#123;x:bx,y:by&#125;)</code></p>
<p><code>import numpy as np import matplotlib.pyplot as plt</code><br>#设置输出风格，为画图美观<br><code>import matplotlib  as mpl mpl.style.use(&#39;seaborn-darkgrid&#39;)</code></p>
<p><code>val = W_conv1.value() convVal = np.array(sess.run(val)) convVal = np.reshape(convVal,[5,5,32]) plt.imshow(convVal[:,:,6]) plt.show()</code></p>
<p>3.8多架构运行<br>&#x2F;&#x2F;GPU使用<br>GPU可以加速深度学习作业的训练速度，如果服务器有多个GPU,那么tensorflow默认使用全部<br>使用部分GPU:</p>
<p>python程序启动时调用：<br><code>CUDA_VISIBLE_DEVICES=0.2.3 python script.py</code></p>
<p>python代码内进行调用：<br><code>import os os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;]=&quot;1&quot;</code></p>
<p>&#x2F;&#x2F;配置GPU显存<br>某些情况下，多作业或者共享GPU的场景中，可以控制tf使用GPU显存大小<br><code>gpuOptions = tf.GPUOptions(per_process_gpu_memory_fraction=0.8) sess = tf.Session(config=tf.ConfigProto(gpu_options=gpuOptions))</code></p>
<p>&#x2F;&#x2F;GPU运行代码<br>#将变量的定义和分配定义到GPU上进行<br><code>with tf.device(&#39;/gpu:0&#39;):     W = tf.get_variable(&#39;W&#39;,(in_dim,out_dim),dtype=tf.float32,initializer=tf.truncated_normal_initializer(stddev=0.1))     b = tf.get_variable(&#39;b&#39;),[out_dim],dtype=tf.float32,initializer=tf.constant_initializer(0))     net = tf.matmul(input_tensor,W)+b</code><br>#在CPU上计算激活函数<br><code>with tf.device(&#39;/cpu:0&#39;):     net = tf.nn.sigmoid(net)</code></p>
<p>&#x2F;&#x2F;多CPU使用，多设备计算<br>&#x2F;&#x2F;利用标号简单的区分并运行<br>#在CPU0上计算<br><code>with tf.device(&#39;/cpu:0&#39;)     ...     net = tf.nn.sigmoid(net)</code><br>#在CPU1上计算<br><code>with tf.device(&#39;/cpu:1&#39;)     ...     net = tf.nn.sigmoid(net)</code></p>
<p>&#x2F;&#x2F;在集群上运行，需要在多个主机上准备多份代码，代码前面部分相同，后续有所不同<br>&#x2F;&#x2F;定义多主机运行参数<br>#这里的地址形式为IP:Port<br><code>cluster = tf.train.ClusterSpectf.train.ClusterSpec(&#123;     &quot;worker&quot;:[         &quot;xx.xx.xx.xx:2222&quot;,    #/job:worker/task:0         &quot;xx.xx.xx.xx:2222&quot;,    #这里job的名称为自定义         &quot;xx.xx.xx.xx:2222&quot;    #task编号同样需在Server中定义         ],     &quot;ps&quot;:[         &quot;xx.xx.xx.xx:2222&quot;,         &quot;xx.xx.xx.xx:2222&quot;         ]&#125;) server = tf.train.Server(cluster, job_name=&quot;worker&quot;, task_index=0)</code></p>
<p>&#x2F;&#x2F;定义第二个主机参数<br>#这里的地址形式为IP:Port<br><code>cluster = tf.train.ClusterSpectf.train.ClusterSpec(&#123;     &quot;worker&quot;:[         &quot;xx.xx.xx.xx:2222&quot;,    #/job:worker/task:0         &quot;xx.xx.xx.xx:2222&quot;,    #这里job的名称为自定义         &quot;xx.xx.xx.xx:2222&quot;    #task编号同样需在Server中定义         ],     &quot;ps&quot;:[         &quot;xx.xx.xx.xx:2222&quot;,         &quot;xx.xx.xx.xx:2222&quot;         ]&#125;) server = tf.train.Server(cluster, job_name=&quot;worker&quot;, task_index=1)</code></p>
<p>&#x2F;&#x2F;不同设备的运行代码<br><code>with tf.device(&#39;/job:worker/task:0/cpu:0&#39;):     ...</code></p>
<p>&#x2F;&#x2F;将不同的任务分配到不同的计算节点上<br>&#x2F;&#x2F;分配计算任务<br><code>with tf.device(tf.train.replica_device_setter(     worker_device=&quot;/job:worker/task:%d&quot; %task_index,cluster=cluster)</code></p>
<p>&#x2F;&#x2F;函数replica_device_setter会将变量参数的定义部分自动定义到ps服务中，后续需要定义Session,用于执行这个过程<br>&#x2F;&#x2F;多主机运行<br>#定义句柄，迭代多少步后停止迭代<br><code>hooks = [tf.train.StopAtStepHook(last_step=1000000)]</code><br>#MonitoredTrainingSession函数会完成会话初始化工作<br>#保存checkpoint,恢复checkpoint,异常判断等<br>#这里需要定义master主机，定义保存、控制操作的master<br><code>with tf.train.MonitroedTrainingSession(     master=server.target,     is_chief=(task_index==0),     checkpoint_dir=&quot;dir/to/cp&quot;,     hooks=hooks) as mon_sess:     ...</code></p>
<p>注：在程序运行过程中，需要认为将程序分配到各个主机上，依次运行各个主机</p>
<p>&#x2F;&#x2F;队列用于数据读取和处理，队列可以是先进先出队列，也可以是随机队列，用于随机化输出<br>&#x2F;&#x2F;tf中队列的操作是对于训练前的过程而言的，有以下作用<br>1.多线程数据预处理并将其推入队列<br>2.在执行过程中，队列不断提供训练数据<br>&#x2F;&#x2F;简单实例说明队列使用<br><code>def simple_shuffle_batch(source,capacity,batch_size=10):</code><br>    #定义随机序列<br>    <code>queue = tf.RandomShuffleQueue(         capacity=capacity,         min_after_dequeue=int(0.9*capacity),         shapes=source.shape,         dtypes=source.dtype)</code><br>    #定义enqueue过程<br>    <code>enqueue = queue.enqueue(source)</code><br>    #定义执行进程个数<br>    <code>num_threads = 4     qr = tf.train.QueueRunner(queue,[enqueue]*num_threads)</code><br>    #声明Queue runner,使得其可以被执行<br>    <code>tf.train.add_queue_runner(qr)</code><br>    #获取数据<br>    <code>return queue.dequeue_many(batch_size)</code><br>#产生测试数据<br><code>input = tf.constant(list(range(100))) input = tf.data.Dataset.from_tensor_slices(input) input = input.make_one_shot_iterator().get_next()</code></p>
<p>#定义函数<br><code>get_batch = simple_shuffle_batch(input,capacity=20)</code></p>
<p>#定义session<br><code>with tf.train.MonitoredSession() as sess:     while not sess.should_stop():         print(sess.run(get_batch))</code></p>
<p>注：队列操作可以使得数据读取过程得到并行的优化，这对于提升程序的运行速度是很有利的。</p>
<p>&#x2F;&#x2F;tf相关扩展<br>4.2.1 tf Layers<br>&#x2F;&#x2F;全连接网络<br>#layers定义全连接网络<br><code>net = tf.layers.dense(inputs=net, units=units, activation=tf.nn.relu)</code></p>
<p>#卷积网络<br><code>net = tf.layers.conv2d(     inputs=net, #输入     filters=n_features, #输出特征数     kernel-size=[5, 5], #卷积核心大小     padding=&quot;same&quot;, #边界     activation=tf.nn.relu #激活函数     )</code></p>
<p>&#x2F;&#x2F;前馈神经网络函数<br>#二维最大池化<br><code>net = tf.layers.max_pooling2d(...)</code><br>#二维平均池化<br><code>net = tf.layers.average_pooling2d(...)</code><br>#二维卷积<br><code>net = tf.layers.conv2d(...)</code><br>#dropout<br><code>net = tf.layers.dropout(...)</code><br>#展开<br><code>net = tf.layers.flatten(...)</code><br>#BN<br><code>net = tf.layers.batch_normalization(...)</code></p>
<p>4.2.2 tf Slim<br>#卷积函数<br><code>def conv2d_layer(input_tensor, size=1, feature=128, name=&#39;conv1d&#39;):     with tf.variable_scope(name):         shape = input_tensor.get_shape.as_list()         kernel = tf.get_variable(&#39;kernel&#39;, (size, size, shape[-1], feature), dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.1))         b = tf.get_variable(&#39;b&#39;, [feature], dtype=tf.float32, initializer=tf.constant_initializer(0))         out = tf.nn.conv2d(input_tensor, kernel, strides=[1,2,2,1],padding=&#39;SAME&#39;)+b     return tf.nn.relu(out)</code><br>#全连接函数<br><code>def full_layer(input_tensor, out_dim, name=&#39;full&#39;):     with tf.variable_scope(name):         shape = input_tensor.get_shape.as_list()         W = tf.get_variable(&#39;W&#39;, (shape[1], out_dim), dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.1))         b = tf.get_variabel(&#39;b&#39;, [out_dim], dtype=tf.float32, initializer=tf.constant_initializer(0))         out = tf.matmul(input_tensor, W)+b     return out</code></p>
<p>&#x2F;&#x2F;slim实现卷积，tfv2取消该库<br>#引入slim库<br><code>import tensorflow.contrib.slim as slim</code><br>#定义卷积层<br><code>net = slim.conv2d(inputs, 16, 4, strides=2, activation_fn=tf.nn.relu, scope=&#39;conv1&#39;)</code><br>#加入池化层<br><code>net = tf.nn.max_pool(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;SAME&#39;)</code></p>
<p><code>net = slim.conv2d(net, 32, 4, strides=2, activation_fn=tf.nn.relu, scope=&#39;conv2&#39;) net = tf.nn.max_pool(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;SAME&#39;)</code></p>
<p>#flatten层，用于将三维的图形数据展开成一维数据，用于全连接层<br><code>net = slim.flatten(net)</code><br>#全连接层<br><code>y = slim.fully_connected(net, 10, activation_fn=line, scope=&#39;full&#39;, reuse=False)</code></p>
<p>4.2.3 tfLearn<br>&#x2F;&#x2F;tflearn抽象层次更高，代码可读性更好,其是一个完整的生态<br>&#x2F;&#x2F;基础网络架构<br>#全连接<br><code>net = tflearn.fully_connected(...)</code><br>#卷积<br><code>net = tflearn.conv_2d(...)</code><br>#LSTM<br><code>net = tflearn.lstm(...)</code><br>#dropout<br><code>net = tflearn.dropout(...)</code></p>
<p>&#x2F;&#x2F;输入函数<br><code>network = tflearn.input_data(shape=[None, 28, 28, 1], name=&#39;input&#39;)</code></p>
<p>&#x2F;&#x2F;优化部分<br>#定义优化过程<br><code>network = tflearn.layers.estimator.regression(     network,     optimizer=&#39;adam&#39;, #优化方法     learning_rate=0.01, #学习率     loss=&#39;categorical_crossentropy&#39;, #损失函数     name=&#39;target&#39;)</code></p>
<p>&#x2F;&#x2F;利用tflearn完成手写数字的识别任务<br><code>import tflearn from tflearn.layers.core import input_data,dropout, fully_connected from tflearn.layers.conv import conv_2d, , max_pool_2d from tflearn.layers.normalization import local_response_normalization from tflearn.layers.estimator import regression</code></p>
<p>#载入并处理数据<br><code>import tflearn.datasets.mnist as mnist X, Y, testX, testY = mnist.load_data(one_hot=True)</code><br>#转换为二维图形<br><code>X = X.reshape([-1, 28, 28, 1]) testX = testX.reshape([-1, 28, 28, 1])</code></p>
<p>#建立神经网络<br><code>network = tflearn.input_data(shape=[None, 28, 28, 1], name=&#39;input&#39;) network = conv_2d(network, 32, 3, activation=&#39;relu&#39;, regularizer=&#39;L2&#39;) network = max_pool_2d(network) network = local_response_normalization(network) network = fully_connected(network, 128, activation=&#39;tanh&#39;) network = dropout(network, 0.8) network = fully_connected(network, 256, activation=&#39;tanh&#39;) network = dropout(network, 0.8) network = fully_connected(network, 10, activation=&#39;softmax&#39;)</code></p>
<p>#定义优化过程<br><code>network = regression(     network,     optimizer=&#39;adam&#39;,     learning_rate=0.01,     loss=&#39;categorical_crossentropy&#39;,     name=&#39;target&#39;)</code></p>
<p>#训练过程<br><code>model = tflearn.DNN(network, tensorboard_verbose=0) model.fit(&#123;&#39;input&#39;:X&#125;, &#123;&#39;target&#39;:Y&#125;, n_epoch=20,     validation_set=(&#123;&#39;input&#39;:testX&#125;, &#123;&#39;target&#39;:testY&#125;),     snapshot_step=100, show_metric=True, run_id=&#39;convnet_mnist&#39;)</code></p>
<p>&#x2F;&#x2F;Keras代码可读性好，并且横跨多个机器学习框架，但其扩展性较差<br>&#x2F;&#x2F;引入库<br><code>from keras.layers import Dense, Dropout, Flatten from keras.layers import Conv2D, MaxPooling2D</code></p>
<p>&#x2F;&#x2F;Keras直接顺序加入模型，无需通过数据方式进行传递<br>&#x2F;&#x2F;基础网络层<br><code>from keras.models import Sequential model = Sequential()</code><br>#加入卷积层<br><code>model.add(Conv2D(...))</code><br>#加入池化层<br><code>model.add(MaxPooling2D(...))</code><br>#加入全连接层<br><code>model.add(Dense(...))</code><br>#dropout<br><code>model.add(Dropout(0.25))</code></p>
<p>&#x2F;&#x2F;定义model后可直接加入多种层进行操作，同样其需要定义训练函数<br>&#x2F;&#x2F;定义优化过程<br><code>from keras.optimizers import SGD</code><br>#定义迭代算法<br><code>sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=sgd)</code><br>#训练过程<br><code>model.fit(x_train, y_train, batch_szie=32, epochs=10)</code><br>#评估训练效果<br><code>score = model.evaluate(x_test, y_test, batch_size=32)</code></p>
<p>&#x2F;&#x2F;完整代码<br><code>import keras from keras.models import Sequential from keras.layers import Dense, Dropout, Flatten from keras.layers import Conv2D, MaxPooling2D from keras.optimizers import SGD</code></p>
<p>#这里utils为自己定义的库函数，用于载入数据<br><code>import utils X, Y, testX, testY = utils.load_data(one_hot=True) model = Sequential()</code><br>#定义神经网络过程<br><code>model.add(Conv2D(32, (3, 3), activation=&#39;relu&#39;, input_shape=(100, 100, 3))) model.add(Conv2D(32, (3, 3), activation=&#39;relu&#39;)) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25))</code></p>
<p><code>model.add(Conv2D(64, (3, 3), activation=&#39;relu&#39;)) model.add(Conv2D(64, (3, 3), activatin=&#39;relu&#39;)) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25))</code></p>
<p>#展开为一维数据用于全连接层<br><code>model.add(Flatten()) model.add(Dense(256, activation=&#39;relu&#39;)) model.add(Dropout(0.5)) model.add(Dense(10, activation=&#39;softmax&#39;))</code><br>#梯度迭代算法<br><code>sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=sgd)</code><br>#训练过程<br><code>model.fit(x_train, y_train, batch_size=32, epochs=10)</code><br>#效果评估<br><code>score = model.evaluate(x_test, y_test, batch_size=32)</code></p>
<p>4.3 Tensorboard与问题监控<br>&#x2F;&#x2F;tensorboard最重要的作用就在于观察训练过程中的各种问题并改善，包括梯度消失、过拟合等问题<br>&#x2F;&#x2F;获取所有可训练的参数<br><code>var_list_w = [var for var in tf.trainable_variables() if &#39;w&#39; in var.name] var_list_b = [var for var in tf.trainable_variables() if &#39;b&#39; in var.name]</code></p>
<p>&#x2F;&#x2F;利用定义的梯度算法来计算梯度<br><code>gradient_w = optimizer.compute_gradients(loss, var_list=var_list_w) gradient_b = optimizer.compute_gradients(loss, var_list=var_list_b)</code></p>
<p>&#x2F;&#x2F;返回的梯度是一个列表，可对其进行各种列表操作<br>&#x2F;&#x2F;加入summary操作<br><code>for idx, itr_g in enumerate(gradient_w):     variable_summaries(itr_g[0], &#39;layer%d-w-grad&#39;%idx) for idx, itr_g in enumerate(gradient_b):     variable_summaries(itr_g[0], &#39;layer%d-b-grad&#39;%idx</code></p>
<p><code>for idx, itr_g in enumerate(var_list_w):     variable_summaries(itr_g, &#39;layer%d-w-grad&#39;%idx) for idx, itr_g in enumerate(var_list_b):     variable_summaries(itr_g, &#39;layer%d-b-grad&#39;%idx)</code></p>
<p>4.4改善深度神经网络<br>&#x2F;&#x2F;出现梯度消失一种最有效的方式就是进行BN操作<br>&#x2F;&#x2F;batchnorm层<br><code>net = tf.contrib.layers.batch_norm(net)</code></p>
<p>&#x2F;&#x2F;加入BN层的神经网络<br>#对于sigmoid激活函数来讲，BN操作效果可能不理想<br><code>net = slim.fully_connected(x, 4, activation_fn=tf.nn.sigmoid, scope=&#39;full1&#39;, reuse=False) net = tf.contrib.layers.batch_norm(net)</code></p>
<p><code>net = slim.fully_connected(net, 8, activation_fn=tf.nn.sigmoid, scope=&#39;full2&#39;, reuse=False) net = tf.contrib.layers.batch_norm(net)</code></p>
<p><code>net = slim.fully_connected(net, 8, activation_fn=tf.nn.sigmoid, scope=&#39;full3&#39;, reuse=False) net = tf.contrib.layers.batch_norm(net)</code></p>
<p><code>net = slim.fully_connected(net, 4, activation_fn=tf.nn.sigmoid, scope=&#39;full4&#39;, reuse=False) net = tf.contrib.layers.batch_norm(net)</code></p>
<p><code>net = slim.fully_connected(net, 3, activation_fn=tf.nn.sigmoid, scope=&#39;full5&#39;, reuse=False)</code></p>
<p><code>loss = tf.reduce_mean(tf.square(y-label))</code></p>
<p>4.5性能优化建议<br>&#x2F;&#x2F;训练前的优化技巧<br>1.网络结构优化<br>Relu和BN能够有效加快神经网络训练速度<br>卷积核心的选取可以从大的卷积核心修改为多个小的卷积核心<br>将nxn修改为nx1+1xn，减少参数量，不同的输出内容之间可以进行concat<br>引入跨层支路解决梯度问题（ResNet)<br>2.初始值的选取<br>不好的初始值对训练的影响非常大，有效的初始化方法包括xavier初始化方法和He初始化方法<br>3.数据预处理<br>包括去均值和方差均衡<br>&#x2F;&#x2F;训练过程中的优化技巧<br>1）优化算法的选择<br>Adam<br>2）学习率的选取<br>从大的步长开始进行迭代，逐步减少学习率<br>3）Batchsize选择<br>4）model ensembles<br>使用不同初始值同时训练多个模型，预测过程中将多个模型输出结果做平均，有效提升结果精度<br>5)dropout选择<br>从0.5附近进行调整，调整步长为0.05左右</p>
<p>&#x2F;&#x2F;物体检测<br>1.传统检测方法<br>2001年，基于Haar特征和Adaboost检测方法引起轰动<br>2012年之前，三方面不断创新与优化：特征的设计更新、检测窗口的选择、分类器的设计更新</p>
<p>2.深度学习的物体检测<br>1）基于分类的物体检测<br>处理过程：图像被分解成多个小区域，每个小区域将运行一个分类算法以确定区域是否包含待检测物体，之后再在这个小区域的周围确认物体的边界框。代表算法：R-CNN、Fast-RCNN、Faster-RCNN<br>2) 基于回归的物体检测<br>将问题建模为回归问题，通过深度神经网络直接预测出边界框和所属类别的置信度。代表算法：SSD、YOLO模型</p>
<p>&#x2F;&#x2F;YOLO模型<br>官网：<a href="https://pjreddie.com/darknet/yolo/">https://pjreddie.com/darknet/yolo/</a><br>&#x2F;&#x2F;选讲tiny YOLO v1模型，由9个卷积层和3个全连接层组成，每个卷积层都由卷积层、LeakyRelu和Max Pooling操作组成，前9个卷积层可被理解为特征提取器，最后三个全连接层可被理解为预测边界框的回归器。<br>参考论文：You Only Look Once:Unified, Real-Time Object Detection<br>参考实例：<a href="https://github.com/xslittlegrass/CarND-Vehicle-Detection">https://github.com/xslittlegrass/CarND-Vehicle-Detection</a><br>模型参数：45089374<br>深度学习框架：Keras 1.2.2</p>
<p>&#x2F;&#x2F;构建YOLO模型网络结构<br><code>import keras from keras.models import Sequential from keras.layers.convolutional import Convlution2D, MaxPooling2D from keras.layers.advanced_activations import LeakyReLU from keras.layers.core import Flatten, Dense, Activation, Reshape from utils import load_weights, Box, yolo_net_out_to_car_boxes, draw_box def construct_yolo_model():     keras.backend.set_image_dim_ordering(&#39;th&#39;)     model = Sequential()     model.add(Convolution2D(16, 3, 3, input_shape=(3, 448, 448), border_mode=&#39;same&#39;, subsample=(1, 1)))     model.add(LeakyReLU(alpha=0.1))     model.add(MaxPooling2D(pool_size=(2, 2)))</code></p>
<pre><code>model.add(Convolution2D(32, 3, 3, border_mode=&#39;same&#39;))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling2D(pool_size=(2, 2), border_mode=&#39;valid&#39;))

model.add(Convolution2D(32, 3, 3, border_mode=&#39;same&#39;))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling2D(pool_size=(2, 2), border_mode=&#39;valid&#39;))

model.add(Convolution2D(64, 3, 3, border_mode=&#39;same&#39;))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling2D(pool_size=(2, 2), border_mode=&#39;valid&#39;))

model.add(Convolution2D(128, 3, 3, border_mode=&#39;same&#39;))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling2D(pool_size=(2, 2), border_mode=&#39;valid&#39;))

model.add(Convolution2D(256, 3, 3, border_mode=&#39;same&#39;))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling2D(pool_size=(2, 2), border_mode=&#39;valid&#39;))

model.add(Convolution2D(512, 3, 3, border_mode=&#39;same&#39;))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling2D(pool_size=(2, 2), border_mode=&#39;valid&#39;))

model.add(Convolution2D(1024, 3, 3, border_mode=&#39;same&#39;))
model.add(LeakyReLU(alpha=0.1))

model.add(Convolution2D(1024, 3, 3, border_mode=&#39;same&#39;))
model.add(LeakyReLU(alpha=0.1))

model.add(Convolution2D(1024, 3, 3, border_mode=&#39;same&#39;))
model.add(LeakyReLU(alpha=0.1

model.add(Flatten())
model.add(Dense(256))
model.add(Dense(4096))
model.add(LeakyReLU(alpha=0.1))
model.add(Dense(1470))
model.summary()
return model
</code></pre>
<p>注：网络的输入是形状为（3,448,448)的图像，其输出是一个1470维度的向量，它包含预测边界框、物体类别信息。1470矢量被分成三个部分，分别给出了所属类别概率、置信度和边框坐标。这三个部分进一步划分为49个小区域，与每个单元的预测相对应。<br>输出向量信息组织方式：<br><code>probability:49*20=980</code><br>判断类别，20个类别<br><code>confidence:49*2=98</code><br>是否包含物体（0,1）<br><code>box coordinates:49*8=392 (x_min,y_min,x_max,y_max),(c_x,c_y,w,h)</code></p>
<p>8.4.3车辆图像数据探索<br>1.车辆视频数据预处理<br>&#x2F;&#x2F;预处理及可视化图像<br><code>def visualize_images():     imagePath = &#39;./test_images/test1.jpg&#39;     image = plt.imread(imagePath)</code><br>    #去除顶部和底部图片<br>    <code>image_crop = image[300:650,500:,:]</code><br>    #将图片转换为模型所需要的输入格式<br>    <code>resized = cv2.resize(image_crop, (448, 448))     f1,(ax11,ax22,ax33) = plt.subplot(1, 3, figsize=(16, 6))     ax11.imshow(image)     ax22.imshow(image_crop)     ax33.imshow(resized)     pylab.show()     return resized</code></p>
<p>8.4.5迁移学习<br>通过迁移学习加载使用Pre-trained YOLO模型进行行车检测。具体做法是将pre-trained模型中的权重加载进之前构造的模型结构中，官网提供的权重，可以通过脚本解析成Keras能够加载的格式。<br>&#x2F;&#x2F;加载YOLO模型权重<br><code>def load_model_weights(model):     #预训练权重网址：https://pjreddie.com/darknet/yolo/     load_weights(model, &#39;./yolo-tiny.weights&#39;)</code></p>
<p>&#x2F;&#x2F;加载模型权重的具体逻辑<br><code>def load_weights(model, yolo_weight_file):     data = np.fromfile(yolo_weight_file, np.float32)     data = data[4:]     index = 0     for layer in model.layers:         shape = [w.shape for w in layer.get_weights()]         if shape !=[]:             kshape, bshape = shape             bia = data[index:index+np.prod(bshape)].reshape(bshape)             index += np.prod(bshape)             ker = data[index:index:index+np.prod(kshape)].reshape(kshape)             index += np.prod(kshape)             layer.set_weights([ker, bia])</code></p>
<p>&#x2F;&#x2F;模型推断<br>&#x2F;&#x2F;使用模型进行在线推断，预测出车辆区域<br><code>def inference_image(model, resized):     #转置     batch = np.transpose(resized, (2, 0, 1))     #将像素值变换到-1~1     batch = 2*(batch/255.) - 1     #将一张图片转为数组     batch = np.expand_dims(batch, axis=0）     out = model.predict(batch)     return out</code></p>
<p>&#x2F;&#x2F;绘制检测结果<br>&#x2F;&#x2F;将上述的预测结果转换为边框坐标，同时基于阈值进行预测<br><code>th = 0.17 boxes = yolo_net_to_out_to_car_boxes(out[0], threshold=th)</code></p>
<p>&#x2F;&#x2F;定义box边框对象，判断是否保留预测的边框结果通过c,在图像上绘制车辆位置通过对象中的坐标信息<br>#定义box类，存储边框信息和物体检测类别等信息<br><code>class Box: def __init__(self):     #x, y轴坐标     self.x, self.y = float(), float()     #边框宽度和长度     self.w, self.h = float(), float()     #置信度     self.c = float()     #所属类别概率     self.prob = float()</code></p>
<p>&#x2F;&#x2F;通过yolo_net_to_out_to_car_boxes方法，将预测出的Vector转换为Box对象信息。其核心逻辑是解析模型预测输出向量中的坐标、类别和置信度信息<br>&#x2F;&#x2F;置信度大于阈值边界框则进行保留<br><code>class_num = 6 #yolo模型可以预测多种类别，6为车辆所属类别 p = probs[grid, :] *bx.c if p[class_num]&gt;=threshold:     bx.prob = p[class_num]     boxes.append(bx)</code></p>
<p>&#x2F;&#x2F;将结果绘制在图像上<br><code>def visualize_image_car_detection(boxes):     imagePath = &#39;./test_images/test1.jpg&#39;     image = plt.imread(imagePath)     f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))     ax1.imshow(image)     ax2.imshow(draw_box(boxes, plt.imread(imagePath), [[500, 1280],[300,650]]))     pylab.show()</code></p>
<p>&#x2F;&#x2F;将边框绘制在图像上<br><code>def draw_box(boxes, im, crop_dim):     imgcv = im     [xmin, xmax] = crop_dim[0]     [ymin, ymax] = crop_dim[1]     for b in boxes:         h, w, _ = imgcv.shape         left = int((b.x-b.w/2.)*w)         right = int((b.x+b.w/2.)*w)         top = int((b.y-b.h/2.)*h)         bot = int((b.y+b.h/2.)*h)         left = int(left*(xmax-xmin)/w+xmin)         right = int(right*(xmax-xmin)/w+xmin)         top = int(top*(ymax-ymin)/h+ymin)         bot = int(bot*(ymax-ymin)/h+ymin)         if left&lt;0 : left=0         if right&gt;w-1 : right=w-1         if top&lt;0 : top=0         if bot&gt;h-1 : bot=h-1         thick = int((h+w)//150)         cv2.rectangle(imgcv, (left, top), (right, bot), (255,0,0), thick)     return imgcv</code></p>
<p>8.5.1英伟达End to End模型<br>End to End的好处：通过缩减人工预处理和后续处理，尽可能使模型从原始输入到输出，使得其根据网络模型能够有足够多的空间进行自动调节，从而减少基于规则的复杂变化。<br>缺点：可解释性较差，准确度和精度不容易受控制。<br>&#x2F;&#x2F;构建英伟达模型<br><code>import tensorflow as tf import keras from keras.models import Sequential from keras.layers import Dense, Activation, Flatten, Lambda from keras.layers import Conv2D, Dropout from keras import losses def nvida_model():     model = Sequential()     model.add(Lambda(lambda x: x/127.5-1., input_shape=(img_height, img_width, img_channels)))     model.add(Conv2D(24, kernel_size=(5, 5), strides=(2, 2), padding=&#39;valid&#39;, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;))     model.add(Conv2D(36, kernel_size=(5, 5), strides=(2, 2), padding=&#39;valid&#39;, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;))     model.add(Conv2D(48, kernel_size=(5, 5), strides=(2, 2), padding=&#39;valid&#39;, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;))     model.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding=&#39;valid&#39;, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;))     model.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding=&#39;valid&#39;, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu     model.add(Flatten())     model.add(Dense(1164, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;))     model.add(Dense(100, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;))     model.add(Dense(50, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;))     model.add(Dense(10, kernel_initializer=&#39;he_normal&#39;, activation=&#39;elu&#39;))     model.add(Dense(1, kernel_initializer=&#39;he_normal&#39;))     model.compile(loss=&#39;mse&#39;, optimizer=&#39;Adadelta&#39;)     return model</code></p>
<p>&#x2F;&#x2F;8.5.3数据分析<br>1）转向控制数据分布<br>#绘制转向分布<br><code>def steering_distribution():     wheel_sig = pd.read_csv(params.data_dir+&#39;/epoch01_steering.csv&#39;)     wheel_sig.head() wheel_sig.wheel.hist(bins=50)</code></p>
<p>2)数据变化幅度<br>#绘制转向变化幅度<br><code>def angel_visualize():     wheel_sig = pd.read_csv(params.data_dir+&#39;/epoch01_steering.csv&#39;)     wheel_sig.plot(x=&#39;frame&#39;, y=&#39;wheel&#39;)     plt.show()</code></p>
<p>8.5.4读入视频，并处理图像<br>&#x2F;&#x2F;使用OpenCV从视频中提取图像，以及与其对应的转向角度并返回<br>#提取图像并处理<br><code>imgs = [] wheels = [] epochs = [10] for epoch in epochs:     vid_path = utils.join_dir(params.data_dir, &#39;epoch&#123;:0&gt;2&#125;_front.mp4&#39;.format(epoch))     assert os.path.isfile(vid_path)     frame_count = frame_count_func(vid_path)     cap = cv2.VideoCapture(vid_path)     for frame_id in range(frame_count):         while True:         #通过OpenCV中的VideoCapture进行视频中图像的提取             ret, img = cap.read()             if not ret:                 break             #用户可以自定义对图像的处理、扩展和增强操作             img = a_image_convert.img_preprocess(img, color_mode, flip=False)             imgs.append(img)         csv.path = os.path.join(data_dir, &#39;epoch&#123;:0&gt;2&#125;_steering.csv&#39;.format(epoch))         rows = pd.read_csv(csv.path)         yy = rows[&#39;wheel&#39;].values         wheels.extend(yy)         cap.release()     imgs = np.array(imgs)     wheels = np.array(wheels)     wheels = np.reshape(wheels, (len(wheels), 1)     return imgs, wheels</code></p>
<p>8.5.5深度学习模型构建与训练<br>&#x2F;&#x2F;训练模型<br><code>def training(model, X_train_RGB, y_train_RGB):     RGB_model = model     time_start = time.time()     #fit the model     RGB_history = RGB_model.fit(X_train_RGB, y_train_RGB, epochs=30, batch_size=batch_size)     return RGB_model, RGB_history</code></p>
<p>&#x2F;&#x2F;可视化结果<br>#将训练过程中的loss误差进行可视化<br><code>def visualize_label(RGB_history):     print(RGB_history.history[&#39;loss&#39;]     plt.figure(figsize=(9, 6))     plt.plot(RGB_history.history[&#39;loss&#39;])     plt.title(&#39;model loss&#39;)     plt.ylabel(&#39;Loss&#39;, fontsize=12)     plt.xlabel(&#39;Epoch&#39;, fontsize=12)     plt.legend([&#39;train RGB&#39;], loc=&#39;upper right&#39;)     plt.grid()     plt.show()</code></p>
<p>&#x2F;&#x2F;可视化<br>&#x2F;&#x2F;数据的绘图过程就是将前面所得到的一系列数据，通过静态、动态的二维、三维图形进行展示<br>1.Matplotlib<br>&#x2F;&#x2F;绘制y&#x3D;sinx图像<br><code>import numpy as np import matplotlib.pyplot as plt x = np.linspace(0, 4*np.pi, 1000) y = np.sin(x) plt.plot(x,y)</code></p>
<p>&#x2F;&#x2F;利用API,绘制更加审美要求的图像<br><code>import numpy as np import matplotlib.pyplot as plt import matplotlib as mpl #设置图片风格 mpl.style.use(&#39;seaborn-darkgrid&#39;) #定义曲线 x = np.linspace(0, 4*np.pi, 100) y1 = np.sin(x) y2 = np.sin(x+1) y3 = np.sin(x+2) #绘图 plt.plot(x, y1, color=&#39;#009900&#39;, lw=6, alpha=0.6) plt.plot(x, y2, color=&#39;#990000&#39;, lw=6, alpha=0.6) plt.plot(x, y3, color=&#39;#000099&#39;, lw=6, alpha=0.6) #展示 plt.show()</code></p>
<p>9.4ECharts<br>&#x2F;&#x2F;ECharts提供了常规的折线图、柱状图、散点图、饼图、K线图等等，功能强大。<br>&#x2F;&#x2F;ECharts图形绘制<br>略</p>
<p>&#x2F;&#x2F;文本向量化<br>&#x2F;&#x2F;文本向量化函数<br>#文本TfIdf向量化<br><code>from sklearn.feature_extraction.text import TfidfVectorizer vectorizer = TfidVectorizer() vectors = vectorizer.fit_transform(datas)</code></p>
<p>&#x2F;&#x2F;文本向量化的数据进行降维<br>&#x2F;&#x2F;LDA降维<br><code>from sklearn.decomposition import LatentDirichletAllocation lda = LatenDirichletAllocation(n_components=n_topic, max_iter=5,     learning_method = &#39;online&#39;,     learning_offset = 50.,     radom_state = 0)</code><br>#用LDA方法降维数据<br><code>dr_vectors = lad.fit_transform(vectors)</code></p>
<p>9.6三维可视化<br>&#x2F;&#x2F;ECharts地图柱状图<br><code>myChart.setOption(&#123;     visualMap: &#123;         show: flase,         calculable: true,         realtime: false,         inRange: &#123;         color: [&#39;#313695&#39;, &#39;#4575b4&#39;, &#39;#74add1&#39;, &#39;#abd9e9&#39;,                 &#39;#e0f3f8&#39;, &#39;#ffffbf&#39;, &#39;#fee090&#39;, &#39;#fdae61&#39;,                 &#39;#f46d43&#39;, &#39;#d73027&#39;, &#39;#d73027&#39;, &#39;a50026&#39;]                 &#125;,         outOfRange: &#123;             colorAlpha: 0             &#125;,         max: linedata[1]         &#125;,         ...         series: [&#123;             type: &#39;bar3D&#39;,             shading: &#39;realistic&#39;,             coordinateSystem: &#39;mapbox&#39;,             barSize: 0.2,             silent: true,             data: linedata[0]             &#125;]         &#125;);</code></p>
<p>&#x2F;&#x2F;利用Matplotlib完成对三维数据的可视化任务<br><code>from mpl_toolkits.mplot3d import axes3d import matplotlib.pyplot as plt from matplotlib import cm import matplotlib.style as style style.use(&#39;seaborn-darkgrid&#39;)</code></p>
<p>#定义三维画布<br><code>fig = plt.figure() ax = fig.gca(projection=&#39;3d&#39;)</code><br>#获取数据<br><code>X, Y, Z = axes3d.get_test_data(0.05)</code><br>#绘制surface<br><code>ax.plot_surface(X, Y, Z, rstride=8, cstride=8, alpha=0.3)</code><br>#绘制等值线<br><code>cst = ax.contourf(X, Y, Z, zdir=&#39;z&#39;, offset=-100, cmap=cm.coolwarm) cst = ax.contourf(X, Y, Z, zdir=&#39;x&#39;, offset=-40, cmap=cm.coolwarm) cst = ax.contourf(X, Y, Z, zdir=&#39;y&#39;, offset=40, cmap=cm.coolwarm)</code></p>
<p><code>plt.show()</code></p>
<p>9.7动态可视化<br>&#x2F;&#x2F;Matplotlib中用于数据动态演示的方法为animation,其可以通过函数进行简单的调用，以进行动态图形的演示工作<br>&#x2F;&#x2F;动画展示<br><code>import matplotlib.animation as animation animation.FuncAniamtion(     ...     )</code></p>
<p>&#x2F;&#x2F;动态可视化的展示方式是在普通的图表之上通过不断地修改数据并进行展示，这种修改可以通过setOption而得到的，在实现上可以通过函数递归的方式实现动态数据的可视化工作<br><code>function update()&#123;     myChart.setOption(...);         setTimeout(update, UPDATE_DURATION);         &#125; update();</code></p>
<p>&#x2F;&#x2F;优化实践<br>10.1通用深度神经网络训练优化建议</p>
<p>1）通用的较为优化的训练过程<br>1.将问题转换为相似的经典问题场景，参照paper中的配置和调优技巧进行最初的实验与优化<br>2.优化算法：选用随机梯度下降（SGD)算法，虽然批量梯度下降（BGD)相比SGD有一些优势，但是在处理大规模数据时，SGD及其优化变种更加简单和快速。<br>3.随机Shuffle样本：应尽量避免连续处理的样本属于同一类别的情况。尽量选择当前样本能让模型产生较大的误差，而不是较小的误差<br>4.规范化数据：输入的每个变量均值最好趋近于0.变换输入变量，使其协方差相近，变量间尽量不要相关<br>5.激活函数的选取：相比Sigmoid函数，tanh和Relu有更好的收敛速度。<br>6.权重初始化：可以随机通过一种分布，均值为0.<br>7.选择学习率：每个权重都可以选取属于自己的学习率。处于低层的权重学习率最好大于高层的权重学习率。学习率最好正比于每个单元的输入数量。</p>
<p>2）CNN训练过程中通常关注的优化点和参数<br>一般比较关注：Learning Rate,Weight Decay,Momentum,Batchsize,Init Weights,数据增强<br>eg:在Resnet中，使用SGD优化算法优化方法训练，mini-batch的大小设置为256，学习率初始化为0.1.随着训练进行，当Loss不再下降，会每次自适应以10倍进行缩减学习率。模型训练用了60x10^4轮迭代。Weight Decay设置为0.0001，同时设置momentum为0.9</p>
<p>3)RNN训练过程中通常关注的优化点和参数<br>一般比较关注：SGD,正则化，规范化梯度，Pad Sentence,Init Weight, Batch Size, Embedding输入，输出控制，Vacabulary Size, Sampled Softmax<br>eg:Google发布的TTS模型TACOTRON为例</p>
<p>10.1.1 过拟合和欠拟合<br>欠拟合：若训练集和测试集的误差有收敛但很高时，则为高偏差<br>过拟合：若训练集和测试集的误差较大时，则为高方差</p>
<p>解决过拟合的方法：<br>正则化，数据增强，Early Stop, Dropout, Batch Normalization</p>
<p>解决欠拟合的方法：<br>1.使用更加复杂的深度学习网络架构<br>2.添加其他特征项，有时候模型出现欠拟合的情况是因为特征项不够导致的，可以添加其他特征项来很好的解决这个问题<br>3.减少正则化参数和组件，正则化的目的是用来防止过拟合。</p>
<p>10.1.2数据增强<br>&#x2F;&#x2F;数据增强的根本原因在于机器在学习的过程中会在模型中遇到大量的参数，同时为了防止过拟合<br>1）对于图像数据，可采取：<br>1.图像平移：使得网络学习到平移不变的特性<br>2.图像旋转：使得网络学习到旋转不变的特性<br>3.图像亮度变化<br>4.裁剪<br>5.缩放<br>6.图像模糊:用不同的卷积模板产生模糊图像<br>2）语音识别中对输入数据添加随机噪声等方式<br>3）NLP中最常用的方式就是进行近义词替换等方式<br>4）噪声注入，可以对输入添加噪声，也可以对隐藏层或者输出层添加噪声</p>
<p>10.1.3梯度消失<br>&#x2F;&#x2F;实验数据显示了深度神经网络在训练过程中，随着epoch的增加各隐藏层的学习率变化。前面隐藏层的学习速度要低于后面的隐藏层<br>&#x2F;&#x2F;梯度消失的原因：根据链式法则，如果每一层神经元对上一层输出的偏导乘上权重结果都小于1的话，那么即使这个结果是0.99，在经过足够多层的传播后，误差对输入层的偏导也会趋近于0<br>解决梯度消失的策略：<br>1.BN<br>2.RNN中使用LSTM:适用于RNN,门控制和长时记忆可缓解和解决梯度消失问题<br>3.激活函数Relu:新的激活函数解析性质更好，其在一定程度上克服了sigmoid函数和tanh函数的梯度消失问题。<br>4.在RNN反向传播过程中减少时间步长度。</p>
<p>10.1.4初始化权重<br>&#x2F;&#x2F;在参数解空间内，好的权重初始化方式，意味着离全局最小值更近。<br>1.高斯初始化，为权重初始化较小的值，权重按照高斯分布随机进行初始化，固定均值和方差<br>2.Xaiver更新方法，使用tanh为激活函数，效果较好。进行梯度更新时，收敛速度较快，然而没有考虑Relu<br>3.MSRA方法，适用于从头训练深层深度神经网络的网络结构。权重以高斯分布随机进行初始化，方差需要考虑空间过滤器的大小和过滤器数量的影响。</p>
<p>10.1.5优化算法<br>近些年最常用的是采用Adam优化算法，也可以采用自适应学习率的方法实现快速收敛。</p>
<p>10.1.6超参数选择<br>一些实践经验：<br>1.在验证集上进行调参<br>2.优先调Learning Rate<br>3.通过初期设计卷积层尽量深、卷积核尽量多的模型，强行让模型拟合训练集，这时会出现过拟合，之后通过Dropout、正则化和Data Augument等等方式去改善模型结果<br>4.调整模型的层数和卷积核数量</p>
<p>&#x2F;&#x2F;通过Scikit-learn的网格搜索库进行参数调优实例<br>1.常见搜索参数<br>学习率、Dropout、Epochs和神经元数量<br>2.数据集下载<br>数据集为Pima Indians Onset of Diabetes分类数据集<br>下载地址：<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/">https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/</a><br>3.搜索最优batchsize和epochs<br>&#x2F;&#x2F;以20的步长，从10到100逐步评估不同的微型批尺寸，epochs分别设置为10、50、100<br><code>import numpy from sklearn.grida_search import GridSearchCV from keras.models import Sequential from keras.layers import Dense from keras.wrappers.scikit_learn import KerasClassifier</code></p>
<p>#Function to create model, required for KerasClassifier<br><code>def create_model():     #create model     model = Sequential()     model.add(Dense(12, input_dim=8, activation=&#39;relu&#39;))     model.add(Dense(1, activation=&#39;sigmoid&#39;))</code></p>
<pre><code>#compile model
model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;])
return model
</code></pre>
<p><code>#fix random seed for reproducibility seed = 7 numpy.random.seed(seed) #load dataset dataset = numpy.loadtxt(&quot;pima-indians-diabetes.csv&quot;, delimiter=&#39;,&#39;) #split into input (x) and output (Y) variables X = [:, 0:8] Y = [:, 8] #create model model = KerasClassifier(build_fn=create_model, verbose=0) #define the grid search parameters batch_size = [10, 20, 40, 60, 80, 100] epochs = [10, 50, 100] param_grid = dict(batch_size=batch_size, nb_epoch=epochs) grid = GridSearchCV(estimator=model, param_grid=parm_grid, n_jobs=-1) grid_result = grid_fit(X,Y) #summarize results print(&quot;Best: %f using %s&quot; % (grid_result.best_score_, grid_result.best_params)) for params, mean_score, scores in grid_result.grid_scores_:     print(&quot;%f (%f) with: %r&quot; % (scores.mean(), scores.std(), params))</code></p>
<p>10.2深度学习系统性能优化建议<br>10.2.1输入及预处理流水线优化<br>输入流水线：从磁盘读取图像，将JPEG预处理为张量，进行数据预处理裁剪、翻转等，然后进行批处理操作<br>1.在CPU端进行预处理<br>&#x2F;&#x2F;在CPU端上放置输入预处理操作可以显著提高性能，GPU专注训练<br>&#x2F;&#x2F;控制代码在CPU端执行<br><code>with tf.device(&quot;/cpu:0&quot;):     # function to get and process data. ​    distored_inputs = load_and_preprocess_images()</code></p>
<p>2.使用大文件<br>读取大量的小文件会显著影响I&#x2F;O性能<br>1）转换为TFRecord格式<br>2）小数据集加载到内存</p>
<p>10.2.2数据格式<br>NHWC的方存局部性更好（每三个输入像素即可得到一个输出像素），NCHW则必须等所有通道输入都准备好后才能得到最终的输出结果，需要占用较大的临时空间。<br>tf默认NHWC格式，Nvidia cuDNN默认NCHW格式<br>注：设计网络时充分考虑这两种格式，最好能够灵活切换，在GPU上训练时使用NCHW格式，在CPU上做预测时使用NHWC格式</p>
<p>10.2.3编译优化<br>&#x2F;&#x2F;通过bazel命令对特定平台对tf进行编译<br><code>bazel build -c opt --copt=-march=&quot;brodewell&quot; --config=cuda //tensorflow/tools/pip_package:build_pip_package</code></p>
<p>10.2.4GPU性能瓶颈诊断<br>&#x2F;&#x2F;参考如下分析步骤对作业进行优化<br>1）对代码进行性能分析<br>2）找到运行慢的阶段<br>3）分析慢的原因<br>4）修改成更快的实现<br>5）再次对代码进行性能分析</p>
<p>&#x2F;&#x2F;处理器有两个关键的性能瓶颈：浮点计算量和内存吞吐量。<br>&#x2F;&#x2F;可通过以下工具进行深度学习作业的性能分析<br>1.Tensorflow性能分析工具Timeline(获取执行图中每个节点的执行时间）<br>1）创建metadata运行时对象<br>2）获取运行时信息创建Timeline对象<br>3）将Timeline对象写入json文件<br>4）Chrome加载trace的json文件</p>
<p>&#x2F;&#x2F;tensorflow使用Timeline进行性能分析<br><code>import tensorflow as tf from tensorflow.python.client import timeline</code></p>
<p><code>x = tf.random_normal([1000, 1000]) y = tf.random_normal([1000, 1000]) res = tf.matmul(x, y)</code></p>
<p><code>#run the graph with full trace option with tf.Session() as sess:     run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)     run_metadata = tf.RunMetadata()     sess.run(res, options=run_options, run_metadata=run_metadata)</code></p>
<pre><code>#create Timeline variable，then write it into json file
t1 = timeline.Timeline(run_metadata.step_stats)
ctf = t1.generate_chrome_trace_format()
with open(&#39;timeline.json&#39;, &#39;w&#39;) as f:
    f.write(ctf)
</code></pre>
<p>可以打开谷歌chrome浏览器，转到chrome:&#x2F;&#x2F;tracing页并加载timeline.json文件，接下来，可以进行程序的profiling</p>
<p>2.常用的GPU分析工具<br>1）nvprof是英伟达性能分析工具<br>2）nvvp则是带GUI的英伟达可视化性能分析工具</p>
<p>10.2.5CPU瓶颈优化<br>1）多线程方式优化<br>以下两个针对tensorflow的配置可以通过适配线程池进行CPU的性能优化<br>intra_op_parallelism_threads：对tf操作符内部的任务进行并行化<br>inter_op_parallelism_threads: 控制多个运算符之间的并行化运算<br>&#x2F;&#x2F;多线程优化<br><code>config = tf.ConfigProto() config.intra_op_parallelism_threads = 22 config.inter_op_parallelism_threads = 22 tf.session(config=config)</code></p>
<p>2)使用SIMD高级指令集<br>参考tf官方文档的”Performance Guide”章节</p>
<p>10.2.6模型压缩<br>模型小型化：从模型权重的角度进行压缩和从网络架构的角度进行压缩<br>网络架构角度：提出新的网络结构或卷积方法进行压缩优化，如SqueezeNet, MobileNets等<br>模型权重角度：一般是在已经训练好的模型上进行裁剪，然后fine-tuning到原有模型的准确率，一般的优化方式包括剪枝、权值共享、神经网络二值化等。</p>
<p>10.3工程实践建议<br>10.3.1Model格式转换<br>框架间的模型转换<br>参考链接：<br>1.<a href="https://github.com/ysh329/deep-learning-model-convertor">https://github.com/ysh329/deep-learning-model-convertor</a><br>2.<a href="https://github.com/Microsoft/MMdnn">https://github.com/Microsoft/MMdnn</a></p>
<p>10.3.2迁移学习（Transfer Learning)<br>其思想是将训练好的模型参数迁移到新的模型来帮助新模型的训练和预测。</p>
<p>&#x2F;&#x2F;通过MNIST数据集0<del>4的数字训练一个模型，然后将模型迁移到5</del>9数据集上进行迁移学习<br>1）在MNIST数据集上训练一个简单的卷积神经网络，只预测0<del>4的数字<br>2）将训练好的预测0</del>4数据集的模型，应用到5~9数据集上。对模型冻结卷积层参数，Fine-Tuning全连接层。<br>&#x2F;&#x2F;keras迁移学习实例<br><code>from __future__ import print_function import datetime import keras from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Dropout, Activation, Flatten from keras.layers import Conv2D, MaxPooling2D from keras import backend as K</code></p>
<p><code>now = datetime.datetime.now batch_size = 128 num_classes = 5 epochs = 5</code></p>
<p><code>#input images dimensions img_rows, img_cols = 28, 28 #number of convolutional filters  to use filters = 32 #size of pooling area for max pooling     pool_size = 2 #convolution kernel size kernel_size = 3</code></p>
<p><code>if K.image_data_format()==&#39;channels_first&#39;:     input_shape = (1, img_rows, img_cols) else:     input_shape = (img_rows, img_cols, 1)</code></p>
<p><code>def train_model(model, train, test, num_classes):     x_train = train[0].reshape((train[0].shape[0],)+input_shape)     x_test = test[0].reshape((test[0].shape[0],)+input_shape)     x_train = x_train.astype(&#39;float32&#39;)     x_test = x_test.astype(&#39;float32&#39;)     x_train /= 255     x_test /= 255     print(&#39;x_train shape:&#39;, x_train.shape)     print(x_train.shape[0], &#39;train samples&#39;)     print(x_test.shape[0], &#39;test samples&#39;)</code></p>
<pre><code>#convert class vectors to binary class matrics
y_train = keras.utils.to_categorical(train[1], num_classes)
y_test = keras.utils.to_categorical(test[1], num_classes)

model.compile(
    loss = &#39;categorical_crossentropy&#39;,
    optimizer = &#39;adadelta&#39;,
    metrics = [&#39;accuracy&#39;]
    )

t = now()
model.fit(x_train, y_train,
    batch_size = batch_size,
    epochs = epochs,
    verbose = 1,
    validation_data = (x_test, y_test))
print(&#39;Training time: %s&#39; %(now() -t))
score = model.evaluate(x_test, y_test, verbose=0)
print(&#39;Test score:&#39;, score[0])
</code></pre>
<p><code>#the data,shuffled and spilt between train and test sets (x_train, y_train), (x_test, y_test) = mnist.load-data() #create two datasets one with digits below 5 and one with 5 and above x_train_lt5 = x_train[y_train&lt;5] y_train_lt5 = x_train[y_train&lt;5] x_test_lt5 = x_test[y_test&lt;5] y_test_lt5 = y_test[y_test&lt;5]</code></p>
<p><code>x_train_get5 = x_train[y_train&gt;=5] y_train_get5 = y_train[y_train&gt;=5]-5 x_test_get5 = x_test[y_test&gt;=5] y_test_get5 = y_test[y_test&gt;=5]-5</code></p>
<p><code>#define two groups of layers:feature(convolutions) and classification(dense) feature_layers = [         Conv2D(filters, kernel_size,             padding=&#39;valid&#39;,             input_shape=input_shape),         Activation(&#39;relu&#39;),         Conv2D(filters, kernel_size),         Activation(&#39;relu&#39;),         MaxPooling2D(pool_size=pool_size),         Dropout(0.5),         Flatten()] classification_layers=[     Dense(128),     Activation(&#39;relu&#39;),     Dropout(0.5),     Dense(num_classes),     Activation(&#39;softmax&#39;)]</code></p>
<p><code>#create complete model model = Sequential(feature_layers+classification_layers)</code></p>
<p><code>#train model for 5-digit classification(0~4) train_model(model,     (x_train_lt5, y_train_lt5),     (x_test_lt5, y_test_lt5), num_classes)</code></p>
<p><code>#freeze feature layers and rebuild model for l in feature_layers:     l.trainable = False</code></p>
<p><code>#transfer: train dense layers for new classification task(5~9) train_model(model,     (x_train_gte5, y_train_get5),     (x_test_get5, y_test_get5), num_classes)</code></p>
<p>​<br>​<br>​    </p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/17/CN/%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="就地操作"><a href="#就地操作" class="headerlink" title="就地操作"></a>就地操作</h3><p>问题来源：看代码发现<code>self.relu=nn.ReLU(inplace=True)</code>不明白<code>inplace=True</code>什么意思。</p>
<p>解答：查看pytorch官网关于ReLU定义，<a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU">ReLU</a>其中inplace参数表示可以选择就地执行操作，默认为False,就地执行操作是指图像处理函数的输入图像和输出图像是同一对象，即同一张图像，常规的图像处理函数是不支持输入图像和输出图像是同一图像的。</p>
<p>eg:中值滤波函数</p>
<p><code>medianBlur(src, dst, 7);  //常规操作</code></p>
<p><code>medianBlur(src,  src, 7); //就地操作</code></p>
<p>就地操作直接更改张量的内容，而无需复制它。由于它不创建输入的副本，因此在处理高维数据时减少了内存使用，就地操作有助于使用更少的GPU内存，详情请看该博客<a href="https://www.ksgszhuce.com/tetl/37.html">如何在Pytorch中执行就地操作</a></p>
]]></content>
  </entry>
</search>
