<!DOCTYPE html>
<html lang="zh-CN,en,zh-TW,default">
<head hexo-theme="https://github.com/volantis-x/hexo-theme-volantis/tree/4.2.0">
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
    
  
  <!-- 渲染优化 -->
  <meta http-equiv="x-dns-prefetch-control" content="on">
  <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- 页面元数据 -->
  
  <title>RetinaNet论文笔记 - 阿月浑子-Hexo博客</title>
  
    <meta name="keywords" content="论文笔记,retinanet">
  

  

  <!-- feed -->
  
    <link rel="alternate" href="/atom.xml" title="阿月浑子-Hexo博客" type="application/atom+xml">
  

  <!-- import meta -->
  

  <!-- link -->
  

  <!-- import link -->
  

  
    
<link rel="stylesheet" href="/css/first.css">

  

  
  <link rel="stylesheet" href="/css/style.css" media="print" onload="this.media='all';this.onload=null">
  <noscript><link rel="stylesheet" href="/css/style.css"></noscript>
  

  <script id="loadcss"></script>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end -->
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>

<body>
  

<header id="l_header" class="l_header auto shadow show" style="opacity: 0">
  <div class="container">
  <div id="wrapper">
    <div class="nav-sub">
      <p class="title"></p>
      <ul class="switcher nav-list-h m-phone" id="pjax-header-nav-list">
        <li><a id="s-comment" class="fas fa-comments fa-fw" target="_self" href="javascript:void(0)"></a></li>
        
          <li><a id="s-toc" class="s-toc fas fa-list fa-fw" target="_self" href="javascript:void(0)"></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href="/">
          
            <img no-lazy class="logo" src="volantis-static/media/org.volantis/blog/Logo-NavBar@3x.png">
          
          
          
        </a>
      

			<div class="menu navigation">
				<ul class="nav-list-h m-pc">
          
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/" id="home">
                  <i class="fa-solid fa-rss fa-fw"></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/categories/" id="categories">
                  <i class="fa-solid fa-folder-open fa-fw"></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/archives/" id="archives">
                  <i class="fa-solid fa-archive fa-fw"></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/friends/" id="friends">
                  <i class="fa-solid fa-link fa-fw"></i>友链
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/tags/" id="tags">
                  <i class="fa-solid fa-tags fa-fw"></i>留言箱
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/about/" id="about">
                  <i class="fa-solid fa-info-circle fa-fw"></i>关于
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover">
                  <i class="fa-solid fa-ellipsis-v fa-fw"></i>更多
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/hexo-theme-volantis/" id="https:githubcomvolantis-xhexo-theme-volantis" rel="external nofollow noopener noreferrer" target="_blank">
                  主题源码
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/hexo-theme-volantis/releases/" id="https:githubcomvolantis-xhexo-theme-volantisreleases" rel="external nofollow noopener noreferrer" target="_blank">
                  更新日志
                </a>
                
              </li>
            
          
                    
                      
            
              <hr>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover">
                  有疑问？
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/faqs/" id="faqs">
                  看 FAQ
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/volantis-docs/" id="https:githubcomvolantis-xvolantis-docs" rel="external nofollow noopener noreferrer" target="_blank">
                  看 本站源码
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/hexo-theme-volantis/issues/" id="https:githubcomvolantis-xhexo-theme-volantisissues" rel="external nofollow noopener noreferrer" target="_blank">
                  提 Issue
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
                    
                      
            
              <hr>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover">
                  文学黑洞
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://meiriyiwen.com/random" id="https:meiriyiwencomrandom" rel="external nofollow noopener noreferrer" target="_blank">
                  每日一文
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://www.marxists.org/chinese/index.html" id="https:wwwmarxistsorgchineseindexhtml" rel="external nofollow noopener noreferrer" target="_blank">
                  马克思主义文库
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://www.yikm.net/" id="https:wwwyikmnet" rel="external nofollow noopener noreferrer" target="_blank">
                  游戏厅
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://www.xiaozhongjishu.com/" id="https:wwwxiaozhongjishucom" rel="external nofollow noopener noreferrer" target="_blank">
                  小众技术工具库
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
          
				</ul>
			</div>

      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fas fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search...">
        </form>
      </div>

			<ul class="switcher nav-list-h m-phone">
				
					<li><a class="s-search fas fa-search fa-fw" target="_self" href="javascript:void(0)"></a></li>
				
				<li>
          <a class="s-menu fas fa-bars fa-fw" target="_self" href="javascript:void(0)"></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/" id="home">
                  <i class="fa-solid fa-rss fa-fw"></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/categories/" id="categories">
                  <i class="fa-solid fa-folder-open fa-fw"></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/archives/" id="archives">
                  <i class="fa-solid fa-archive fa-fw"></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/friends/" id="friends">
                  <i class="fa-solid fa-link fa-fw"></i>友链
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/tags/" id="tags">
                  <i class="fa-solid fa-tags fa-fw"></i>留言箱
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/about/" id="about">
                  <i class="fa-solid fa-info-circle fa-fw"></i>关于
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover">
                  <i class="fa-solid fa-ellipsis-v fa-fw"></i>更多
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/hexo-theme-volantis/" id="https:githubcomvolantis-xhexo-theme-volantis" rel="external nofollow noopener noreferrer" target="_blank">
                  主题源码
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/hexo-theme-volantis/releases/" id="https:githubcomvolantis-xhexo-theme-volantisreleases" rel="external nofollow noopener noreferrer" target="_blank">
                  更新日志
                </a>
                
              </li>
            
          
                    
                      
            
              <hr>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover">
                  有疑问？
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/faqs/" id="faqs">
                  看 FAQ
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/volantis-docs/" id="https:githubcomvolantis-xvolantis-docs" rel="external nofollow noopener noreferrer" target="_blank">
                  看 本站源码
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/hexo-theme-volantis/issues/" id="https:githubcomvolantis-xhexo-theme-volantisissues" rel="external nofollow noopener noreferrer" target="_blank">
                  提 Issue
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
                    
                      
            
              <hr>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover">
                  文学黑洞
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://meiriyiwen.com/random" id="https:meiriyiwencomrandom" rel="external nofollow noopener noreferrer" target="_blank">
                  每日一文
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://www.marxists.org/chinese/index.html" id="https:wwwmarxistsorgchineseindexhtml" rel="external nofollow noopener noreferrer" target="_blank">
                  马克思主义文库
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://www.yikm.net/" id="https:wwwyikmnet" rel="external nofollow noopener noreferrer" target="_blank">
                  游戏厅
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://www.xiaozhongjishu.com/" id="https:wwwxiaozhongjishucom" rel="external nofollow noopener noreferrer" target="_blank">
                  小众技术工具库
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>
		</div>
	</div>
  </div>
</header>

  <div id="l_body">
    <div id="l_cover">
  
    
        <div id="full" class="cover-wrapper post dock" style="display: none;">
          
            <div class="cover-bg lazyload placeholder" data-bg="https://gcore.jsdelivr.net/gh/MHG-LAB/cron@gh-pages/bing/bing.jpg"></div>
          
          <div class="cover-body">
  <div class="top">
    
    
      <p class="title">相思似海深旧事如天远</p>
    
    
      <p class="subtitle">where there is a will there is a way</p>
    
  </div>
  <div class="bottom">
    <div class="menu navigation">
      <div class="list-h">
        
          
            <a href="/v5/getting-started/" id="v5getting-started">
              <img src="volantis-static/media/twemoji/assets/svg/1f5c3.svg" class="lazyload" data-srcset="volantis-static/media/twemoji/assets/svg/1f5c3.svg" srcset="data:image/png;base64,666"><p>文档</p>
            </a>
          
            <a href="/faqs/" id="faqs">
              <img src="volantis-static/media/twemoji/assets/svg/1f516.svg" class="lazyload" data-srcset="volantis-static/media/twemoji/assets/svg/1f516.svg" srcset="data:image/png;base64,666"><p>帮助</p>
            </a>
          
            <a href="/examples/" id="examples">
              <img src="volantis-static/media/twemoji/assets/svg/1f396.svg" class="lazyload" data-srcset="volantis-static/media/twemoji/assets/svg/1f396.svg" srcset="data:image/png;base64,666"><p>示例</p>
            </a>
          
            <a href="/contributors/" id="contributors">
              <img src="volantis-static/media/twemoji/assets/svg/1f389.svg" class="lazyload" data-srcset="volantis-static/media/twemoji/assets/svg/1f389.svg" srcset="data:image/png;base64,666"><p>社区</p>
            </a>
          
            <a href="/archives/" id="archives">
              <img src="volantis-static/media/twemoji/assets/svg/1f4f0.svg" class="lazyload" data-srcset="volantis-static/media/twemoji/assets/svg/1f4f0.svg" srcset="data:image/png;base64,666"><p>博客</p>
            </a>
          
            <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/volantis-x/hexo-theme-volantis/" id="https:githubcomvolantis-xhexo-theme-volantis">
              <img src="volantis-static/media/twemoji/assets/svg/1f9ec.svg" class="lazyload" data-srcset="volantis-static/media/twemoji/assets/svg/1f9ec.svg" srcset="data:image/png;base64,666"><p>源码</p>
            </a>
          
        
      </div>
    </div>
  </div>
</div>

          <div id="scroll-down" style="display: none;"><i class="fa fa-chevron-down scroll-down-effects"></i></div>
        </div>
    
  
  </div>

    <div id="safearea">
      <div class="body-wrapper" id="pjax-container">
        

<div class="l_main">
  <article class="article post white-box reveal md shadow article-type-post" id="post" itemscope itemprop="blogPost">
  


  
  <div class="article-meta" id="top">
    
    
    
      <h1 class="title">
        RetinaNet论文笔记
      </h1>
      <div class="new-meta-box">
        
          
            
<div class="new-meta-item author">
  <a class="author" target="_blank" href="https://www.cnblogs.com/pistachio0812" rel="external nofollow noopener noreferrer">
    <img no-lazy src="https://img1.baidu.com/it/u=583582599,306470958&fm=253&fmt=auto&app=138&f=JPEG?w=500&h=500">
    <p>追风赶月的少年</p>
  </a>
</div>

          
        
          
            
  <div class="new-meta-item category">
    <a class="notlink">
      <i class="fa-solid fa-folder-open fa-fw" aria-hidden="true"></i>
      <a class="category-link" href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a>
    </a>
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class="notlink">
    <i class="fa-solid fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2022年4月18日</p>
  </a>
</div>

          
        
          
            
  <div class="new-meta-item wordcount">
    <a class="notlink">
      <i class="fa-solid fa-keyboard fa-fw" aria-hidden="true"></i>
      <p>字数：5.8k字</p>
    </a>
  </div>
  <div class="new-meta-item readtime">
    <a class="notlink">
      <i class="fa-solid fa-hourglass-half fa-fw" aria-hidden="true"></i>
      <p>时长：28分钟</p>
    </a>
  </div>


          
        
      </div>
    
  </div>


  
  <p>论文地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://arxiv.org/pdf/1708.02002.pdf">Focal loss for dense object detection</a></p>
<p>源码地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/facebookresearch/Detectron">RetinaNet</a></p>
<p>文章引用代码地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/bubbliiiing/retinanet-pytorch">https://github.com/bubbliiiing/retinanet-pytorch</a></p>
<p>文章出处：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://blog.csdn.net/weixin_44791964/article/details/108319189">https://blog.csdn.net/weixin_44791964/article/details/108319189</a></p>
<h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><p>Retinanet是在何凯明大神提出Focal loss同时提出的一种新的目标检测方案，来验证Focal Loss的有效性。</p>
<p>One-Stage目标检测方法常常使用先验框提高预测性能，一张图像可能生成成千上万的候选框，但是其中只有很少一部分是包含目标的的，有目标的就是正样本，没有目标的就是负样本。这种情况造成了One-Stage目标检测方法的正负样本不平衡，也使得One-Stage目标检测方法的检测效果比不上Two-Stage目标检测方法。</p>
<p>Focal Loss是一种新的用于平衡One-Stage目标检测方法正负样本的Loss方案。</p>
<p>Retinane的结构非常简单，但是其存在非常多的先验框，以输入600x600x3的图片为例，就存在着67995个先验框，这些先验框里面大多包含的是背景，存在非常多的负样本。以Focal Loss训练的Retinanet可以有效的平衡正负样本，实现有效的训练。</p>
<h3 id="预测部分"><a href="#预测部分" class="headerlink" title="预测部分"></a>预测部分</h3><h4 id="主干网络"><a href="#主干网络" class="headerlink" title="主干网络"></a>主干网络</h4><p><style>.kohpccencptc{}</style><img src="/zh-CN/RetinaNet/RetinaNet/image-20220418210603737.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/image-20220418210603737.png" srcset="data:image/png;base64,666"></p>
<p>假设输入的图片大小为600x600x3。</p>
<p>ResNet50有两个基本的块，分别名为Conv Block和Identity Block，其中Conv Block输入和输出的维度是不一样的，所以不能连续串联，它的作用是改变网络的维度；Identity Block输入维度和输出维度相同，可以串联，用于加深网络的。</p>
<p><style>.ayiyftfuogra{}</style><img src="/zh-CN/RetinaNet/RetinaNet/image-20220419095619530.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/image-20220419095619530.png" srcset="data:image/png;base64,666"></p>
<p>当输入的图片为600x600x3的时候，shape变化与总的网络结构如下：</p>
<p><style>.jlayfmdenlvr{zoom:50%;}</style><img src="/zh-CN/RetinaNet/RetinaNet/20200215151533258.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/20200215151533258.png" srcset="data:image/png;base64,666" alt="img"></p>
<p>我们取出长宽压缩了三次、四次、五次的结果来进行网络金字塔结构的构造</p>
<p>实现代码：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch.utils.model_zoo <span class="keyword">as</span> model_zoo</span><br><span class="line"><span class="keyword">import</span> pdb</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_urls = {</span><br><span class="line"><span class="string">'resnet18'</span>: <span class="string">'https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth'</span>,</span><br><span class="line"><span class="string">'resnet34'</span>: <span class="string">'https://s3.amazonaws.com/pytorch/models/resnet34-333f7ec4.pth'</span>,</span><br><span class="line"><span class="string">'resnet50'</span>: <span class="string">'https://s3.amazonaws.com/pytorch/models/resnet50-19c8e357.pth'</span>,</span><br><span class="line"><span class="string">'resnet101'</span>: <span class="string">'https://s3.amazonaws.com/pytorch/models/resnet101-5d3b4d8f.pth'</span>,</span><br><span class="line"><span class="string">'resnet152'</span>: <span class="string">'https://s3.amazonaws.com/pytorch/models/resnet152-b121ed2d.pth'</span>,</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv3x3</span>(<span class="params">in_planes, out_planes, stride=<span class="number">1</span>, groups=<span class="number">1</span>, dilation=<span class="number">1</span></span>):</span><br><span class="line">    <span class="string">"""3x3 convolution with padding"""</span></span><br><span class="line">    <span class="keyword">return</span> nn.Conv2d(in_planes, out_planes, kernel_size=<span class="number">3</span>, stride=stride,</span><br><span class="line">                     padding=dilation, groups=groups, bias=<span class="literal">False</span>, dilation=dilation)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv1x1</span>(<span class="params">in_planes, out_planes, stride=<span class="number">1</span></span>):</span><br><span class="line">    <span class="string">"""1x1 convolution"""</span></span><br><span class="line">    <span class="keyword">return</span> nn.Conv2d(in_planes, out_planes, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(nn.Module):</span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, inplanes, planes, stride=<span class="number">1</span>, downsample=<span class="literal">None</span>, groups=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 base_width=<span class="number">64</span>, dilation=<span class="number">1</span>, norm_layer=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = nn.BatchNorm2d</span><br><span class="line">        <span class="keyword">if</span> groups != <span class="number">1</span> <span class="keyword">or</span> base_width != <span class="number">64</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'BasicBlock only supports groups=1 and base_width=64'</span>)</span><br><span class="line">        <span class="keyword">if</span> dilation &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError(<span class="string">"Dilation &gt; 1 not supported in BasicBlock"</span>)</span><br><span class="line">        <span class="comment"># Both self.conv1 and self.downsample layers downsample the input when stride != 1</span></span><br><span class="line">        self.conv1 = conv3x3(inplanes, planes, stride)</span><br><span class="line">        self.bn1 = norm_layer(planes)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv2 = conv3x3(planes, planes)</span><br><span class="line">        self.bn2 = norm_layer(planes)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        identity = x</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bottleneck</span>(nn.Module):</span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, inplanes, planes, stride=<span class="number">1</span>, downsample=<span class="literal">None</span>, groups=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 base_width=<span class="number">64</span>, dilation=<span class="number">1</span>, norm_layer=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Bottleneck, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = nn.BatchNorm2d</span><br><span class="line">        width = <span class="built_in">int</span>(planes * (base_width / <span class="number">64.</span>)) * groups</span><br><span class="line">        <span class="comment"># Both self.conv2 and self.downsample layers downsample the input when stride != 1</span></span><br><span class="line">        self.conv1 = conv1x1(inplanes, width)</span><br><span class="line">        self.bn1 = norm_layer(width)</span><br><span class="line">        self.conv2 = conv3x3(width, width, stride, groups, dilation)</span><br><span class="line">        self.bn2 = norm_layer(width)</span><br><span class="line">        self.conv3 = conv1x1(width, planes * self.expansion)</span><br><span class="line">        self.bn3 = norm_layer(planes * self.expansion)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        identity = x</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.bn3(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block, layers, num_classes=<span class="number">1000</span></span>):</span><br><span class="line">        self.inplanes = <span class="number">64</span></span><br><span class="line">        <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>,</span><br><span class="line">                    bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, ceil_mode=<span class="literal">True</span>) <span class="comment"># change</span></span><br><span class="line">        self.layer1 = self._make_layer(block, <span class="number">64</span>, layers[<span class="number">0</span>])</span><br><span class="line">        self.layer2 = self._make_layer(block, <span class="number">128</span>, layers[<span class="number">1</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer3 = self._make_layer(block, <span class="number">256</span>, layers[<span class="number">2</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer4 = self._make_layer(block, <span class="number">512</span>, layers[<span class="number">3</span>], stride=<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        self.avgpool = nn.AvgPool2d(<span class="number">7</span>)</span><br><span class="line">        self.fc = nn.Linear(<span class="number">512</span> * block.expansion, num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                n = m.kernel_size[<span class="number">0</span>] * m.kernel_size[<span class="number">1</span>] * m.out_channels</span><br><span class="line">                m.weight.data.normal_(<span class="number">0</span>, math.sqrt(<span class="number">2.</span> / n))</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">                m.weight.data.fill_(<span class="number">1</span>)</span><br><span class="line">                m.bias.data.zero_()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, block, planes, blocks, stride=<span class="number">1</span></span>):</span><br><span class="line">        downsample = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.inplanes != planes * block.expansion:</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(self.inplanes, planes * block.expansion,</span><br><span class="line">                    kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(planes * block.expansion),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(block(self.inplanes, planes, stride, downsample))</span><br><span class="line">        self.inplanes = planes * block.expansion</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, blocks):</span><br><span class="line">            layers.append(block(self.inplanes, planes))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.bn1(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.maxpool(x)</span><br><span class="line"></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        x = self.layer4(x)</span><br><span class="line"></span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet18</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">"""Constructs a ResNet-18 model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    model = ResNet(BasicBlock, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>], **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">'resnet18'</span>], model_dir=<span class="string">'model_data'</span>), strict=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet34</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">"""Constructs a ResNet-34 model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    model = ResNet(BasicBlock, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">'resnet34'</span>], model_dir=<span class="string">'model_data'</span>), strict=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet50</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">"""Constructs a ResNet-50 model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    model = ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">'resnet50'</span>], model_dir=<span class="string">'model_data'</span>), strict=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet101</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">"""Constructs a ResNet-101 model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    model = ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>], **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">'resnet101'</span>], model_dir=<span class="string">'model_data'</span>), strict=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet152</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">"""Constructs a ResNet-152 model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    model = ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">8</span>, <span class="number">36</span>, <span class="number">3</span>], **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">'resnet152'</span>], model_dir=<span class="string">'model_data'</span>), strict=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></tbody></table></figure>
<h4 id="从特征获取预测结果"><a href="#从特征获取预测结果" class="headerlink" title="从特征获取预测结果"></a>从特征获取预测结果</h4><p><style>.rmhhkrdbxykg{}</style><img src="/zh-CN/RetinaNet/RetinaNet/image-20220419100322079.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/image-20220419100322079.png" srcset="data:image/png;base64,666"></p>
<p>由抽象的结构图可知，获得到的特征还需要经过图像金字塔的处理，这样的结构可以融合多尺度的特征，实现更有效的预测。</p>
<p>图像金字塔的具体结构如下：</p>
<p><style>.wvnknkgxszlf{}</style><img src="/zh-CN/RetinaNet/RetinaNet/2020021613520193.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/2020021613520193.png" srcset="data:image/png;base64,666"></p>
<p>通过图像金字塔我们可以获得五个有效的特征层，分别是P3、P4、P5、P6、P7，<br>为了和普通特征层区分，我们称之为有效特征层，将这五个有效的特征层传输过class+box subnets就可以获得预测结果了。</p>
<p>class subnet采用4次256通道的卷积和1次num_anchors x num_classes的卷积，num_anchors指的是该特征层所拥有的先验框数量，num_classes指的是网络一共对多少类的目标进行检测。</p>
<p>box subnet采用4次256通道的卷积和1次num_anchors x 4的卷积，num_anchors指的是该特征层所拥有的先验框数量，4指的是先验框的调整情况。</p>
<p>需要注意的是，每个特征层所用的class subnet是同一个class subnet；每个特征层所用的box subnet是同一个box subnet。</p>
<p><style>.fcjeigvkjpfj{}</style><img src="/zh-CN/RetinaNet/RetinaNet/image-20220419100832971.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/image-20220419100832971.png" srcset="data:image/png;base64,666"></p>
<p>其中：<br>1.num_anchors x 4的卷积 用于预测 该特征层上 每一个网格点上 每一个先验框的变化情况。（为什么说是变化情况呢，这是因为ssd的预测结果需要结合先验框获得预测框，预测结果就是先验框的变化情况。）</p>
<p>2.num_anchors x num_classes的卷积 用于预测 该特征层上 每一个网格点上 每一个预测框对应的种类。<br>实现代码：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F  </span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> nets.resnet <span class="keyword">import</span> resnet18,resnet34,resnet50,resnet101,resnet152</span><br><span class="line"><span class="keyword">from</span> utils.anchors <span class="keyword">import</span> Anchors</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PyramidFeatures</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, C3_size, C4_size, C5_size, feature_size=<span class="number">256</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(PyramidFeatures, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.P5_1 = nn.Conv2d(C5_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P5_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.P4_1 = nn.Conv2d(C4_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P4_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.P3_1 = nn.Conv2d(C3_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P3_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.P6 = nn.Conv2d(C5_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.P7_1 = nn.ReLU()</span><br><span class="line">        self.P7_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        C3, C4, C5 = inputs</span><br><span class="line">        _, _, h4, w4 = C4.size()</span><br><span class="line">        _, _, h3, w3 = C3.size()</span><br><span class="line"></span><br><span class="line">        P5_x = self.P5_1(C5)</span><br><span class="line">        P5_upsampled_x = F.interpolate(P5_x, size=(h4, w4))</span><br><span class="line">        P5_x = self.P5_2(P5_x)</span><br><span class="line"></span><br><span class="line">        P4_x = self.P4_1(C4)</span><br><span class="line">        P4_x = P5_upsampled_x + P4_x</span><br><span class="line">        P4_upsampled_x = F.interpolate(P4_x, size=(h3, w3))</span><br><span class="line">        P4_x = self.P4_2(P4_x)</span><br><span class="line"></span><br><span class="line">        P3_x = self.P3_1(C3)</span><br><span class="line">        P3_x = P3_x + P4_upsampled_x</span><br><span class="line">        P3_x = self.P3_2(P3_x)</span><br><span class="line"></span><br><span class="line">        P6_x = self.P6(C5)</span><br><span class="line"></span><br><span class="line">        P7_x = self.P7_1(P6_x)</span><br><span class="line">        P7_x = self.P7_2(P7_x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [P3_x, P4_x, P5_x, P6_x, P7_x]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RegressionModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features_in, num_anchors=<span class="number">9</span>, feature_size=<span class="number">256</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(RegressionModel, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(num_features_in, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act1 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act2 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act3 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv4 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act4 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.output = nn.Conv2d(feature_size, num_anchors * <span class="number">4</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.act1(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.act2(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.act3(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv4(out)</span><br><span class="line">        out = self.act4(out)</span><br><span class="line"></span><br><span class="line">        out = self.output(out)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># out is B x C x W x H, with C = 4*num_anchors</span></span><br><span class="line">        out = out.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out.contiguous().view(out.shape[<span class="number">0</span>], -<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ClassificationModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features_in, num_anchors=<span class="number">9</span>, num_classes=<span class="number">80</span>, anchor=<span class="number">0.01</span>, feature_size=<span class="number">256</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ClassificationModel, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.num_anchors = num_anchors</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(num_features_in, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act1 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act2 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act3 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv4 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act4 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.output = nn.Conv2d(feature_size, num_anchors * num_classes, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.output_act = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.act1(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.act2(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.act3(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv4(out)</span><br><span class="line">        out = self.act4(out)</span><br><span class="line"></span><br><span class="line">        out = self.output(out)</span><br><span class="line">        out = self.output_act(out)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># out is B x C x W x H, with C = n_classes + n_anchors</span></span><br><span class="line">        out1 = out.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        batch_size, width, height, channels = out1.shape</span><br><span class="line"></span><br><span class="line">        out2 = out1.view(batch_size, width, height, self.num_anchors, self.num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out2.contiguous().view(x.shape[<span class="number">0</span>], -<span class="number">1</span>, self.num_classes)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Resnet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, phi, load_weights=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Resnet, self).__init__()</span><br><span class="line">        self.edition = [resnet18,resnet34,resnet50,resnet101,resnet152]</span><br><span class="line">        model = self.edition[phi](load_weights)</span><br><span class="line">        <span class="keyword">del</span> model.avgpool</span><br><span class="line">        <span class="keyword">del</span> model.fc</span><br><span class="line">        self.model = model</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.model.conv1(x)</span><br><span class="line">        x = self.model.bn1(x)</span><br><span class="line">        x = self.model.relu(x)</span><br><span class="line">        x = self.model.maxpool(x)</span><br><span class="line"></span><br><span class="line">        x = self.model.layer1(x)</span><br><span class="line">        feat1 = self.model.layer2(x)</span><br><span class="line">        feat2 = self.model.layer3(feat1)</span><br><span class="line">        feat3 = self.model.layer4(feat2)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [feat1,feat2,feat3]</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Retinanet</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes, phi, pretrain_weights=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Retinanet, self).__init__()</span><br><span class="line">        self.pretrain_weights = pretrain_weights</span><br><span class="line">        self.backbone_net = Resnet(phi,pretrain_weights)</span><br><span class="line">        fpn_sizes = {</span><br><span class="line">            <span class="number">0</span>: [<span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>],</span><br><span class="line">            <span class="number">1</span>: [<span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>],</span><br><span class="line">            <span class="number">2</span>: [<span class="number">512</span>, <span class="number">1024</span>, <span class="number">2048</span>],</span><br><span class="line">            <span class="number">3</span>: [<span class="number">512</span>, <span class="number">1024</span>, <span class="number">2048</span>],</span><br><span class="line">            <span class="number">4</span>: [<span class="number">512</span>, <span class="number">1024</span>, <span class="number">2048</span>],</span><br><span class="line">        }[phi]</span><br><span class="line"></span><br><span class="line">        self.fpn = PyramidFeatures(fpn_sizes[<span class="number">0</span>], fpn_sizes[<span class="number">1</span>], fpn_sizes[<span class="number">2</span>])</span><br><span class="line">        self.regressionModel = RegressionModel(<span class="number">256</span>)</span><br><span class="line">        self.classificationModel = ClassificationModel(<span class="number">256</span>, num_classes=num_classes)</span><br><span class="line">        self.anchors = Anchors()</span><br><span class="line">        self._init_weights()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_weights</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.pretrain_weights:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">"_init_weights"</span>)</span><br><span class="line">            <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                    n = m.kernel_size[<span class="number">0</span>] * m.kernel_size[<span class="number">1</span>] * m.out_channels</span><br><span class="line">                    m.weight.data.normal_(<span class="number">0</span>, math.sqrt(<span class="number">2.</span> / n))</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">                    m.weight.data.fill_(<span class="number">1</span>)</span><br><span class="line">                    m.bias.data.zero_()</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"_init_classificationModel"</span>)</span><br><span class="line">        anchor = <span class="number">0.01</span></span><br><span class="line">        self.classificationModel.output.weight.data.fill_(<span class="number">0</span>)</span><br><span class="line">        self.classificationModel.output.bias.data.fill_(-math.log((<span class="number">1.0</span> - anchor) / anchor))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"_init_regressionModel"</span>)</span><br><span class="line">        self.regressionModel.output.weight.data.fill_(<span class="number">0</span>)</span><br><span class="line">        self.regressionModel.output.bias.data.fill_(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line"></span><br><span class="line">        p3, p4, p5 = self.backbone_net(inputs)</span><br><span class="line"></span><br><span class="line">        features = self.fpn([p3, p4, p5])</span><br><span class="line"></span><br><span class="line">        regression = torch.cat([self.regressionModel(feature) <span class="keyword">for</span> feature <span class="keyword">in</span> features], dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        classification = torch.cat([self.classificationModel(feature) <span class="keyword">for</span> feature <span class="keyword">in</span> features], dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        anchors = self.anchors(features)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> features, regression, classification, anchors</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="预测结果的解码"><a href="#预测结果的解码" class="headerlink" title="预测结果的解码"></a>预测结果的解码</h4><p>我们通过对每一个特征层的处理，可以获得三个内容，分别是：</p>
<p>num_anchors x 4的卷积 用于预测 该特征层上 每一个网格点上 每一个先验框的变化情况。</p>
<p>num_anchors x num_classes的卷积 用于预测 该特征层上 每一个网格点上 每一个预测框对应的种类。</p>
<p>每一个有效特征层对应的先验框对应着该特征层上 每一个网格点上 预先设定好的9个框。</p>
<p>我们利用 num_anchors x 4的卷积 与 每一个有效特征层对应的先验框 获得框的真实位置。</p>
<p>每一个有效特征层对应的先验框就是，如图所示的作用：<br>每一个有效特征层将整个图片分成与其长宽对应的网格，如P3的特征层就是将整个图像分成75x75个网格；然后从每个网格中心建立9个先验框，一共75x75x9个，50625个先验框</p>
<p><style>.pssspmkzylyj{}</style><img src="/zh-CN/RetinaNet/RetinaNet/20200129210050147.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/20200129210050147.png" srcset="data:image/png;base64,666"></p>
<p>先验框虽然可以代表一定的框的位置信息与框的大小信息，但是其是有限的，无法表示任意情况，因此还需要调整，Retinanet利用4次256通道的卷积+num_anchors x 4的卷积的结果对先验框进行调整。</p>
<p>num_anchors x 4中的num_anchors表示了这个网格点所包含的先验框数量，其中的4表示了框的左上角xy轴，右下角xy的调整情况。</p>
<p>Retinanet解码过程就是将对应的先验框的左上角和右下角进行位置的调整，调整完的结果就是预测框的位置了。</p>
<p>当然得到最终的预测结构后还要进行得分排序与非极大抑制筛选这一部分基本上是所有目标检测通用的部分。<br>1、取出每一类得分大于confidence_threshold的框和得分。<br>2、利用框的位置和得分进行非极大抑制。<br>实现代码：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">decodebox</span>(<span class="params">regression, anchors, img</span>):</span><br><span class="line">    dtype = regression.dtype</span><br><span class="line">    anchors = anchors.to(dtype)</span><br><span class="line">    y_centers_a = (anchors[..., <span class="number">0</span>] + anchors[..., <span class="number">2</span>]) / <span class="number">2</span></span><br><span class="line">    x_centers_a = (anchors[..., <span class="number">1</span>] + anchors[..., <span class="number">3</span>]) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    ha = anchors[..., <span class="number">2</span>] - anchors[..., <span class="number">0</span>]</span><br><span class="line">    wa = anchors[..., <span class="number">3</span>] - anchors[..., <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    w = regression[..., <span class="number">3</span>].exp() * wa</span><br><span class="line">    h = regression[..., <span class="number">2</span>].exp() * ha</span><br><span class="line"></span><br><span class="line">    y_centers = regression[..., <span class="number">0</span>] * ha + y_centers_a</span><br><span class="line">    x_centers = regression[..., <span class="number">1</span>] * wa + x_centers_a</span><br><span class="line"></span><br><span class="line">    ymin = y_centers - h / <span class="number">2.</span></span><br><span class="line">    xmin = x_centers - w / <span class="number">2.</span></span><br><span class="line">    ymax = y_centers + h / <span class="number">2.</span></span><br><span class="line">    xmax = x_centers + w / <span class="number">2.</span></span><br><span class="line"></span><br><span class="line">    boxes = torch.stack([xmin, ymin, xmax, ymax], dim=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    _, _, height, width = np.shape(img)</span><br><span class="line"></span><br><span class="line">    boxes[:, :, <span class="number">0</span>] = torch.clamp(boxes[:, :, <span class="number">0</span>], <span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line">    boxes[:, :, <span class="number">1</span>] = torch.clamp(boxes[:, :, <span class="number">1</span>], <span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    boxes[:, :, <span class="number">2</span>] = torch.clamp(boxes[:, :, <span class="number">2</span>], <span class="built_in">max</span>=width - <span class="number">1</span>)</span><br><span class="line">    boxes[:, :, <span class="number">3</span>] = torch.clamp(boxes[:, :, <span class="number">3</span>], <span class="built_in">max</span>=height - <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># fig = plt.figure()</span></span><br><span class="line">    <span class="comment"># ax = fig.add_subplot(121)</span></span><br><span class="line">    <span class="comment"># grid_x = x_centers_a[0,-4*4*9:]</span></span><br><span class="line">    <span class="comment"># grid_y = y_centers_a[0,-4*4*9:]</span></span><br><span class="line">    <span class="comment"># plt.ylim(-600,1200)</span></span><br><span class="line">    <span class="comment"># plt.xlim(-600,1200)</span></span><br><span class="line">    <span class="comment"># plt.gca().invert_yaxis()</span></span><br><span class="line">    <span class="comment"># plt.scatter(grid_x.cpu(),grid_y.cpu())</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># anchor_left = anchors[0,-4*4*9:,1]</span></span><br><span class="line">    <span class="comment"># anchor_top = anchors[0,-4*4*9:,0]</span></span><br><span class="line">    <span class="comment"># anchor_w = wa[0,-4*4*9:]</span></span><br><span class="line">    <span class="comment"># anchor_h = ha[0,-4*4*9:]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># for i in range(9,18):</span></span><br><span class="line">    <span class="comment">#     rect1 = plt.Rectangle([anchor_left[i],anchor_top[i]],anchor_w[i],anchor_h[i],color="r",fill=False)</span></span><br><span class="line">    <span class="comment">#     ax.add_patch(rect1)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ax = fig.add_subplot(122)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># grid_x = x_centers_a[0,-4*4*9:]</span></span><br><span class="line">    <span class="comment"># grid_y = y_centers_a[0,-4*4*9:]</span></span><br><span class="line">    <span class="comment"># plt.scatter(grid_x.cpu(),grid_y.cpu())</span></span><br><span class="line">    <span class="comment"># plt.ylim(-600,1200)</span></span><br><span class="line">    <span class="comment"># plt.xlim(-600,1200)</span></span><br><span class="line">    <span class="comment"># plt.gca().invert_yaxis()</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># y_centers = y_centers[0,-4*4*9:]</span></span><br><span class="line">    <span class="comment"># x_centers = x_centers[0,-4*4*9:]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># pre_left = xmin[0,-4*4*9:]</span></span><br><span class="line">    <span class="comment"># pre_top = ymin[0,-4*4*9:]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># pre_w = xmax[0,-4*4*9:]-xmin[0,-4*4*9:]</span></span><br><span class="line">    <span class="comment"># pre_h = ymax[0,-4*4*9:]-ymin[0,-4*4*9:]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># for i in range(9,18):</span></span><br><span class="line">    <span class="comment">#     plt.scatter(x_centers[i].cpu(),y_centers[i].cpu(),c='r')</span></span><br><span class="line">    <span class="comment">#     rect1 = plt.Rectangle([pre_left[i],pre_top[i]],pre_w[i],pre_h[i],color="r",fill=False)</span></span><br><span class="line">    <span class="comment">#     ax.add_patch(rect1)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line">    <span class="keyword">return</span> boxes</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">retinanet_correct_boxes</span>(<span class="params">box_xy, box_wh, input_shape, image_shape, letterbox_image</span>):</span><br><span class="line">    <span class="comment">#-----------------------------------------------------------------#</span></span><br><span class="line">    <span class="comment">#   把y轴放前面是因为方便预测框和图像的宽高进行相乘</span></span><br><span class="line">    <span class="comment">#-----------------------------------------------------------------#</span></span><br><span class="line">    box_yx = box_xy[..., ::-<span class="number">1</span>]</span><br><span class="line">    box_hw = box_wh[..., ::-<span class="number">1</span>]</span><br><span class="line">    input_shape = np.array(input_shape)</span><br><span class="line">    image_shape = np.array(image_shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> letterbox_image:</span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   这里求出来的offset是图像有效区域相对于图像左上角的偏移情况</span></span><br><span class="line">        <span class="comment">#   new_shape指的是宽高缩放情况</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------#</span></span><br><span class="line">        new_shape = np.<span class="built_in">round</span>(image_shape * np.<span class="built_in">min</span>(input_shape/image_shape))</span><br><span class="line">        offset  = (input_shape - new_shape)/<span class="number">2.</span>/input_shape</span><br><span class="line">        scale   = input_shape/new_shape</span><br><span class="line"></span><br><span class="line">        box_yx  = (box_yx - offset) * scale</span><br><span class="line">        box_hw *= scale</span><br><span class="line"></span><br><span class="line">    box_mins    = box_yx - (box_hw / <span class="number">2.</span>)</span><br><span class="line">    box_maxes   = box_yx + (box_hw / <span class="number">2.</span>)</span><br><span class="line">    boxes  = np.concatenate([box_mins[..., <span class="number">0</span>:<span class="number">1</span>], box_mins[..., <span class="number">1</span>:<span class="number">2</span>], box_maxes[..., <span class="number">0</span>:<span class="number">1</span>], box_maxes[..., <span class="number">1</span>:<span class="number">2</span>]], axis=-<span class="number">1</span>)</span><br><span class="line">    boxes *= np.concatenate([image_shape, image_shape], axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> boxes</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">non_max_suppression</span>(<span class="params">prediction, input_shape, image_shape, letterbox_image, conf_thres=<span class="number">0.5</span>, nms_thres=<span class="number">0.4</span></span>):</span><br><span class="line">    output = [<span class="literal">None</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(prediction))]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">    <span class="comment">#   预测只用一张图片，只会进行一次</span></span><br><span class="line">    <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">    <span class="keyword">for</span> i, image_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(prediction):</span><br><span class="line">        <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   对种类预测部分取max。</span></span><br><span class="line">        <span class="comment">#   class_conf  [num_anchors, 1]    种类置信度</span></span><br><span class="line">        <span class="comment">#   class_pred  [num_anchors, 1]    种类</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">        class_conf, class_pred = torch.<span class="built_in">max</span>(image_pred[:, <span class="number">4</span>:], <span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   利用置信度进行第一轮筛选</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">        conf_mask = (class_conf[:, <span class="number">0</span>] &gt;= conf_thres).squeeze()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   根据置信度进行预测结果的筛选</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">        image_pred = image_pred[conf_mask]</span><br><span class="line">        class_conf = class_conf[conf_mask]</span><br><span class="line">        class_pred = class_pred[conf_mask]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> image_pred.size(<span class="number">0</span>):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment">#-------------------------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   detections  [num_anchors, 6]</span></span><br><span class="line">        <span class="comment">#   6的内容为：x1, y1, x2, y2, class_conf, class_pred</span></span><br><span class="line">        <span class="comment">#-------------------------------------------------------------------------#</span></span><br><span class="line">        detections = torch.cat((image_pred[:, :<span class="number">4</span>], class_conf.<span class="built_in">float</span>(), class_pred.<span class="built_in">float</span>()), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   获得预测结果中包含的所有种类</span></span><br><span class="line">        <span class="comment">#------------------------------------------#</span></span><br><span class="line">        unique_labels = detections[:, -<span class="number">1</span>].cpu().unique()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> prediction.is_cuda:</span><br><span class="line">            unique_labels = unique_labels.cuda()</span><br><span class="line">            detections = detections.cuda()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> unique_labels:</span><br><span class="line">            <span class="comment">#------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   获得某一类得分筛选后全部的预测结果</span></span><br><span class="line">            <span class="comment">#------------------------------------------#</span></span><br><span class="line">            detections_class = detections[detections[:, -<span class="number">1</span>] == c]</span><br><span class="line"></span><br><span class="line">            <span class="comment">#------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   使用官方自带的非极大抑制会速度更快一些！</span></span><br><span class="line">            <span class="comment">#------------------------------------------#</span></span><br><span class="line">            keep = nms(</span><br><span class="line">                detections_class[:, :<span class="number">4</span>],</span><br><span class="line">                detections_class[:, <span class="number">4</span>],</span><br><span class="line">                nms_thres</span><br><span class="line">            )</span><br><span class="line">            max_detections = detections_class[keep]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># #------------------------------------------#</span></span><br><span class="line">            <span class="comment"># #   按照存在物体的置信度排序</span></span><br><span class="line">            <span class="comment"># #------------------------------------------#</span></span><br><span class="line">            <span class="comment"># _, conf_sort_index = torch.sort(detections_class[:, 4], descending=True)</span></span><br><span class="line">            <span class="comment"># detections_class = detections_class[conf_sort_index]</span></span><br><span class="line">            <span class="comment"># #------------------------------------------#</span></span><br><span class="line">            <span class="comment"># #   进行非极大抑制</span></span><br><span class="line">            <span class="comment"># #------------------------------------------#</span></span><br><span class="line">            <span class="comment"># max_detections = []</span></span><br><span class="line">            <span class="comment"># while detections_class.size(0):</span></span><br><span class="line">            <span class="comment">#     #---------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#     #   取出这一类置信度最高的，一步一步往下判断。</span></span><br><span class="line">            <span class="comment">#     #   判断重合程度是否大于nms_thres，如果是则去除掉</span></span><br><span class="line">            <span class="comment">#     #---------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#     max_detections.append(detections_class[0].unsqueeze(0))</span></span><br><span class="line">            <span class="comment">#     if len(detections_class) == 1:</span></span><br><span class="line">            <span class="comment">#         break</span></span><br><span class="line">            <span class="comment">#     ious = bbox_iou(max_detections[-1], detections_class[1:])</span></span><br><span class="line">            <span class="comment">#     detections_class = detections_class[1:][ious &lt; nms_thres]</span></span><br><span class="line">            <span class="comment"># #------------------------------------------#</span></span><br><span class="line">            <span class="comment"># #   堆叠</span></span><br><span class="line">            <span class="comment"># #------------------------------------------#</span></span><br><span class="line">            <span class="comment"># max_detections = torch.cat(max_detections).data</span></span><br><span class="line">            </span><br><span class="line">            output[i] = max_detections <span class="keyword">if</span> output[i] <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> torch.cat((output[i], max_detections))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> output[i] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            output[i]           = output[i].cpu().numpy()</span><br><span class="line">            box_xy, box_wh      = (output[i][:, <span class="number">0</span>:<span class="number">2</span>] + output[i][:, <span class="number">2</span>:<span class="number">4</span>])/<span class="number">2</span>, output[i][:, <span class="number">2</span>:<span class="number">4</span>] - output[i][:, <span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line">            output[i][:, :<span class="number">4</span>]    = retinanet_correct_boxes(box_xy, box_wh, input_shape, image_shape, letterbox_image)</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="原图上进行绘制"><a href="#原图上进行绘制" class="headerlink" title="原图上进行绘制"></a>原图上进行绘制</h4><p>通过第三步，我们可以获得预测框在原图上的位置，而且这些预测框都是经过筛选的。这些筛选后的框可以直接绘制在图片上，就可以获得结果了。</p>
<h3 id="训练部分"><a href="#训练部分" class="headerlink" title="训练部分"></a>训练部分</h3><h4 id="真实框的处理"><a href="#真实框的处理" class="headerlink" title="真实框的处理"></a>真实框的处理</h4><p>从预测部分我们知道，每个特征层的预测结果，num_anchors x 4的卷积 用于预测 该特征层上 每一个网格点上 每一个先验框的变化情况。</p>
<p>也就是说，我们直接利用retinanet网络预测到的结果，并不是预测框在图片上的真实位置，需要解码才能得到真实位置。</p>
<p>而在训练的时候，我们需要计算loss函数，这个loss函数是相对于Retinanet网络的预测结果的。我们需要把图片输入到当前的Retinanet网络中，得到预测结果；同时还需要把真实框的信息，进行编码，这个编码是把真实框的位置信息格式转化为Retinanet预测结果的格式信息。</p>
<p>也就是，我们需要找到 每一张用于训练的图片的每一个真实框对应的先验框，并求出如果想要得到这样一个真实框，我们的预测结果应该是怎么样的。</p>
<p>从预测结果获得真实框的过程被称作解码，而从真实框获得预测结果的过程就是编码的过程。</p>
<p>因此我们只需要将解码过程逆过来就是编码过程了。</p>
<p>在进行编码的时候，我们需要找到每一个真实框对应的先验框，我们把和真实框重合程度在0.5以上的作为正样本，在0.4以下的作为负样本，在0.4和0.5之间的作为忽略样本。<br>实现代码：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_target</span>(<span class="params">anchor, bbox_annotation, classification, cuda</span>):</span><br><span class="line">    IoU = calc_iou(anchor[:, :], bbox_annotation[:, :<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">    IoU_max, IoU_argmax = torch.<span class="built_in">max</span>(IoU, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute the loss for classification</span></span><br><span class="line">    targets = torch.ones_like(classification) * -<span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> cuda:</span><br><span class="line">        targets = targets.cuda()</span><br><span class="line"></span><br><span class="line">    targets[torch.lt(IoU_max, <span class="number">0.4</span>), :] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    positive_indices = torch.ge(IoU_max, <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    num_positive_anchors = positive_indices.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">    assigned_annotations = bbox_annotation[IoU_argmax, :]</span><br><span class="line"></span><br><span class="line">    targets[positive_indices, :] = <span class="number">0</span></span><br><span class="line">    targets[positive_indices, assigned_annotations[positive_indices, <span class="number">4</span>].long()] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> targets, num_positive_anchors, positive_indices, assigned_annotations</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">encode_bbox</span>(<span class="params">assigned_annotations, positive_indices, anchor_widths, anchor_heights, anchor_ctr_x, anchor_ctr_y</span>):</span><br><span class="line">    assigned_annotations = assigned_annotations[positive_indices, :]</span><br><span class="line"></span><br><span class="line">    anchor_widths_pi = anchor_widths[positive_indices]</span><br><span class="line">    anchor_heights_pi = anchor_heights[positive_indices]</span><br><span class="line">    anchor_ctr_x_pi = anchor_ctr_x[positive_indices]</span><br><span class="line">    anchor_ctr_y_pi = anchor_ctr_y[positive_indices]</span><br><span class="line"></span><br><span class="line">    gt_widths = assigned_annotations[:, <span class="number">2</span>] - assigned_annotations[:, <span class="number">0</span>]</span><br><span class="line">    gt_heights = assigned_annotations[:, <span class="number">3</span>] - assigned_annotations[:, <span class="number">1</span>]</span><br><span class="line">    gt_ctr_x = assigned_annotations[:, <span class="number">0</span>] + <span class="number">0.5</span> * gt_widths</span><br><span class="line">    gt_ctr_y = assigned_annotations[:, <span class="number">1</span>] + <span class="number">0.5</span> * gt_heights</span><br><span class="line"></span><br><span class="line">    <span class="comment"># efficientdet style</span></span><br><span class="line">    gt_widths = torch.clamp(gt_widths, <span class="built_in">min</span>=<span class="number">1</span>)</span><br><span class="line">    gt_heights = torch.clamp(gt_heights, <span class="built_in">min</span>=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    targets_dx = (gt_ctr_x - anchor_ctr_x_pi) / anchor_widths_pi</span><br><span class="line">    targets_dy = (gt_ctr_y - anchor_ctr_y_pi) / anchor_heights_pi</span><br><span class="line">    targets_dw = torch.log(gt_widths / anchor_widths_pi)</span><br><span class="line">    targets_dh = torch.log(gt_heights / anchor_heights_pi)</span><br><span class="line"></span><br><span class="line">    targets = torch.stack((targets_dy, targets_dx, targets_dh, targets_dw))</span><br><span class="line">    targets = targets.t()</span><br><span class="line">    <span class="keyword">return</span> targets</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="loss计算"><a href="#loss计算" class="headerlink" title="loss计算"></a>loss计算</h4><p>loss的计算分为两个部分：<br>1、Smooth Loss：获取所有正标签的框的预测结果的回归loss。<br>2、Focal Loss：获取所有未被忽略的种类的预测结果的交叉熵loss。</p>
<p>由于在Retinanet的训练过程中，正负样本极其不平衡，即 存在对应真实框的先验框可能只有若干个，但是不存在对应真实框的负样本却有上万个，这就会导致负样本的loss值极大，因此引入了Focal Loss进行正负样本的平衡。</p>
<p>Focal loss是何恺明大神提出的一种新的loss计算方案。其具有两个重要的特点。</p>
<p>a)控制正负样本的权重<br>控制容易分类和难分类样本的权重<br>正负样本的概念如下：<br>一张图像可能生成成千上万的候选框，但是其中只有很少一部分是包含目标的的，有目标的就是正样本，没有目标的就是负样本。</p>
<p>容易分类和难分类样本的概念如下：<br>假设存在一个二分类，样本1属于类别1的pt=0.9，样本2属于类别1的pt=0.6，显然前者更可能是类别1，其就是容易分类的样本；后者有可能是类别1，所以其为难分类样本。</p>
<p>如何实现权重控制呢：<br>以二分类为例，常用交叉熵loss:</p>
<p><style>.rmvtltqnqlyb{zoom:50%;}</style><img src="/zh-CN/RetinaNet/RetinaNet/20191101111610548.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/20191101111610548.png" srcset="data:image/png;base64,666" alt="img"></p>
<p>利用pt简化交叉熵损失：</p>
<p><style>.cixoctuvvdwd{zoom:50%;}</style><img src="/zh-CN/RetinaNet/RetinaNet/20191101111700950.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/20191101111700950.png" srcset="data:image/png;base64,666" alt="在这里插入图片描述"></p>
<p>因此得到：</p>
<p><style>.xdvwsukcwsmd{zoom:50%;}</style><img src="/zh-CN/RetinaNet/RetinaNet/20191101111712727.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/20191101111712727.png" srcset="data:image/png;base64,666" alt="在这里插入图片描述"></p>
<p><strong>想要降低负样本的影响，可以在常规的损失函数前增加一个系数αt。与Pt类似，当label=1的时候，αt=α；当label=otherwise的时候，αt=1 - α，a的范围也是0到1。此时我们便可以通过设置α实现控制正负样本对loss的贡献</strong><style>.vssxnmdwwmko{zoom:50%;}</style><img src="/zh-CN/RetinaNet/RetinaNet/2019110111235956.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/2019110111235956.png" srcset="data:image/png;base64,666" alt="在这里插入图片描述"></p>
<p>其中：</p>
<p><style>.coqbvbcwmpuv{zoom:50%;}</style><img src="/zh-CN/RetinaNet/RetinaNet/20200214164001867.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/20200214164001867.png" srcset="data:image/png;base64,666" alt="在这里插入图片描述"></p>
<p>分解：</p>
<p><style>.ysjjceuidmcv{zoom:50%;}</style><img src="/zh-CN/RetinaNet/RetinaNet/20200214164354541.jpg" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/20200214164354541.jpg" srcset="data:image/png;base64,666" alt="在这里插入图片描述"></p>
<p>b)控制容易分类和难分类样本的权重</p>
<p>按照刚才的思路，一个二分类，样本1属于类别1的pt=0.9，样本2属于类别1的pt=0.6，也就是 <strong>是某个类的概率越大，其越容易分类</strong> 所以利用1-Pt就可以计算出其属于容易分类或者难分类。<br>具体实现方式如下。</p>
<p><style>.ffxgrlwyugur{zoom:50%;}</style><img src="/zh-CN/RetinaNet/RetinaNet/20191101113143598.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/20191101113143598.png" srcset="data:image/png;base64,666" alt="在这里插入图片描述"></p>
<p>其中调制系数为：</p>
<p><style>.exdgojkqfdsd{zoom:50%;}</style><img src="/zh-CN/RetinaNet/RetinaNet/image-20220419103637923.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/image-20220419103637923.png" srcset="data:image/png;base64,666" alt="image-20220419103637923"></p>
<p>1、当pt趋于0的时候，调制系数趋于1，对于总的loss的贡献很大。当pt趋于1的时候，调制系数趋于0，也就是对于总的loss的贡献很小。<br>2、当γ=0的时候，focal loss就是传统的交叉熵损失，可以通过调整γ实现调制系数的改变。</p>
<p>c）两种权重控制方法合并<br>通过如下公式就可以实现控制正负样本的权重和控制容易分类和难分类样本的权重。</p>
<p><style>.sjjlpfncnqwh{zoom:50%;}</style><img src="/zh-CN/RetinaNet/RetinaNet/20191101114056207.png" class="lazyload" data-srcset="/zh-CN/RetinaNet/RetinaNet/20191101114056207.png" srcset="data:image/png;base64,666" alt="在这里插入图片描述"></p>
<p>实现代码：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FocalLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(FocalLoss, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, classifications, regressions, anchors, annotations, alpha = <span class="number">0.25</span>, gamma = <span class="number">2.0</span>, cuda = <span class="literal">True</span></span>):</span><br><span class="line">        <span class="comment"># 设置</span></span><br><span class="line">        dtype = regressions.dtype</span><br><span class="line">        batch_size = classifications.shape[<span class="number">0</span>]</span><br><span class="line">        classification_losses = []</span><br><span class="line">        regression_losses = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获得先验框，将先验框转换成中心宽高的形势</span></span><br><span class="line">        anchor = anchors[<span class="number">0</span>, :, :].to(dtype)</span><br><span class="line">        <span class="comment"># 转换成中心，宽高的形式</span></span><br><span class="line">        anchor_widths = anchor[:, <span class="number">3</span>] - anchor[:, <span class="number">1</span>]</span><br><span class="line">        anchor_heights = anchor[:, <span class="number">2</span>] - anchor[:, <span class="number">0</span>]</span><br><span class="line">        anchor_ctr_x = anchor[:, <span class="number">1</span>] + <span class="number">0.5</span> * anchor_widths</span><br><span class="line">        anchor_ctr_y = anchor[:, <span class="number">0</span>] + <span class="number">0.5</span> * anchor_heights</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">            <span class="comment"># 取出真实框</span></span><br><span class="line">            bbox_annotation = annotations[j]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 获得每张图片的分类结果和回归预测结果</span></span><br><span class="line">            classification = classifications[j, :, :]</span><br><span class="line">            regression = regressions[j, :, :]</span><br><span class="line">            <span class="comment"># 平滑标签</span></span><br><span class="line">            classification = torch.clamp(classification, <span class="number">1e-4</span>, <span class="number">1.0</span> - <span class="number">1e-4</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(bbox_annotation) == <span class="number">0</span>:</span><br><span class="line">                alpha_factor = torch.ones_like(classification) * alpha</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> cuda:</span><br><span class="line">                    alpha_factor = alpha_factor.cuda()</span><br><span class="line">                alpha_factor = <span class="number">1.</span> - alpha_factor</span><br><span class="line">                focal_weight = classification</span><br><span class="line">                focal_weight = alpha_factor * torch.<span class="built_in">pow</span>(focal_weight, gamma)</span><br><span class="line">                </span><br><span class="line">                bce = -(torch.log(<span class="number">1.0</span> - classification))</span><br><span class="line">                </span><br><span class="line">                cls_loss = focal_weight * bce</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> cuda:</span><br><span class="line">                    regression_losses.append(torch.tensor(<span class="number">0</span>).to(dtype).cuda())</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    regression_losses.append(torch.tensor(<span class="number">0</span>).to(dtype))</span><br><span class="line">                classification_losses.append(cls_loss.<span class="built_in">sum</span>())</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 获得目标预测结果</span></span><br><span class="line">            targets, num_positive_anchors, positive_indices, assigned_annotations = get_target(anchor, bbox_annotation, classification, cuda)</span><br><span class="line">            </span><br><span class="line">            alpha_factor = torch.ones_like(targets) * alpha</span><br><span class="line">            <span class="keyword">if</span> cuda:</span><br><span class="line">                alpha_factor = alpha_factor.cuda()</span><br><span class="line">            alpha_factor = torch.where(torch.eq(targets, <span class="number">1.</span>), alpha_factor, <span class="number">1.</span> - alpha_factor)</span><br><span class="line">            focal_weight = torch.where(torch.eq(targets, <span class="number">1.</span>), <span class="number">1.</span> - classification, classification)</span><br><span class="line">            focal_weight = alpha_factor * torch.<span class="built_in">pow</span>(focal_weight, gamma)</span><br><span class="line"></span><br><span class="line">            bce = -(targets * torch.log(classification) + (<span class="number">1.0</span> - targets) * torch.log(<span class="number">1.0</span> - classification))</span><br><span class="line"></span><br><span class="line">            cls_loss = focal_weight * bce</span><br><span class="line"></span><br><span class="line">            zeros = torch.zeros_like(cls_loss)</span><br><span class="line">            <span class="keyword">if</span> cuda:</span><br><span class="line">                zeros = zeros.cuda()</span><br><span class="line">            cls_loss = torch.where(torch.ne(targets, -<span class="number">1.0</span>), cls_loss, zeros)</span><br><span class="line">            classification_losses.append(cls_loss.<span class="built_in">sum</span>() / torch.clamp(num_positive_anchors.to(dtype), <span class="built_in">min</span>=<span class="number">1.0</span>))</span><br><span class="line">            <span class="comment"># smoooth_l1</span></span><br><span class="line">            <span class="keyword">if</span> positive_indices.<span class="built_in">sum</span>() &gt; <span class="number">0</span>:</span><br><span class="line">                targets = encode_bbox(assigned_annotations, positive_indices, anchor_widths, anchor_heights, anchor_ctr_x, anchor_ctr_y)</span><br><span class="line">               </span><br><span class="line">                regression_diff = torch.<span class="built_in">abs</span>(targets - regression[positive_indices, :])</span><br><span class="line"></span><br><span class="line">                regression_loss = torch.where(</span><br><span class="line">                    torch.le(regression_diff, <span class="number">1.0</span> / <span class="number">9.0</span>),</span><br><span class="line">                    <span class="number">0.5</span> * <span class="number">9.0</span> * torch.<span class="built_in">pow</span>(regression_diff, <span class="number">2</span>),</span><br><span class="line">                    regression_diff - <span class="number">0.5</span> / <span class="number">9.0</span></span><br><span class="line">                )</span><br><span class="line">                regression_losses.append(regression_loss.mean())</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> cuda:</span><br><span class="line">                    regression_losses.append(torch.tensor(<span class="number">0</span>).to(dtype).cuda())</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    regression_losses.append(torch.tensor(<span class="number">0</span>).to(dtype))</span><br><span class="line">        c_loss = torch.stack(classification_losses).mean()</span><br><span class="line">        r_loss = torch.stack(regression_losses).mean()</span><br><span class="line">        loss = c_loss + r_loss</span><br><span class="line">        <span class="keyword">return</span> loss, c_loss, r_loss</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

  
  
    
    <div class="footer">
      
      
      
      
        <div class="donate">
          <div class="imgs">
            
              <img src="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png" srcset="data:image/png;base64,666">
            
              <img src="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png" srcset="data:image/png;base64,666">
            
          </div>
        </div>
      
    </div>
  
  
    


  <div class="article-meta" id="bottom">
    <div class="new-meta-box">
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2022-10-04T21:28:09+08:00">
  <a class="notlink">
    <i class="fa-solid fa-edit fa-fw" aria-hidden="true"></i>
    <p>更新于：2022年10月4日</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" rel="nofollow"><i class="fa-solid fa-hashtag fa-fw" aria-hidden="true"></i><p>论文笔记</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/retinanet/" rel="nofollow"><i class="fa-solid fa-hashtag fa-fw" aria-hidden="true"></i><p>retinanet</p></a></div>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title rel="external nofollow noopener noreferrer" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://pistachio0812.github.io/zh-CN/RetinaNet/&title=RetinaNet论文笔记 - 阿月浑子-Hexo博客&summary=">
          
            <img src="volantis-static/media/org.volantis/logo/128/qq.png" class="lazyload" data-srcset="volantis-static/media/org.volantis/logo/128/qq.png" srcset="data:image/png;base64,666">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title rel="external nofollow noopener noreferrer" target="_blank" href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://pistachio0812.github.io/zh-CN/RetinaNet/&title=RetinaNet论文笔记 - 阿月浑子-Hexo博客&summary=">
          
            <img src="volantis-static/media/org.volantis/logo/128/qzone.png" class="lazyload" data-srcset="volantis-static/media/org.volantis/logo/128/qzone.png" srcset="data:image/png;base64,666">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title rel="external nofollow noopener noreferrer" target="_blank" href="http://service.weibo.com/share/share.php?url=http://pistachio0812.github.io/zh-CN/RetinaNet/&title=RetinaNet论文笔记 - 阿月浑子-Hexo博客&summary=">
          
            <img src="volantis-static/media/org.volantis/logo/128/weibo.png" class="lazyload" data-srcset="volantis-static/media/org.volantis/logo/128/weibo.png" srcset="data:image/png;base64,666">
          
        </a>
      
    
      
        
        <div class="hoverbox">
          <a class="share"><img src="volantis-static/media/org.volantis/logo/128/wechat.png" class="lazyload" data-srcset="volantis-static/media/org.volantis/logo/128/wechat.png" srcset="data:image/png;base64,666"></a>
          <div class="target">
            <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAEYCAAAAACi5bZQAAAC/0lEQVR42u3aS1LEMAwFwLn/pWFPQcVPUoYI2rv5eezO5pWk14f17XohAAMGDBgwYNbAvIrr6+/LBxn+3/Z9wIABAwYMGDDrYNKLpAe5+n36eupBgQEDBgwYMGD+DsxUsJq6yNX/VR8cGDBgwIABAwbMKUg1OKbfAwMGDBgwYMCA6Qayq32qwRAMGDBgwIABA2aqQVUNYGmjrlvYensnEgwYMGDAgAHzNpjqgZ/6unwfMGDAgAEDBswamO66u6A1Hegu7wMGDBgwYMCAWQNTHQRKfzfVmEsHi+J7ggEDBgwYMGDWwFQDW/dgdw8Ile8FBgwYMGDAgFkDkwa3boBLC05TDbXj/cGAAQMGDBgwa2DSgJQGp3S/0wZf+r3jBwoGDBgwYMCAWQczBVQ9cHXfajAdq+CBAQMGDBgwYH4NZmpQqDtIVG34dQtoPwY8MGDAgAEDBswamG4Q6x5oCqhd4AIDBgwYMGDArIPpXij9vAqUBrn4HmDAgAEDBgyYdTB3F66qgFOFsXbyBQMGDBgwYMA8DmZ84xCu2ihL9zt+HwwYMGDAgAGzBiYtVKVw1QGi0wJXGijbE1VgwIABAwYMmMfAnG6QFp6qQax7rtNzx4UqMGDAgAEDBszjYKYKQ3cVoNJA2C5sgQEDBgwYMGDWw0wfoNuYS4NlufAFBgwYMGDAgFkDMz1AlA7uTA0cTcGDAQMGDBgwYPbBpBdOA18VOA2Ip0Gu3IkEAwYMGDBgwDwGplpIqha00s+nGoJjFTwwYMCAAQMGzGNguus0sHUDXPVBxYNMYMCAAQMGDJg1MFODzdUBoimwboEKDBgwYMCAAbMXplpwqoJ0waYGmeIKHhgwYMCAAQPmsTDVwtDpgFBaWJpaxwESDBgwYMCAAfNvYLoDRqdB8PR83cYbGDBgwIABA+b/wqQHnXq/eo63BTwwYMCAAQMGzO0w1QtNNdKm/ycOkGDAgAEDBgyYdTDdBla1cXYKNBbgriDBgAEDBgwYMGtgLDBgwIABAwbMsvUJRw/kHVspYwEAAAAASUVORK5CYII=">
          </div>
        </div>
      
    
      
    
  </div>
</div>



        
      
    </div>
  </div>


  
  

  
    <div class="prev-next">
      
        <a class="prev" href="/zh-CN/%E6%95%B0%E6%8D%AE%E9%9B%86/">
          <p class="title"><i class="fas fa-chevron-left" aria-hidden="true"></i>数据集介绍</p>
          <p class="content">参考博文1.针对 VOC2007和VOC2012 的具体用法
2.Pascal Voc（07+12）联合训练并在07上测试
VOC2007和VOC2012用法目前广大研究者们普遍使用的是 VOC...</p>
        </a>
      
      
        <a class="next" href="/zh-CN/centernet/">
          <p class="title">CenterNet论文笔记<i class="fas fa-chevron-right" aria-hidden="true"></i></p>
          <p class="content">论文地址：CenterNet: Keypoint Triplets for Object Detection (thecvf.com)
源码地址： CenterNet: Keypoint Tri...</p>
        </a>
      
    </div>
  
</article>


  

  






</div>
<aside class="l_side">
  
  
    
    



  <section class="widget toc-wrapper sticky shadow desktop mobile" id="toc-div">
    
  <header>
    
      <i class="fa-solid fa-list fa-fw" aria-hidden="true"></i><span class="name">本文目录</span>
    
  </header>


    <div class="content">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E6%80%9D%E8%B7%AF"><span class="toc-text">实现思路</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E9%83%A8%E5%88%86"><span class="toc-text">预测部分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E5%B9%B2%E7%BD%91%E7%BB%9C"><span class="toc-text">主干网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8E%E7%89%B9%E5%BE%81%E8%8E%B7%E5%8F%96%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C"><span class="toc-text">从特征获取预测结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E7%9A%84%E8%A7%A3%E7%A0%81"><span class="toc-text">预测结果的解码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E7%BB%98%E5%88%B6"><span class="toc-text">原图上进行绘制</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E9%83%A8%E5%88%86"><span class="toc-text">训练部分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9C%9F%E5%AE%9E%E6%A1%86%E7%9A%84%E5%A4%84%E7%90%86"><span class="toc-text">真实框的处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#loss%E8%AE%A1%E7%AE%97"><span class="toc-text">loss计算</span></a></li></ol></li></ol></li></ol>
    </div>
  </section>


  


</aside>



        
        
          <!--此文件用来存放一些不方便取值的变量-->
<!--思路大概是将值藏到重加载的区域内-->

<script>
  window.pdata={}
  pdata.ispage=true;
  pdata.postTitle="RetinaNet论文笔记";
  pdata.commentPath="";
  pdata.commentPlaceholder="";

  var l_header=document.getElementById("l_header");
  
  l_header.classList.add("show");
  
</script>

        
      </div>
      
  
  <footer class="footer clearfix">
    <br><br>
    
      
        <div class="aplayer-container">
          

  
    <meting-js theme="#1BCDFC" autoplay="false" volume="0.7" loop="all" order="list" fixed="false" list-max-height="320px" server="tencent" type="playlist" id="2185397204" list-folded="true">
    </meting-js>
  


        </div>
      
    
      
        <br>
        <div class="social-wrapper">
          
            
              <a href="/atom.xml" class="social fas fa-rss flat-btn" target="_blank" rel="external nofollow noopener noreferrer">
                
              </a>
            
          
            
              <a href="mailto:2395856915@qq.com" class="social fas fa-envelope flat-btn" target="_blank" rel="external nofollow noopener noreferrer">
                
              </a>
            
          
            
              <a href="https://github.com/pistachio0812" class="social fab fa-github flat-btn" target="_blank" rel="external nofollow noopener noreferrer">
                
              </a>
            
          
            
          
            
          
        </div>
      
    
      
        <div><p>博客内容遵循 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
      
    
      
        本站使用
        <a href="https://github.com/volantis-x/hexo-theme-volantis/tree/4.2.0" target="_blank" class="codename" rel="external nofollow noopener noreferrer">Volantis</a>
        作为主题
      
    
      
        <div class="copyright">
        <p><a href="/">Copyright ©2020-2023江西理工大学.All Rights Reserved</a></p>

        </div>
      
    
  </footer>


      <a id="s-top" class="fas fa-arrow-up fa-fw" href="javascript:void(0)"></a>
    </div>
  </div>
  <div>
    <script>
window.volantis={};
window.volantis.loadcss=document.getElementById("loadcss");
/********************脚本懒加载函数********************************/
function loadScript(src, cb) {
var HEAD = document.getElementsByTagName('head')[0] || document.documentElement;
var script = document.createElement('script');
script.setAttribute('type','text/javascript');
if (cb) script.onload = cb;
script.setAttribute('src', src);
HEAD.appendChild(script);
}
//https://github.com/filamentgroup/loadCSS
var loadCSS = function( href, before, media, attributes ){
	var doc = window.document;
	var ss = doc.createElement( "link" );
	var ref;
	if( before ){
		ref = before;
	}
	else {
		var refs = ( doc.body || doc.getElementsByTagName( "head" )[ 0 ] ).childNodes;
		ref = refs[ refs.length - 1];
	}
	var sheets = doc.styleSheets;
	if( attributes ){
		for( var attributeName in attributes ){
			if( attributes.hasOwnProperty( attributeName ) ){
				ss.setAttribute( attributeName, attributes[attributeName] );
			}
		}
	}
	ss.rel = "stylesheet";
	ss.href = href;
	ss.media = "only x";
	function ready( cb ){
		if( doc.body ){
			return cb();
		}
		setTimeout(function(){
			ready( cb );
		});
	}
	ready( function(){
		ref.parentNode.insertBefore( ss, ( before ? ref : ref.nextSibling ) );
	});
	var onloadcssdefined = function( cb ){
		var resolvedHref = ss.href;
		var i = sheets.length;
		while( i-- ){
			if( sheets[ i ].href === resolvedHref ){
				return cb();
			}
		}
		setTimeout(function() {
			onloadcssdefined( cb );
		});
	};
	function loadCB(){
		if( ss.addEventListener ){
			ss.removeEventListener( "load", loadCB );
		}
		ss.media = media || "all";
	}
	if( ss.addEventListener ){
		ss.addEventListener( "load", loadCB);
	}
	ss.onloadcssdefined = onloadcssdefined;
	onloadcssdefined( loadCB );
	return ss;
};
</script>
<script>
  
  loadCSS("volantis-static/libs/@fortawesome/fontawesome-free/css/all.min.css", window.volantis.loadcss);
  
  
  loadCSS("volantis-static/libs/font-awesome-animation/font-awesome-animation.min.css", window.volantis.loadcss);
  
  
  loadCSS("volantis-static/libs/node-waves/dist/waves.min.css", window.volantis.loadcss);
  
  
</script>
<!-- required -->

<script src="/volantis-static/libs/jquery/dist/jquery.min.js"></script>

<script>
  function pjax_fancybox() {
    $(".md .gallery").find("img").each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("class", "fancybox");
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 判断当前页面是否存在描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".md .gallery").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  function SCload_fancybox() {
    if ($(".md .gallery").find("img").length == 0) return;
    loadCSS("https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css", document.getElementById("loadcss"));
    setTimeout(function() {
      loadScript('https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js', pjax_fancybox)
    }, 1);
  };
  $(function () {
    SCload_fancybox();
  });
</script>


<!-- internal -->







  <script defer src="volantis-static/libs/vanilla-lazyload/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 0
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    lazyLoadInstance.update();
  });
  document.addEventListener('pjax:complete', function () {
    lazyLoadInstance.update();
  });
</script>




  
  
    <script>
      window.FPConfig = {
        delay: 0,
        ignoreKeywords: [],
        maxRPS: 5,
        hoverDelay: 25
      };
    </script>
    <script defer src="volantis-static/libs/flying-pages/flying-pages.min.js"></script>
  








  <script>
  let APlayerController = new Object();
  APlayerController.id = '2185397204';  // 设定全局音乐播放ID
  APlayerController.volume = '0.7';
  loadCSS("https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.css", window.volantis.loadcss);
  // APlayer 需要在  MetingJS 之前加载
  loadScript("volantis-static/libs/aplayer/dist/APlayer.min.js")
  window.volantis.LoadMetingJS=0
  var checkAPlayer = setInterval(function () {
    if (!window.APlayer) return
    clearInterval(checkAPlayer)
	if (!window.volantis.LoadMetingJS&&!window.MetingJSElement){
	  window.LoadMetingJS=1
      loadScript("volantis-static/libs/meting/dist/Meting.min.js")
	  }
  }, 2500)

</script>







  
<script src="/js/app.js"></script>



<!-- optional -->

  <script>
const SearchServiceimagePath="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@master/img/";
const ROOT =  ("/" || "/").endsWith('/') ? ("/" || "/") : ("//" || "/" );

$('.input.u-search-input').one('focus',function(){
	
		loadScript('/js/search/hexo.js',setSearchService);
	
})

function listenSearch(){
  
    customSearch = new HexoSearch({
      imagePath: SearchServiceimagePath
    });
  
}
function setSearchService() {
	listenSearch();
	
}
</script>





  
<script src="/volantis-static/libs/node-waves/dist/waves.min.js"></script>

  <script type="text/javascript">
    $(function () {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>



  
<script src="/volantis-static/libs/comment_typing/comment_typing.js"></script>












<script>
function listennSidebarTOC() {
  const navItems = document.querySelectorAll(".toc li");
  if (!navItems.length) return;
  const sections = [...navItems].map((element) => {
    const link = element.querySelector(".toc-link");
    const target = document.getElementById(
      decodeURI(link.getAttribute("href")).replace("#", "")
    );
    link.addEventListener("click", (event) => {
      event.preventDefault();
      window.scrollTo({
		top: target.offsetTop + 100,
		
		behavior: "smooth"
		
	  });
    });
    return target;
  });

  function activateNavByIndex(target) {
    if (target.classList.contains("active-current")) return;

    document.querySelectorAll(".toc .active").forEach((element) => {
      element.classList.remove("active", "active-current");
    });
    target.classList.add("active", "active-current");
    let parent = target.parentNode;
    while (!parent.matches(".toc")) {
      if (parent.matches("li")) parent.classList.add("active");
      parent = parent.parentNode;
    }
  }

  function findIndex(entries) {
    let index = 0;
    let entry = entries[index];
    if (entry.boundingClientRect.top > 0) {
      index = sections.indexOf(entry.target);
      return index === 0 ? 0 : index - 1;
    }
    for (; index < entries.length; index++) {
      if (entries[index].boundingClientRect.top <= 0) {
        entry = entries[index];
      } else {
        return sections.indexOf(entry.target);
      }
    }
    return sections.indexOf(entry.target);
  }

  function createIntersectionObserver(marginTop) {
    marginTop = Math.floor(marginTop + 10000);
    let intersectionObserver = new IntersectionObserver(
      (entries, observe) => {
        let scrollHeight = document.documentElement.scrollHeight + 100;
        if (scrollHeight > marginTop) {
          observe.disconnect();
          createIntersectionObserver(scrollHeight);
          return;
        }
        let index = findIndex(entries);
        activateNavByIndex(navItems[index]);
      },
      {
        rootMargin: marginTop + "px 0px -100% 0px",
        threshold: 0,
      }
    );
    sections.forEach((element) => {
      element && intersectionObserver.observe(element);
    });
  }
  createIntersectionObserver(document.documentElement.scrollHeight);
}

document.addEventListener("DOMContentLoaded", listennSidebarTOC);
document.addEventListener("pjax:success", listennSidebarTOC);
</script>

<!-- more -->




    
      


<script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script>


<script>
    var pjax;
    document.addEventListener('DOMContentLoaded', function () {
      pjax = new Pjax({
        elements: 'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([pjax-fancybox])',
        selectors: [
          "title",
          "#l_cover",
          "#pjax-container",
          "#pjax-header-nav-list"
        ],
        cacheBust: false,   // url 地址追加时间戳，用以避免浏览器缓存
        timeout: 5000
      });
    });

    document.addEventListener('pjax:send', function (e) {
      //window.stop(); // 相当于点击了浏览器的停止按钮

      try {
        var currentUrl = window.location.pathname;
        var targetUrl = e.triggerElement.href;
        var banUrl = [""];
        if (banUrl[0] != "") {
          banUrl.forEach(item => {
            if(currentUrl.indexOf(item) != -1 || targetUrl.indexOf(item) != -1) {
              window.location.href = targetUrl;
            }
          });
        }
      } catch (error) {}

      window.subData = null; // 移除标题（用于一二级导航栏切换处）
      if (typeof $.fancybox != "undefined") {
        $.fancybox.close();    // 关闭弹窗
      }
      volantis.$switcher.removeClass('active'); // 关闭移动端激活的搜索框
      volantis.$header.removeClass('z_search-open'); // 关闭移动端激活的搜索框
      volantis.$wrapper.removeClass('sub'); // 跳转页面时关闭二级导航

      // 解绑事件 避免重复监听
      volantis.$topBtn.unbind('click');
      $('.menu a').unbind('click');
      $(window).unbind('resize');
      $(window).unbind('scroll');
      $(document).unbind('scroll');
      $(document).unbind('click');
      $('body').unbind('click');
	  
    });

    document.addEventListener('pjax:complete', function () {
      // 关于百度统计对 SPA 页面的处理：
      // 方案一：百度统计>管理>单页应用设置中，打开开启按钮即可对SPA进行统计。 https://tongji.baidu.com/web/help/article?id=324
      // 方案二：取消注释下列代码。 https://tongji.baidu.com/web/help/article?id=235
       

      // 关于谷歌统计对 SPA 页面的处理：
      // 当应用以动态方式加载内容并更新地址栏中的网址时，也应该更新通过 gtag.js 存储的网页网址。
      // https://developers.google.cn/analytics/devguides/collection/gtagjs/single-page-applications?hl=zh-cn
      
	 

      $('.nav-main').find('.list-v').not('.menu-phone').removeAttr("style",""); // 移除小尾巴的移除
      $('.menu-phone.list-v').removeAttr("style",""); // 移除小尾巴的移除
      $('script[data-pjax], .pjax-reload script').each(function () {
        $(this).parent().append($(this).remove());
      });
      try{
          if (typeof $.fancybox == "undefined") {
            SCload_fancybox();
          } else {
            pjax_fancybox();
          }
        
        
        
        
        
        
        
        
        
        
      } catch (e) {
        console.log(e);
      }
	  
    });

    document.addEventListener('pjax:error', function (e) {
	  
      window.location.href = e.triggerElement.href;
    });
</script>

    
  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
