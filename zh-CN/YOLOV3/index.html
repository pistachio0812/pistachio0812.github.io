<!DOCTYPE html>
<html lang="zh-CN,en,zh-TW,default">
<head hexo-theme="https://github.com/volantis-x/hexo-theme-volantis/tree/4.2.0">
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
    
  
  <!-- 渲染优化 -->
  <meta http-equiv="x-dns-prefetch-control" content="on">
  <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- 页面元数据 -->
  
  <title>yolov3论文笔记 - 阿月浑子-Hexo博客</title>
  
    <meta name="keywords" content="论文笔记,yolov3">
  

  

  <!-- feed -->
  
    <link rel="alternate" href="/atom.xml" title="阿月浑子-Hexo博客" type="application/atom+xml">
  

  <!-- import meta -->
  

  <!-- link -->
  

  <!-- import link -->
  

  
    
<link rel="stylesheet" href="/css/first.css">

  

  
  <link rel="stylesheet" href="/css/style.css" media="print" onload="this.media='all';this.onload=null">
  <noscript><link rel="stylesheet" href="/css/style.css"></noscript>
  

  <script id="loadcss"></script>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end -->
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>

<body>
  

<header id="l_header" class="l_header auto shadow show" style="opacity: 0">
  <div class="container">
  <div id="wrapper">
    <div class="nav-sub">
      <p class="title"></p>
      <ul class="switcher nav-list-h m-phone" id="pjax-header-nav-list">
        <li><a id="s-comment" class="fas fa-comments fa-fw" target="_self" href="javascript:void(0)"></a></li>
        
          <li><a id="s-toc" class="s-toc fas fa-list fa-fw" target="_self" href="javascript:void(0)"></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href="/">
          
            <img no-lazy class="logo" src="volantis-static/media/org.volantis/blog/Logo-NavBar@3x.png">
          
          
          
        </a>
      

			<div class="menu navigation">
				<ul class="nav-list-h m-pc">
          
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/" id="home">
                  <i class="fa-solid fa-rss fa-fw"></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/categories/" id="categories">
                  <i class="fa-solid fa-folder-open fa-fw"></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/archives/" id="archives">
                  <i class="fa-solid fa-archive fa-fw"></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/friends/" id="friends">
                  <i class="fa-solid fa-link fa-fw"></i>友链
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/tags/" id="tags">
                  <i class="fa-solid fa-tags fa-fw"></i>留言箱
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/about/" id="about">
                  <i class="fa-solid fa-info-circle fa-fw"></i>关于
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover">
                  <i class="fa-solid fa-ellipsis-v fa-fw"></i>更多
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/hexo-theme-volantis/" id="https:githubcomvolantis-xhexo-theme-volantis" rel="external nofollow noopener noreferrer" target="_blank">
                  主题源码
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/hexo-theme-volantis/releases/" id="https:githubcomvolantis-xhexo-theme-volantisreleases" rel="external nofollow noopener noreferrer" target="_blank">
                  更新日志
                </a>
                
              </li>
            
          
                    
                      
            
              <hr>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover">
                  有疑问？
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/faqs/" id="faqs">
                  看 FAQ
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/volantis-docs/" id="https:githubcomvolantis-xvolantis-docs" rel="external nofollow noopener noreferrer" target="_blank">
                  看 本站源码
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/hexo-theme-volantis/issues/" id="https:githubcomvolantis-xhexo-theme-volantisissues" rel="external nofollow noopener noreferrer" target="_blank">
                  提 Issue
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
                    
                      
            
              <hr>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover">
                  文学黑洞
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://meiriyiwen.com/random" id="https:meiriyiwencomrandom" rel="external nofollow noopener noreferrer" target="_blank">
                  每日一文
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://www.marxists.org/chinese/index.html" id="https:wwwmarxistsorgchineseindexhtml" rel="external nofollow noopener noreferrer" target="_blank">
                  马克思主义文库
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://www.yikm.net/" id="https:wwwyikmnet" rel="external nofollow noopener noreferrer" target="_blank">
                  游戏厅
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://www.xiaozhongjishu.com/" id="https:wwwxiaozhongjishucom" rel="external nofollow noopener noreferrer" target="_blank">
                  小众技术工具库
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
          
				</ul>
			</div>

      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fas fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search...">
        </form>
      </div>

			<ul class="switcher nav-list-h m-phone">
				
					<li><a class="s-search fas fa-search fa-fw" target="_self" href="javascript:void(0)"></a></li>
				
				<li>
          <a class="s-menu fas fa-bars fa-fw" target="_self" href="javascript:void(0)"></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/" id="home">
                  <i class="fa-solid fa-rss fa-fw"></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/categories/" id="categories">
                  <i class="fa-solid fa-folder-open fa-fw"></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/archives/" id="archives">
                  <i class="fa-solid fa-archive fa-fw"></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/friends/" id="friends">
                  <i class="fa-solid fa-link fa-fw"></i>友链
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/tags/" id="tags">
                  <i class="fa-solid fa-tags fa-fw"></i>留言箱
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/about/" id="about">
                  <i class="fa-solid fa-info-circle fa-fw"></i>关于
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover">
                  <i class="fa-solid fa-ellipsis-v fa-fw"></i>更多
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/hexo-theme-volantis/" id="https:githubcomvolantis-xhexo-theme-volantis" rel="external nofollow noopener noreferrer" target="_blank">
                  主题源码
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/hexo-theme-volantis/releases/" id="https:githubcomvolantis-xhexo-theme-volantisreleases" rel="external nofollow noopener noreferrer" target="_blank">
                  更新日志
                </a>
                
              </li>
            
          
                    
                      
            
              <hr>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover">
                  有疑问？
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/faqs/" id="faqs">
                  看 FAQ
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/volantis-docs/" id="https:githubcomvolantis-xvolantis-docs" rel="external nofollow noopener noreferrer" target="_blank">
                  看 本站源码
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://github.com/volantis-x/hexo-theme-volantis/issues/" id="https:githubcomvolantis-xhexo-theme-volantisissues" rel="external nofollow noopener noreferrer" target="_blank">
                  提 Issue
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
                    
                      
            
              <hr>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover">
                  文学黑洞
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://meiriyiwen.com/random" id="https:meiriyiwencomrandom" rel="external nofollow noopener noreferrer" target="_blank">
                  每日一文
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://www.marxists.org/chinese/index.html" id="https:wwwmarxistsorgchineseindexhtml" rel="external nofollow noopener noreferrer" target="_blank">
                  马克思主义文库
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://www.yikm.net/" id="https:wwwyikmnet" rel="external nofollow noopener noreferrer" target="_blank">
                  游戏厅
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="https://www.xiaozhongjishu.com/" id="https:wwwxiaozhongjishucom" rel="external nofollow noopener noreferrer" target="_blank">
                  小众技术工具库
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>
		</div>
	</div>
  </div>
</header>

  <div id="l_body">
    <div id="l_cover">
  
    
        <div id="full" class="cover-wrapper post dock" style="display: none;">
          
            <div class="cover-bg lazyload placeholder" data-bg="https://gcore.jsdelivr.net/gh/MHG-LAB/cron@gh-pages/bing/bing.jpg"></div>
          
          <div class="cover-body">
  <div class="top">
    
    
      <p class="title">相思似海深旧事如天远</p>
    
    
      <p class="subtitle">where there is a will there is a way</p>
    
  </div>
  <div class="bottom">
    <div class="menu navigation">
      <div class="list-h">
        
          
            <a href="/v5/getting-started/" id="v5getting-started">
              <img src="volantis-static/media/twemoji/assets/svg/1f5c3.svg" class="lazyload" data-srcset="volantis-static/media/twemoji/assets/svg/1f5c3.svg" srcset="data:image/png;base64,666"><p>文档</p>
            </a>
          
            <a href="/faqs/" id="faqs">
              <img src="volantis-static/media/twemoji/assets/svg/1f516.svg" class="lazyload" data-srcset="volantis-static/media/twemoji/assets/svg/1f516.svg" srcset="data:image/png;base64,666"><p>帮助</p>
            </a>
          
            <a href="/examples/" id="examples">
              <img src="volantis-static/media/twemoji/assets/svg/1f396.svg" class="lazyload" data-srcset="volantis-static/media/twemoji/assets/svg/1f396.svg" srcset="data:image/png;base64,666"><p>示例</p>
            </a>
          
            <a href="/contributors/" id="contributors">
              <img src="volantis-static/media/twemoji/assets/svg/1f389.svg" class="lazyload" data-srcset="volantis-static/media/twemoji/assets/svg/1f389.svg" srcset="data:image/png;base64,666"><p>社区</p>
            </a>
          
            <a href="/archives/" id="archives">
              <img src="volantis-static/media/twemoji/assets/svg/1f4f0.svg" class="lazyload" data-srcset="volantis-static/media/twemoji/assets/svg/1f4f0.svg" srcset="data:image/png;base64,666"><p>博客</p>
            </a>
          
            <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/volantis-x/hexo-theme-volantis/" id="https:githubcomvolantis-xhexo-theme-volantis">
              <img src="volantis-static/media/twemoji/assets/svg/1f9ec.svg" class="lazyload" data-srcset="volantis-static/media/twemoji/assets/svg/1f9ec.svg" srcset="data:image/png;base64,666"><p>源码</p>
            </a>
          
        
      </div>
    </div>
  </div>
</div>

          <div id="scroll-down" style="display: none;"><i class="fa fa-chevron-down scroll-down-effects"></i></div>
        </div>
    
  
  </div>

    <div id="safearea">
      <div class="body-wrapper" id="pjax-container">
        

<div class="l_main">
  <article class="article post white-box reveal md shadow article-type-post" id="post" itemscope itemprop="blogPost">
  


  
  <div class="article-meta" id="top">
    
    
    
      <h1 class="title">
        yolov3论文笔记
      </h1>
      <div class="new-meta-box">
        
          
            
<div class="new-meta-item author">
  <a class="author" target="_blank" href="https://www.cnblogs.com/pistachio0812" rel="external nofollow noopener noreferrer">
    <img no-lazy src="https://img1.baidu.com/it/u=583582599,306470958&fm=253&fmt=auto&app=138&f=JPEG?w=500&h=500">
    <p>追风赶月的少年</p>
  </a>
</div>

          
        
          
            
  <div class="new-meta-item category">
    <a class="notlink">
      <i class="fa-solid fa-folder-open fa-fw" aria-hidden="true"></i>
      <a class="category-link" href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a>
    </a>
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class="notlink">
    <i class="fa-solid fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2022年4月16日</p>
  </a>
</div>

          
        
          
            
  <div class="new-meta-item wordcount">
    <a class="notlink">
      <i class="fa-solid fa-keyboard fa-fw" aria-hidden="true"></i>
      <p>字数：6.4k字</p>
    </a>
  </div>
  <div class="new-meta-item readtime">
    <a class="notlink">
      <i class="fa-solid fa-hourglass-half fa-fw" aria-hidden="true"></i>
      <p>时长：30分钟</p>
    </a>
  </div>


          
        
      </div>
    
  </div>


  
  <p>论文地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://arxiv.org/pdf/1804.02767.pdf">https://arxiv.org/pdf/1804.02767.pdf</a></p>
<p>源码地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/ultralytics/yolov3">ultralytics/yolov3</a></p>
<p>文章引用源码：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/bubbliiiing/yolo3-pytorch">https://github.com/bubbliiiing/yolo3-pytorch</a></p>
<p>文章出处：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://blog.csdn.net/weixin_44791964/article/details/105310627">https://blog.csdn.net/weixin_44791964/article/details/105310627</a></p>
<h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><h3 id="预测部分"><a href="#预测部分" class="headerlink" title="预测部分"></a>预测部分</h3><h4 id="主干网络Darknet53"><a href="#主干网络Darknet53" class="headerlink" title="主干网络Darknet53"></a>主干网络Darknet53</h4><p><style>.ynhqqoyhaulq{}</style><img src="/zh-CN/YOLOV3/YOLOV3/image-20220416194945035.png" class="lazyload" data-srcset="/zh-CN/YOLOV3/YOLOV3/image-20220416194945035.png" srcset="data:image/png;base64,666"></p>
<p>YoloV3所使用的主干特征提取网络为Darknet53，它具有两个重要特点：<br>1、Darknet53具有一个重要特点是使用了残差网络Residual，Darknet53中的残差卷积就是首先进行一次卷积核大小为3X3、步长为2的卷积，该卷积会压缩输入进来的特征层的宽和高，此时我们可以获得一个特征层，我们将该特征层命名为layer。之后我们再对该特征层进行一次1X1的卷积和一次3X3的卷积，并把这个结果加上layer，此时我们便构成了残差结构。通过不断的1X1卷积和3X3卷积以及残差边的叠加，我们便大幅度的加深了网络。残差网络的特点是容易优化，并且能够通过增加相当的深度来提高准确率。其内部的残差块使用了跳跃连接，缓解了在深度神经网络中增加深度带来的梯度消失问题。</p>
<p>2、Darknet53的每一个卷积部分使用了特有的DarknetConv2D结构，每一次卷积的时候进行l2正则化，完成卷积后进行BatchNormalization标准化与LeakyReLU。普通的ReLU是将所有的负值都设为零，Leaky ReLU则是给所有负值赋予一个非零斜率。以数学的方式我们可以表示为：</p>
<p><style>.vqimglqscrtl{}</style><img src="/zh-CN/YOLOV3/YOLOV3/image-20220419102411716.png" class="lazyload" data-srcset="/zh-CN/YOLOV3/YOLOV3/image-20220419102411716.png" srcset="data:image/png;base64,666"></p>
<p>实现代码：<br></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"># 详情见nets/darknet.py</span><br><span class="line">#---------------------------------------------------------------------#</span><br><span class="line">#   残差结构</span><br><span class="line">#   利用一个1x1卷积下降通道数，然后利用一个3x3卷积提取特征并且上升通道数</span><br><span class="line">#   最后接上一个残差边</span><br><span class="line">#---------------------------------------------------------------------#</span><br><span class="line">class BasicBlock(nn.Module):</span><br><span class="line">    def __init__(self, inplanes, planes):</span><br><span class="line">        super(BasicBlock, self).__init__()</span><br><span class="line">        self.conv1  = nn.Conv2d(inplanes, planes[0], kernel_size=1, stride=1, padding=0, bias=False)</span><br><span class="line">        self.bn1    = nn.BatchNorm2d(planes[0])</span><br><span class="line">        self.relu1  = nn.LeakyReLU(0.1)</span><br><span class="line">        </span><br><span class="line">        self.conv2  = nn.Conv2d(planes[0], planes[1], kernel_size=3, stride=1, padding=1, bias=False)</span><br><span class="line">        self.bn2    = nn.BatchNorm2d(planes[1])</span><br><span class="line">        self.relu2  = nn.LeakyReLU(0.1)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        residual = x</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu1(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = self.relu2(out)</span><br><span class="line"></span><br><span class="line">        out += residual</span><br><span class="line">        return out</span><br><span class="line"></span><br><span class="line">class DarkNet(nn.Module):</span><br><span class="line">    def __init__(self, layers):</span><br><span class="line">        super(DarkNet, self).__init__()</span><br><span class="line">        self.inplanes = 32</span><br><span class="line">        # 416,416,3 -&gt; 416,416,32</span><br><span class="line">        self.conv1  = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)</span><br><span class="line">        self.bn1    = nn.BatchNorm2d(self.inplanes)</span><br><span class="line">        self.relu1  = nn.LeakyReLU(0.1)</span><br><span class="line"></span><br><span class="line">        # 416,416,32 -&gt; 208,208,64</span><br><span class="line">        self.layer1 = self._make_layer([32, 64], layers[0])</span><br><span class="line">        # 208,208,64 -&gt; 104,104,128</span><br><span class="line">        self.layer2 = self._make_layer([64, 128], layers[1])</span><br><span class="line">        # 104,104,128 -&gt; 52,52,256</span><br><span class="line">        self.layer3 = self._make_layer([128, 256], layers[2])</span><br><span class="line">        # 52,52,256 -&gt; 26,26,512</span><br><span class="line">        self.layer4 = self._make_layer([256, 512], layers[3])</span><br><span class="line">        # 26,26,512 -&gt; 13,13,1024</span><br><span class="line">        self.layer5 = self._make_layer([512, 1024], layers[4])</span><br><span class="line"></span><br><span class="line">        self.layers_out_filters = [64, 128, 256, 512, 1024]</span><br><span class="line"></span><br><span class="line">        # 进行权值初始化</span><br><span class="line">        for m in self.modules():</span><br><span class="line">            if isinstance(m, nn.Conv2d):</span><br><span class="line">                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels</span><br><span class="line">                m.weight.data.normal_(0, math.sqrt(2. / n))</span><br><span class="line">            elif isinstance(m, nn.BatchNorm2d):</span><br><span class="line">                m.weight.data.fill_(1)</span><br><span class="line">                m.bias.data.zero_()</span><br><span class="line"></span><br><span class="line">    #---------------------------------------------------------------------#</span><br><span class="line">    #   在每一个layer里面，首先利用一个步长为2的3x3卷积进行下采样</span><br><span class="line">    #   然后进行残差结构的堆叠</span><br><span class="line">    #---------------------------------------------------------------------#</span><br><span class="line">    def _make_layer(self, planes, blocks):</span><br><span class="line">        layers = []</span><br><span class="line">        # 下采样，步长为2，卷积核大小为3</span><br><span class="line">        layers.append(("ds_conv", nn.Conv2d(self.inplanes, planes[1], kernel_size=3, stride=2, padding=1, bias=False)))</span><br><span class="line">        layers.append(("ds_bn", nn.BatchNorm2d(planes[1])))</span><br><span class="line">        layers.append(("ds_relu", nn.LeakyReLU(0.1)))</span><br><span class="line">        # 加入残差结构</span><br><span class="line">        self.inplanes = planes[1]</span><br><span class="line">        for i in range(0, blocks):</span><br><span class="line">            layers.append(("residual_{}".format(i), BasicBlock(self.inplanes, planes)))</span><br><span class="line">        return nn.Sequential(OrderedDict(layers))</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.bn1(x)</span><br><span class="line">        x = self.relu1(x)</span><br><span class="line"></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        out3 = self.layer3(x)</span><br><span class="line">        out4 = self.layer4(out3)</span><br><span class="line">        out5 = self.layer5(out4)</span><br><span class="line"></span><br><span class="line">        return out3, out4, out5</span><br><span class="line"></span><br><span class="line">def darknet53():</span><br><span class="line">    model = DarkNet([1, 2, 8, 8, 4])</span><br><span class="line">    return model</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p></p>
<h4 id="从特征层获取预测结果"><a href="#从特征层获取预测结果" class="headerlink" title="从特征层获取预测结果"></a>从特征层获取预测结果</h4><p><style>.iuedbeyniins{}</style><img src="/zh-CN/YOLOV3/YOLOV3/image-20220416194945035.png" class="lazyload" data-srcset="/zh-CN/YOLOV3/YOLOV3/image-20220416194945035.png" srcset="data:image/png;base64,666"></p>
<p>从特征获取预测结果的过程可以分为两个部分，分别是：</p>
<p>·构建FPN特征金字塔进行加强特征提取。<br>·利用Yolo Head对三个有效特征层进行预测。<br>a）构建FPN特征金字塔进行加强特征提取<br>在特征利用部分，YoloV3提取多特征层进行目标检测，一共提取三个特征层。三个特征层位于主干部分Darknet53的不同位置，分别位于中间层，中下层，底层，三个特征层的shape分别为(52,52,256)、(26,26,512)、(13,13,1024)。</p>
<p>在获得三个有效特征层后，我们利用这三个有效特征层进行FPN层的构建，构建方式为：</p>
<p>·13x13x1024的特征层进行5次卷积处理，处理完后利用YoloHead获得预测结果，一部分用于进行上采样UmSampling2d后与26x26x512特征层进行结合，结合特征层的shape为(26,26,768)。<br>·结合特征层再次进行5次卷积处理，处理完后利用YoloHead获得预测结果，一部分用于进行上采样UmSampling2d后与52x52x256特征层进行结合，结合特征层的shape为(52,52,384)。<br>·结合特征层再次进行5次卷积处理，处理完后利用YoloHead获得预测结果。<br>特征金字塔可以将不同shape的特征层进行特征融合，有利于提取出更好的特征。</p>
<p>b）利用Yolo Head获得预测结果<br>利用FPN特征金字塔，我们可以获得三个加强特征，这三个加强特征的shape分别为(13,13,512)、(26,26,256)、(52,52,128)，然后我们利用这三个shape的特征层传入Yolo Head获得预测结果。</p>
<p>Yolo Head本质上是一次3x3卷积加上一次1x1卷积，3x3卷积的作用是特征整合，1x1卷积的作用是调整通道数。</p>
<p>对三个特征层分别进行处理，假设我们预测是的VOC数据集，我们的输出层的shape分别为(13,13,75)，(26,26,75)，(52,52,75)，最后一个维度为75是因为该图是基于voc数据集的，它的类为20种，YoloV3针对每一个特征层的每一个特征点存在3个先验框，所以预测结果的通道数为3x25；<br>如果使用的是coco训练集，类则为80种，最后的维度应该为255 = 3x85，三个特征层的shape为(13,13,255)，(26,26,255)，(52,52,255)</p>
<p>其实际情况就是，输入N张416x416的图片，在经过多层的运算后，会输出三个shape分别为(N,13,13,255)，(N,26,26,255)，(N,52,52,255)的数据，对应每个图分为13x13、26x26、52x52的网格上3个先验框的位置。</p>
<p>实现代码如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 详情见nets/yolo.py</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv2d</span>(<span class="params">filter_in, filter_out, kernel_size</span>):</span><br><span class="line">    pad = (kernel_size - <span class="number">1</span>) // <span class="number">2</span> <span class="keyword">if</span> kernel_size <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(OrderedDict([</span><br><span class="line">        (<span class="string">"conv"</span>, nn.Conv2d(filter_in, filter_out, kernel_size=kernel_size, stride=<span class="number">1</span>, padding=pad, bias=<span class="literal">False</span>)),</span><br><span class="line">        (<span class="string">"bn"</span>, nn.BatchNorm2d(filter_out)),</span><br><span class="line">        (<span class="string">"relu"</span>, nn.LeakyReLU(<span class="number">0.1</span>)),</span><br><span class="line">    ]))</span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------------------------------#</span></span><br><span class="line"><span class="comment">#   make_last_layers里面一共有七个卷积，前五个用于提取特征。</span></span><br><span class="line"><span class="comment">#   后两个用于获得yolo网络的预测结果</span></span><br><span class="line"><span class="comment">#------------------------------------------------------------------------#</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_last_layers</span>(<span class="params">filters_list, in_filters, out_filter</span>):</span><br><span class="line">    m = nn.Sequential(</span><br><span class="line">        conv2d(in_filters, filters_list[<span class="number">0</span>], <span class="number">1</span>),</span><br><span class="line">        conv2d(filters_list[<span class="number">0</span>], filters_list[<span class="number">1</span>], <span class="number">3</span>),</span><br><span class="line">        conv2d(filters_list[<span class="number">1</span>], filters_list[<span class="number">0</span>], <span class="number">1</span>),</span><br><span class="line">        conv2d(filters_list[<span class="number">0</span>], filters_list[<span class="number">1</span>], <span class="number">3</span>),</span><br><span class="line">        conv2d(filters_list[<span class="number">1</span>], filters_list[<span class="number">0</span>], <span class="number">1</span>),</span><br><span class="line">        conv2d(filters_list[<span class="number">0</span>], filters_list[<span class="number">1</span>], <span class="number">3</span>),</span><br><span class="line">        nn.Conv2d(filters_list[<span class="number">1</span>], out_filter, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> m</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YoloBody</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, anchors_mask, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(YoloBody, self).__init__()</span><br><span class="line">        <span class="comment">#---------------------------------------------------#   </span></span><br><span class="line">        <span class="comment">#   生成darknet53的主干模型</span></span><br><span class="line">        <span class="comment">#   获得三个有效特征层，他们的shape分别是：</span></span><br><span class="line">        <span class="comment">#   52,52,256</span></span><br><span class="line">        <span class="comment">#   26,26,512</span></span><br><span class="line">        <span class="comment">#   13,13,1024</span></span><br><span class="line">        <span class="comment">#---------------------------------------------------#</span></span><br><span class="line">        self.backbone = darknet53()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#---------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   out_filters : [64, 128, 256, 512, 1024]</span></span><br><span class="line">        <span class="comment">#---------------------------------------------------#</span></span><br><span class="line">        out_filters = self.backbone.layers_out_filters</span><br><span class="line"></span><br><span class="line">        <span class="comment">#------------------------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   计算yolo_head的输出通道数，对于voc数据集而言</span></span><br><span class="line">        <span class="comment">#   final_out_filter0 = final_out_filter1 = final_out_filter2 = 75</span></span><br><span class="line">        <span class="comment">#------------------------------------------------------------------------#</span></span><br><span class="line">        self.last_layer0            = make_last_layers([<span class="number">512</span>, <span class="number">1024</span>], out_filters[-<span class="number">1</span>], <span class="built_in">len</span>(anchors_mask[<span class="number">0</span>]) * (num_classes + <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        self.last_layer1_conv       = conv2d(<span class="number">512</span>, <span class="number">256</span>, <span class="number">1</span>)</span><br><span class="line">        self.last_layer1_upsample   = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">'nearest'</span>)</span><br><span class="line">        self.last_layer1            = make_last_layers([<span class="number">256</span>, <span class="number">512</span>], out_filters[-<span class="number">2</span>] + <span class="number">256</span>, <span class="built_in">len</span>(anchors_mask[<span class="number">1</span>]) * (num_classes + <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        self.last_layer2_conv       = conv2d(<span class="number">256</span>, <span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line">        self.last_layer2_upsample   = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">'nearest'</span>)</span><br><span class="line">        self.last_layer2            = make_last_layers([<span class="number">128</span>, <span class="number">256</span>], out_filters[-<span class="number">3</span>] + <span class="number">128</span>, <span class="built_in">len</span>(anchors_mask[<span class="number">2</span>]) * (num_classes + <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment">#---------------------------------------------------#   </span></span><br><span class="line">        <span class="comment">#   获得三个有效特征层，他们的shape分别是：</span></span><br><span class="line">        <span class="comment">#   52,52,256；26,26,512；13,13,1024</span></span><br><span class="line">        <span class="comment">#---------------------------------------------------#</span></span><br><span class="line">        x2, x1, x0 = self.backbone(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#---------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   第一个特征层</span></span><br><span class="line">        <span class="comment">#   out0 = (batch_size,255,13,13)</span></span><br><span class="line">        <span class="comment">#---------------------------------------------------#</span></span><br><span class="line">        <span class="comment"># 13,13,1024 -&gt; 13,13,512 -&gt; 13,13,1024 -&gt; 13,13,512 -&gt; 13,13,1024 -&gt; 13,13,512</span></span><br><span class="line">        out0_branch = self.last_layer0[:<span class="number">5</span>](x0)</span><br><span class="line">        out0        = self.last_layer0[<span class="number">5</span>:](out0_branch)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 13,13,512 -&gt; 13,13,256 -&gt; 26,26,256</span></span><br><span class="line">        x1_in = self.last_layer1_conv(out0_branch)</span><br><span class="line">        x1_in = self.last_layer1_upsample(x1_in)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 26,26,256 + 26,26,512 -&gt; 26,26,768</span></span><br><span class="line">        x1_in = torch.cat([x1_in, x1], <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#---------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   第二个特征层</span></span><br><span class="line">        <span class="comment">#   out1 = (batch_size,255,26,26)</span></span><br><span class="line">        <span class="comment">#---------------------------------------------------#</span></span><br><span class="line">        <span class="comment"># 26,26,768 -&gt; 26,26,256 -&gt; 26,26,512 -&gt; 26,26,256 -&gt; 26,26,512 -&gt; 26,26,256</span></span><br><span class="line">        out1_branch = self.last_layer1[:<span class="number">5</span>](x1_in)</span><br><span class="line">        out1        = self.last_layer1[<span class="number">5</span>:](out1_branch)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 26,26,256 -&gt; 26,26,128 -&gt; 52,52,128</span></span><br><span class="line">        x2_in = self.last_layer2_conv(out1_branch)</span><br><span class="line">        x2_in = self.last_layer2_upsample(x2_in)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 52,52,128 + 52,52,256 -&gt; 52,52,384</span></span><br><span class="line">        x2_in = torch.cat([x2_in, x2], <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#---------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   第一个特征层</span></span><br><span class="line">        <span class="comment">#   out3 = (batch_size,255,52,52)</span></span><br><span class="line">        <span class="comment">#---------------------------------------------------#</span></span><br><span class="line">        <span class="comment"># 52,52,384 -&gt; 52,52,128 -&gt; 52,52,256 -&gt; 52,52,128 -&gt; 52,52,256 -&gt; 52,52,128</span></span><br><span class="line">        out2 = self.last_layer2(x2_in)</span><br><span class="line">        <span class="keyword">return</span> out0, out1, out2</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="预测结果的解码"><a href="#预测结果的解码" class="headerlink" title="预测结果的解码"></a>预测结果的解码</h4><p>由第二步我们可以获得三个特征层的预测结果，shape分别为：</p>
<p>·(N,13,13,255)<br>·(N,26,26,255)<br>·(N,52,52,255)<br>在这里我们简单了解一下每个有效特征层到底做了什么：<br>每一个有效特征层将整个图片分成与其长宽对应的网格，如(N,13,13,255)的特征层就是将整个图像分成13x13个网格；然后从每个网格中心建立多个先验框，这些框是网络预先设定好的框，网络的预测结果会判断这些框内是否包含物体，以及这个物体的种类。</p>
<p>由于每一个网格点都具有三个先验框，所以上述的预测结果可以reshape为：</p>
<p>(N,13,13,3,85)<br>(N,26,26,3,85)<br>(N,52,52,3,85)<br>其中的85可以拆分为4+1+80，其中的4代表先验框的调整参数，1代表先验框内是否包含物体，80代表的是这个先验框的种类，由于coco分了80类，所以这里是80。如果YoloV3只检测两类物体，那么这个85就变为了4+1+2 = 7。</p>
<p>即85包含了4+1+80，分别代表x_offset、y_offset、h和w、置信度、分类结果。</p>
<p>但是这个预测结果并不对应着最终的预测框在图片上的位置，还需要解码才可以完成。</p>
<p>YoloV3的解码过程分为两步：</p>
<p>·先将每个网格点加上它对应的x_offset和y_offset，加完后的结果就是预测框的中心。<br>·然后再利用 先验框和h、w结合 计算出预测框的宽高。这样就能得到整个预测框的位置了。</p>
<p>得到最终的预测结果后还要进行<strong>得分排序与非极大抑制筛选</strong>。</p>
<p>这一部分基本上是所有目标检测通用的部分。其对于每一个类进行判别：<br><strong>1、取出每一类得分大于self.obj_threshold的框和得分。<br>2、利用框的位置和得分进行非极大抑制。</strong></p>
<p>实现代码如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 详情见utils/utils_bbox.py</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecodeBox</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, anchors, num_classes, input_shape, anchors_mask = [[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>], [<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>], [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]]</span>):</span><br><span class="line">        <span class="built_in">super</span>(DecodeBox, self).__init__()</span><br><span class="line">        self.anchors        = anchors</span><br><span class="line">        self.num_classes    = num_classes</span><br><span class="line">        self.bbox_attrs     = <span class="number">5</span> + num_classes</span><br><span class="line">        self.input_shape    = input_shape</span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   13x13的特征层对应的anchor是[116,90],[156,198],[373,326]</span></span><br><span class="line">        <span class="comment">#   26x26的特征层对应的anchor是[30,61],[62,45],[59,119]</span></span><br><span class="line">        <span class="comment">#   52x52的特征层对应的anchor是[10,13],[16,30],[33,23]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        self.anchors_mask   = anchors_mask</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode_box</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        outputs = []</span><br><span class="line">        <span class="keyword">for</span> i, <span class="built_in">input</span> <span class="keyword">in</span> <span class="built_in">enumerate</span>(inputs):</span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   输入的input一共有三个，他们的shape分别是</span></span><br><span class="line">            <span class="comment">#   batch_size, 255, 13, 13</span></span><br><span class="line">            <span class="comment">#   batch_size, 255, 26, 26</span></span><br><span class="line">            <span class="comment">#   batch_size, 255, 52, 52</span></span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            batch_size      = <span class="built_in">input</span>.size(<span class="number">0</span>)</span><br><span class="line">            input_height    = <span class="built_in">input</span>.size(<span class="number">2</span>)</span><br><span class="line">            input_width     = <span class="built_in">input</span>.size(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   输入为416x416时</span></span><br><span class="line">            <span class="comment">#   stride_h = stride_w = 32、16、8</span></span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            stride_h = self.input_shape[<span class="number">0</span>] / input_height</span><br><span class="line">            stride_w = self.input_shape[<span class="number">1</span>] / input_width</span><br><span class="line">            <span class="comment">#-------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   此时获得的scaled_anchors大小是相对于特征层的</span></span><br><span class="line">            <span class="comment">#-------------------------------------------------#</span></span><br><span class="line">            scaled_anchors = [(anchor_width / stride_w, anchor_height / stride_h) <span class="keyword">for</span> anchor_width, anchor_height <span class="keyword">in</span> self.anchors[self.anchors_mask[i]]]</span><br><span class="line"></span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   输入的input一共有三个，他们的shape分别是</span></span><br><span class="line">            <span class="comment">#   batch_size, 3, 13, 13, 85</span></span><br><span class="line">            <span class="comment">#   batch_size, 3, 26, 26, 85</span></span><br><span class="line">            <span class="comment">#   batch_size, 3, 52, 52, 85</span></span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            prediction = <span class="built_in">input</span>.view(batch_size, <span class="built_in">len</span>(self.anchors_mask[i]),</span><br><span class="line">                                    self.bbox_attrs, input_height, input_width).permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>).contiguous()</span><br><span class="line"></span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   先验框的中心位置的调整参数</span></span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            x = torch.sigmoid(prediction[..., <span class="number">0</span>])  </span><br><span class="line">            y = torch.sigmoid(prediction[..., <span class="number">1</span>])</span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   先验框的宽高调整参数</span></span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            w = prediction[..., <span class="number">2</span>]</span><br><span class="line">            h = prediction[..., <span class="number">3</span>]</span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   获得置信度，是否有物体</span></span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            conf        = torch.sigmoid(prediction[..., <span class="number">4</span>])</span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   种类置信度</span></span><br><span class="line">            <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">            pred_cls    = torch.sigmoid(prediction[..., <span class="number">5</span>:])</span><br><span class="line"></span><br><span class="line">            FloatTensor = torch.cuda.FloatTensor <span class="keyword">if</span> x.is_cuda <span class="keyword">else</span> torch.FloatTensor</span><br><span class="line">            LongTensor  = torch.cuda.LongTensor <span class="keyword">if</span> x.is_cuda <span class="keyword">else</span> torch.LongTensor</span><br><span class="line"></span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   生成网格，先验框中心，网格左上角 </span></span><br><span class="line">            <span class="comment">#   batch_size,3,13,13</span></span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            grid_x = torch.linspace(<span class="number">0</span>, input_width - <span class="number">1</span>, input_width).repeat(input_height, <span class="number">1</span>).repeat(</span><br><span class="line">                batch_size * <span class="built_in">len</span>(self.anchors_mask[i]), <span class="number">1</span>, <span class="number">1</span>).view(x.shape).<span class="built_in">type</span>(FloatTensor)</span><br><span class="line">            grid_y = torch.linspace(<span class="number">0</span>, input_height - <span class="number">1</span>, input_height).repeat(input_width, <span class="number">1</span>).t().repeat(</span><br><span class="line">                batch_size * <span class="built_in">len</span>(self.anchors_mask[i]), <span class="number">1</span>, <span class="number">1</span>).view(y.shape).<span class="built_in">type</span>(FloatTensor)</span><br><span class="line"></span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   按照网格格式生成先验框的宽高</span></span><br><span class="line">            <span class="comment">#   batch_size,3,13,13</span></span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            anchor_w = FloatTensor(scaled_anchors).index_select(<span class="number">1</span>, LongTensor([<span class="number">0</span>]))</span><br><span class="line">            anchor_h = FloatTensor(scaled_anchors).index_select(<span class="number">1</span>, LongTensor([<span class="number">1</span>]))</span><br><span class="line">            anchor_w = anchor_w.repeat(batch_size, <span class="number">1</span>).repeat(<span class="number">1</span>, <span class="number">1</span>, input_height * input_width).view(w.shape)</span><br><span class="line">            anchor_h = anchor_h.repeat(batch_size, <span class="number">1</span>).repeat(<span class="number">1</span>, <span class="number">1</span>, input_height * input_width).view(h.shape)</span><br><span class="line"></span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   利用预测结果对先验框进行调整</span></span><br><span class="line">            <span class="comment">#   首先调整先验框的中心，从先验框中心向右下角偏移</span></span><br><span class="line">            <span class="comment">#   再调整先验框的宽高。</span></span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            pred_boxes          = FloatTensor(prediction[..., :<span class="number">4</span>].shape)</span><br><span class="line">            pred_boxes[..., <span class="number">0</span>]  = x.data + grid_x</span><br><span class="line">            pred_boxes[..., <span class="number">1</span>]  = y.data + grid_y</span><br><span class="line">            pred_boxes[..., <span class="number">2</span>]  = torch.exp(w.data) * anchor_w</span><br><span class="line">            pred_boxes[..., <span class="number">3</span>]  = torch.exp(h.data) * anchor_h</span><br><span class="line"></span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   将输出结果归一化成小数的形式</span></span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            _scale = torch.Tensor([input_width, input_height, input_width, input_height]).<span class="built_in">type</span>(FloatTensor)</span><br><span class="line">            output = torch.cat((pred_boxes.view(batch_size, -<span class="number">1</span>, <span class="number">4</span>) / _scale,</span><br><span class="line">                                conf.view(batch_size, -<span class="number">1</span>, <span class="number">1</span>), pred_cls.view(batch_size, -<span class="number">1</span>, self.num_classes)), -<span class="number">1</span>)</span><br><span class="line">            outputs.append(output.data)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">yolo_correct_boxes</span>(<span class="params">self, box_xy, box_wh, input_shape, image_shape, letterbox_image</span>):</span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   把y轴放前面是因为方便预测框和图像的宽高进行相乘</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------#</span></span><br><span class="line">        box_yx = box_xy[..., ::-<span class="number">1</span>]</span><br><span class="line">        box_hw = box_wh[..., ::-<span class="number">1</span>]</span><br><span class="line">        input_shape = np.array(input_shape)</span><br><span class="line">        image_shape = np.array(image_shape)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> letterbox_image:</span><br><span class="line">            <span class="comment">#-----------------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   这里求出来的offset是图像有效区域相对于图像左上角的偏移情况</span></span><br><span class="line">            <span class="comment">#   new_shape指的是宽高缩放情况</span></span><br><span class="line">            <span class="comment">#-----------------------------------------------------------------#</span></span><br><span class="line">            new_shape = np.<span class="built_in">round</span>(image_shape * np.<span class="built_in">min</span>(input_shape/image_shape))</span><br><span class="line">            offset  = (input_shape - new_shape)/<span class="number">2.</span>/input_shape</span><br><span class="line">            scale   = input_shape/new_shape</span><br><span class="line"></span><br><span class="line">            box_yx  = (box_yx - offset) * scale</span><br><span class="line">            box_hw *= scale</span><br><span class="line"></span><br><span class="line">        box_mins    = box_yx - (box_hw / <span class="number">2.</span>)</span><br><span class="line">        box_maxes   = box_yx + (box_hw / <span class="number">2.</span>)</span><br><span class="line">        boxes  = np.concatenate([box_mins[..., <span class="number">0</span>:<span class="number">1</span>], box_mins[..., <span class="number">1</span>:<span class="number">2</span>], box_maxes[..., <span class="number">0</span>:<span class="number">1</span>], box_maxes[..., <span class="number">1</span>:<span class="number">2</span>]], axis=-<span class="number">1</span>)</span><br><span class="line">        boxes *= np.concatenate([image_shape, image_shape], axis=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> boxes</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">non_max_suppression</span>(<span class="params">self, prediction, num_classes, input_shape, image_shape, letterbox_image, conf_thres=<span class="number">0.5</span>, nms_thres=<span class="number">0.4</span></span>):</span><br><span class="line">        <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   将预测结果的格式转换成左上角右下角的格式。</span></span><br><span class="line">        <span class="comment">#   prediction  [batch_size, num_anchors, 85]</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">        box_corner          = prediction.new(prediction.shape)</span><br><span class="line">        box_corner[:, :, <span class="number">0</span>] = prediction[:, :, <span class="number">0</span>] - prediction[:, :, <span class="number">2</span>] / <span class="number">2</span></span><br><span class="line">        box_corner[:, :, <span class="number">1</span>] = prediction[:, :, <span class="number">1</span>] - prediction[:, :, <span class="number">3</span>] / <span class="number">2</span></span><br><span class="line">        box_corner[:, :, <span class="number">2</span>] = prediction[:, :, <span class="number">0</span>] + prediction[:, :, <span class="number">2</span>] / <span class="number">2</span></span><br><span class="line">        box_corner[:, :, <span class="number">3</span>] = prediction[:, :, <span class="number">1</span>] + prediction[:, :, <span class="number">3</span>] / <span class="number">2</span></span><br><span class="line">        prediction[:, :, :<span class="number">4</span>] = box_corner[:, :, :<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">        output = [<span class="literal">None</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(prediction))]</span><br><span class="line">        <span class="keyword">for</span> i, image_pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(prediction):</span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   对种类预测部分取max。</span></span><br><span class="line">            <span class="comment">#   class_conf  [num_anchors, 1]    种类置信度</span></span><br><span class="line">            <span class="comment">#   class_pred  [num_anchors, 1]    种类</span></span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            class_conf, class_pred = torch.<span class="built_in">max</span>(image_pred[:, <span class="number">5</span>:<span class="number">5</span> + num_classes], <span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   利用置信度进行第一轮筛选</span></span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            conf_mask = (image_pred[:, <span class="number">4</span>] * class_conf[:, <span class="number">0</span>] &gt;= conf_thres).squeeze()</span><br><span class="line"></span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   根据置信度进行预测结果的筛选</span></span><br><span class="line">            <span class="comment">#----------------------------------------------------------#</span></span><br><span class="line">            image_pred = image_pred[conf_mask]</span><br><span class="line">            class_conf = class_conf[conf_mask]</span><br><span class="line">            class_pred = class_pred[conf_mask]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> image_pred.size(<span class="number">0</span>):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment">#-------------------------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   detections  [num_anchors, 7]</span></span><br><span class="line">            <span class="comment">#   7的内容为：x1, y1, x2, y2, obj_conf, class_conf, class_pred</span></span><br><span class="line">            <span class="comment">#-------------------------------------------------------------------------#</span></span><br><span class="line">            detections = torch.cat((image_pred[:, :<span class="number">5</span>], class_conf.<span class="built_in">float</span>(), class_pred.<span class="built_in">float</span>()), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment">#------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   获得预测结果中包含的所有种类</span></span><br><span class="line">            <span class="comment">#------------------------------------------#</span></span><br><span class="line">            unique_labels = detections[:, -<span class="number">1</span>].cpu().unique()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> prediction.is_cuda:</span><br><span class="line">                unique_labels = unique_labels.cuda()</span><br><span class="line">                detections = detections.cuda()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> unique_labels:</span><br><span class="line">                <span class="comment">#------------------------------------------#</span></span><br><span class="line">                <span class="comment">#   获得某一类得分筛选后全部的预测结果</span></span><br><span class="line">                <span class="comment">#------------------------------------------#</span></span><br><span class="line">                detections_class = detections[detections[:, -<span class="number">1</span>] == c]</span><br><span class="line"></span><br><span class="line">                <span class="comment">#------------------------------------------#</span></span><br><span class="line">                <span class="comment">#   使用官方自带的非极大抑制会速度更快一些！</span></span><br><span class="line">                <span class="comment">#------------------------------------------#</span></span><br><span class="line">                keep = nms(</span><br><span class="line">                    detections_class[:, :<span class="number">4</span>],</span><br><span class="line">                    detections_class[:, <span class="number">4</span>] * detections_class[:, <span class="number">5</span>],</span><br><span class="line">                    nms_thres</span><br><span class="line">                )</span><br><span class="line">                max_detections = detections_class[keep]</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># # 按照存在物体的置信度排序</span></span><br><span class="line">                <span class="comment"># _, conf_sort_index = torch.sort(detections_class[:, 4]*detections_class[:, 5], descending=True)</span></span><br><span class="line">                <span class="comment"># detections_class = detections_class[conf_sort_index]</span></span><br><span class="line">                <span class="comment"># # 进行非极大抑制</span></span><br><span class="line">                <span class="comment"># max_detections = []</span></span><br><span class="line">                <span class="comment"># while detections_class.size(0):</span></span><br><span class="line">                <span class="comment">#     # 取出这一类置信度最高的，一步一步往下判断，判断重合程度是否大于nms_thres，如果是则去除掉</span></span><br><span class="line">                <span class="comment">#     max_detections.append(detections_class[0].unsqueeze(0))</span></span><br><span class="line">                <span class="comment">#     if len(detections_class) == 1:</span></span><br><span class="line">                <span class="comment">#         break</span></span><br><span class="line">                <span class="comment">#     ious = bbox_iou(max_detections[-1], detections_class[1:])</span></span><br><span class="line">                <span class="comment">#     detections_class = detections_class[1:][ious &lt; nms_thres]</span></span><br><span class="line">                <span class="comment"># # 堆叠</span></span><br><span class="line">                <span class="comment"># max_detections = torch.cat(max_detections).data</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Add max detections to outputs</span></span><br><span class="line">                output[i] = max_detections <span class="keyword">if</span> output[i] <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> torch.cat((output[i], max_detections))</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> output[i] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                output[i]           = output[i].cpu().numpy()</span><br><span class="line">                box_xy, box_wh      = (output[i][:, <span class="number">0</span>:<span class="number">2</span>] + output[i][:, <span class="number">2</span>:<span class="number">4</span>])/<span class="number">2</span>, output[i][:, <span class="number">2</span>:<span class="number">4</span>] - output[i][:, <span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line">                output[i][:, :<span class="number">4</span>]    = self.yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape, letterbox_image)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="原图上进行绘制"><a href="#原图上进行绘制" class="headerlink" title="原图上进行绘制"></a>原图上进行绘制</h4><p>通过第三步，我们可以获得预测框在原图上的位置，而且这些预测框都是经过筛选的。这些筛选后的框可以直接绘制在图片上，就可以获得结果了。</p>
<h3 id="训练部分"><a href="#训练部分" class="headerlink" title="训练部分"></a>训练部分</h3><h4 id="计算loss所需参数"><a href="#计算loss所需参数" class="headerlink" title="计算loss所需参数"></a>计算loss所需参数</h4><p>在计算loss的时候，实际上是pred和target之间的对比：<br>pred就是网络的预测结果。<br>target就是网络的真实框情况。</p>
<h4 id="pred是什么"><a href="#pred是什么" class="headerlink" title="pred是什么"></a>pred是什么</h4><p>对于yolo3的模型来说，网络最后输出的内容就是三个特征层每个网格点对应的预测框及其种类，即三个特征层分别对应着图片被分为不同size的网格后，每个网格点上三个先验框对应的位置、置信度及其种类。</p>
<p>输出层的shape分别为(13,13,75)，(26,26,75)，(52,52,75)，最后一个维度为75是因为是基于voc数据集的，它的类为20种，yolo3只有针对每一个特征层存在3个先验框，所以最后维度为3x25；<br>如果使用的是coco训练集，类则为80种，最后的维度应该为255 = 3x85，三个特征层的shape为(13,13,255)，(26,26,255)，(52,52,255)</p>
<p>现在的y_pre还是没有解码的，解码了之后才是真实图像上的情况。</p>
<h4 id="target是什么。"><a href="#target是什么。" class="headerlink" title="target是什么。"></a>target是什么。</h4><p>target就是一个真实图像中，真实框的情况。<br>第一个维度是batch_size，第二个维度是每一张图片里面真实框的数量，第三个维度内部是真实框的信息，包括位置以及种类。</p>
<h4 id="loss的计算过程"><a href="#loss的计算过程" class="headerlink" title="loss的计算过程"></a>loss的计算过程</h4><p>拿到pred和target后，不可以简单的减一下作为对比，需要进行如下步骤。</p>
<p>判断真实框在图片中的位置，判断其属于哪一个网格点去检测。判断真实框和这个特征点的哪个先验框重合程度最高。计算该网格点应该有怎么样的预测结果才能获得真实框，与真实框重合度最高的先验框被用于作为正样本。<br>根据网络的预测结果获得预测框，计算预测框和所有真实框的重合程度，如果重合程度大于一定门限，则将该预测框对应的先验框忽略。其余作为负样本。<br>最终损失由三个部分组成：a、正样本，编码后的长宽与xy轴偏移量与预测值的差距。b、正样本，预测结果中置信度的值与1对比；负样本，预测结果中置信度的值与0对比。c、实际存在的框，种类预测结果与实际结果的对比。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 详情见nets/yolo_training.py</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YOLOLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, anchors, num_classes, input_shape, cuda, anchors_mask = [[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>], [<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>], [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]]</span>):</span><br><span class="line">        <span class="built_in">super</span>(YOLOLoss, self).__init__()</span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   13x13的特征层对应的anchor是[116,90],[156,198],[373,326]</span></span><br><span class="line">        <span class="comment">#   26x26的特征层对应的anchor是[30,61],[62,45],[59,119]</span></span><br><span class="line">        <span class="comment">#   52x52的特征层对应的anchor是[10,13],[16,30],[33,23]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        self.anchors        = anchors</span><br><span class="line">        self.num_classes    = num_classes</span><br><span class="line">        self.bbox_attrs     = <span class="number">5</span> + num_classes</span><br><span class="line">        self.input_shape    = input_shape</span><br><span class="line">        self.anchors_mask   = anchors_mask</span><br><span class="line"></span><br><span class="line">        self.ignore_threshold = <span class="number">0.7</span></span><br><span class="line">        self.cuda = cuda</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">clip_by_tensor</span>(<span class="params">self, t, t_min, t_max</span>):</span><br><span class="line">        t = t.<span class="built_in">float</span>()</span><br><span class="line">        result = (t &gt;= t_min).<span class="built_in">float</span>() * t + (t &lt; t_min).<span class="built_in">float</span>() * t_min</span><br><span class="line">        result = (result &lt;= t_max).<span class="built_in">float</span>() * result + (result &gt; t_max).<span class="built_in">float</span>() * t_max</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">MSELoss</span>(<span class="params">self, pred, target</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.<span class="built_in">pow</span>(pred - target, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">BCELoss</span>(<span class="params">self, pred, target</span>):</span><br><span class="line">        epsilon = <span class="number">1e-7</span></span><br><span class="line">        pred    = self.clip_by_tensor(pred, epsilon, <span class="number">1.0</span> - epsilon)</span><br><span class="line">        output  = - target * torch.log(pred) - (<span class="number">1.0</span> - target) * torch.log(<span class="number">1.0</span> - pred)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, l, <span class="built_in">input</span>, targets=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment">#----------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   l代表的是，当前输入进来的有效特征层，是第几个有效特征层</span></span><br><span class="line">        <span class="comment">#   input的shape为  bs, 3*(5+num_classes), 13, 13</span></span><br><span class="line">        <span class="comment">#                   bs, 3*(5+num_classes), 26, 26</span></span><br><span class="line">        <span class="comment">#                   bs, 3*(5+num_classes), 52, 52</span></span><br><span class="line">        <span class="comment">#   targets代表的是真实框。</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#--------------------------------#</span></span><br><span class="line">        <span class="comment">#   获得图片数量，特征层的高和宽</span></span><br><span class="line">        <span class="comment">#   13和13</span></span><br><span class="line">        <span class="comment">#--------------------------------#</span></span><br><span class="line">        bs      = <span class="built_in">input</span>.size(<span class="number">0</span>)</span><br><span class="line">        in_h    = <span class="built_in">input</span>.size(<span class="number">2</span>)</span><br><span class="line">        in_w    = <span class="built_in">input</span>.size(<span class="number">3</span>)</span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   计算步长</span></span><br><span class="line">        <span class="comment">#   每一个特征点对应原来的图片上多少个像素点</span></span><br><span class="line">        <span class="comment">#   如果特征层为13x13的话，一个特征点就对应原来的图片上的32个像素点</span></span><br><span class="line">        <span class="comment">#   如果特征层为26x26的话，一个特征点就对应原来的图片上的16个像素点</span></span><br><span class="line">        <span class="comment">#   如果特征层为52x52的话，一个特征点就对应原来的图片上的8个像素点</span></span><br><span class="line">        <span class="comment">#   stride_h = stride_w = 32、16、8</span></span><br><span class="line">        <span class="comment">#   stride_h和stride_w都是32。</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------------#</span></span><br><span class="line">        stride_h = self.input_shape[<span class="number">0</span>] / in_h</span><br><span class="line">        stride_w = self.input_shape[<span class="number">1</span>] / in_w</span><br><span class="line">        <span class="comment">#-------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   此时获得的scaled_anchors大小是相对于特征层的</span></span><br><span class="line">        <span class="comment">#-------------------------------------------------#</span></span><br><span class="line">        scaled_anchors  = [(a_w / stride_w, a_h / stride_h) <span class="keyword">for</span> a_w, a_h <span class="keyword">in</span> self.anchors]</span><br><span class="line">        <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   输入的input一共有三个，他们的shape分别是</span></span><br><span class="line">        <span class="comment">#   bs, 3*(5+num_classes), 13, 13 =&gt; batch_size, 3, 13, 13, 5 + num_classes</span></span><br><span class="line">        <span class="comment">#   batch_size, 3, 26, 26, 5 + num_classes</span></span><br><span class="line">        <span class="comment">#   batch_size, 3, 52, 52, 5 + num_classes</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">        prediction = <span class="built_in">input</span>.view(bs, <span class="built_in">len</span>(self.anchors_mask[l]), self.bbox_attrs, in_h, in_w).permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>).contiguous()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   先验框的中心位置的调整参数</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">        x = torch.sigmoid(prediction[..., <span class="number">0</span>])</span><br><span class="line">        y = torch.sigmoid(prediction[..., <span class="number">1</span>])</span><br><span class="line">        <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   先验框的宽高调整参数</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">        w = prediction[..., <span class="number">2</span>]</span><br><span class="line">        h = prediction[..., <span class="number">3</span>]</span><br><span class="line">        <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   获得置信度，是否有物体</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">        conf = torch.sigmoid(prediction[..., <span class="number">4</span>])</span><br><span class="line">        <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   种类置信度</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">        pred_cls = torch.sigmoid(prediction[..., <span class="number">5</span>:])</span><br><span class="line"></span><br><span class="line">        <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   获得网络应该有的预测结果</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------#</span></span><br><span class="line">        y_true, noobj_mask, box_loss_scale = self.get_target(l, targets, scaled_anchors, in_h, in_w)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#---------------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   将预测结果进行解码，判断预测结果和真实值的重合程度</span></span><br><span class="line">        <span class="comment">#   如果重合程度过大则忽略，因为这些特征点属于预测比较准确的特征点</span></span><br><span class="line">        <span class="comment">#   作为负样本不合适</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------------#</span></span><br><span class="line">        noobj_mask = self.get_ignore(l, x, y, h, w, targets, scaled_anchors, in_h, in_w, noobj_mask)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.cuda:</span><br><span class="line">            y_true          = y_true.cuda()</span><br><span class="line">            noobj_mask      = noobj_mask.cuda()</span><br><span class="line">            box_loss_scale  = box_loss_scale.cuda()</span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   reshape_y_true[...,2:3]和reshape_y_true[...,3:4]</span></span><br><span class="line">        <span class="comment">#   表示真实框的宽高，二者均在0-1之间</span></span><br><span class="line">        <span class="comment">#   真实框越大，比重越小，小框的比重更大。</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        box_loss_scale = <span class="number">2</span> - box_loss_scale</span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   计算中心偏移情况的loss，使用BCELoss效果好一些</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        loss_x = torch.<span class="built_in">sum</span>(self.BCELoss(x, y_true[..., <span class="number">0</span>]) * box_loss_scale * y_true[..., <span class="number">4</span>])</span><br><span class="line">        loss_y = torch.<span class="built_in">sum</span>(self.BCELoss(y, y_true[..., <span class="number">1</span>]) * box_loss_scale * y_true[..., <span class="number">4</span>])</span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   计算宽高调整值的loss</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        loss_w = torch.<span class="built_in">sum</span>(self.MSELoss(w, y_true[..., <span class="number">2</span>]) * <span class="number">0.5</span> * box_loss_scale * y_true[..., <span class="number">4</span>])</span><br><span class="line">        loss_h = torch.<span class="built_in">sum</span>(self.MSELoss(h, y_true[..., <span class="number">3</span>]) * <span class="number">0.5</span> * box_loss_scale * y_true[..., <span class="number">4</span>])</span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   计算置信度的loss</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        loss_conf   = torch.<span class="built_in">sum</span>(self.BCELoss(conf, y_true[..., <span class="number">4</span>]) * y_true[..., <span class="number">4</span>]) + \</span><br><span class="line">                      torch.<span class="built_in">sum</span>(self.BCELoss(conf, y_true[..., <span class="number">4</span>]) * noobj_mask)</span><br><span class="line"></span><br><span class="line">        loss_cls    = torch.<span class="built_in">sum</span>(self.BCELoss(pred_cls[y_true[..., <span class="number">4</span>] == <span class="number">1</span>], y_true[..., <span class="number">5</span>:][y_true[..., <span class="number">4</span>] == <span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">        loss        = loss_x  + loss_y + loss_w + loss_h + loss_conf + loss_cls</span><br><span class="line">        num_pos = torch.<span class="built_in">sum</span>(y_true[..., <span class="number">4</span>])</span><br><span class="line">        num_pos = torch.<span class="built_in">max</span>(num_pos, torch.ones_like(num_pos))</span><br><span class="line">        <span class="keyword">return</span> loss, num_pos</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">calculate_iou</span>(<span class="params">self, _box_a, _box_b</span>):</span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   计算真实框的左上角和右下角</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        b1_x1, b1_x2 = _box_a[:, <span class="number">0</span>] - _box_a[:, <span class="number">2</span>] / <span class="number">2</span>, _box_a[:, <span class="number">0</span>] + _box_a[:, <span class="number">2</span>] / <span class="number">2</span></span><br><span class="line">        b1_y1, b1_y2 = _box_a[:, <span class="number">1</span>] - _box_a[:, <span class="number">3</span>] / <span class="number">2</span>, _box_a[:, <span class="number">1</span>] + _box_a[:, <span class="number">3</span>] / <span class="number">2</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   计算先验框获得的预测框的左上角和右下角</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        b2_x1, b2_x2 = _box_b[:, <span class="number">0</span>] - _box_b[:, <span class="number">2</span>] / <span class="number">2</span>, _box_b[:, <span class="number">0</span>] + _box_b[:, <span class="number">2</span>] / <span class="number">2</span></span><br><span class="line">        b2_y1, b2_y2 = _box_b[:, <span class="number">1</span>] - _box_b[:, <span class="number">3</span>] / <span class="number">2</span>, _box_b[:, <span class="number">1</span>] + _box_b[:, <span class="number">3</span>] / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   将真实框和预测框都转化成左上角右下角的形式</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        box_a = torch.zeros_like(_box_a)</span><br><span class="line">        box_b = torch.zeros_like(_box_b)</span><br><span class="line">        box_a[:, <span class="number">0</span>], box_a[:, <span class="number">1</span>], box_a[:, <span class="number">2</span>], box_a[:, <span class="number">3</span>] = b1_x1, b1_y1, b1_x2, b1_y2</span><br><span class="line">        box_b[:, <span class="number">0</span>], box_b[:, <span class="number">1</span>], box_b[:, <span class="number">2</span>], box_b[:, <span class="number">3</span>] = b2_x1, b2_y1, b2_x2, b2_y2</span><br><span class="line"></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   A为真实框的数量，B为先验框的数量</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        A = box_a.size(<span class="number">0</span>)</span><br><span class="line">        B = box_b.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   计算交的面积</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        max_xy  = torch.<span class="built_in">min</span>(box_a[:, <span class="number">2</span>:].unsqueeze(<span class="number">1</span>).expand(A, B, <span class="number">2</span>), box_b[:, <span class="number">2</span>:].unsqueeze(<span class="number">0</span>).expand(A, B, <span class="number">2</span>))</span><br><span class="line">        min_xy  = torch.<span class="built_in">max</span>(box_a[:, :<span class="number">2</span>].unsqueeze(<span class="number">1</span>).expand(A, B, <span class="number">2</span>), box_b[:, :<span class="number">2</span>].unsqueeze(<span class="number">0</span>).expand(A, B, <span class="number">2</span>))</span><br><span class="line">        inter   = torch.clamp((max_xy - min_xy), <span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line">        inter   = inter[:, :, <span class="number">0</span>] * inter[:, :, <span class="number">1</span>]</span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   计算预测框和真实框各自的面积</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        area_a = ((box_a[:, <span class="number">2</span>]-box_a[:, <span class="number">0</span>]) * (box_a[:, <span class="number">3</span>]-box_a[:, <span class="number">1</span>])).unsqueeze(<span class="number">1</span>).expand_as(inter)  <span class="comment"># [A,B]</span></span><br><span class="line">        area_b = ((box_b[:, <span class="number">2</span>]-box_b[:, <span class="number">0</span>]) * (box_b[:, <span class="number">3</span>]-box_b[:, <span class="number">1</span>])).unsqueeze(<span class="number">0</span>).expand_as(inter)  <span class="comment"># [A,B]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   求IOU</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------#</span></span><br><span class="line">        union = area_a + area_b - inter</span><br><span class="line">        <span class="keyword">return</span> inter / union  <span class="comment"># [A,B]</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_target</span>(<span class="params">self, l, targets, anchors, in_h, in_w</span>):</span><br><span class="line">        <span class="comment">#-----------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   计算一共有多少张图片</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------#</span></span><br><span class="line">        bs              = <span class="built_in">len</span>(targets)</span><br><span class="line">        <span class="comment">#-----------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   用于选取哪些先验框不包含物体</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------#</span></span><br><span class="line">        noobj_mask      = torch.ones(bs, <span class="built_in">len</span>(self.anchors_mask[l]), in_h, in_w, requires_grad = <span class="literal">False</span>)</span><br><span class="line">        <span class="comment">#-----------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   让网络更加去关注小目标</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------#</span></span><br><span class="line">        box_loss_scale  = torch.zeros(bs, <span class="built_in">len</span>(self.anchors_mask[l]), in_h, in_w, requires_grad = <span class="literal">False</span>)</span><br><span class="line">        <span class="comment">#-----------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   batch_size, 3, 13, 13, 5 + num_classes</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------#</span></span><br><span class="line">        y_true          = torch.zeros(bs, <span class="built_in">len</span>(self.anchors_mask[l]), in_h, in_w, self.bbox_attrs, requires_grad = <span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(bs):            </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(targets[b])==<span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            batch_target = torch.zeros_like(targets[b])</span><br><span class="line">            <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   计算出正样本在特征层上的中心点</span></span><br><span class="line">            <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">            batch_target[:, [<span class="number">0</span>,<span class="number">2</span>]] = targets[b][:, [<span class="number">0</span>,<span class="number">2</span>]] * in_w</span><br><span class="line">            batch_target[:, [<span class="number">1</span>,<span class="number">3</span>]] = targets[b][:, [<span class="number">1</span>,<span class="number">3</span>]] * in_h</span><br><span class="line">            batch_target[:, <span class="number">4</span>] = targets[b][:, <span class="number">4</span>]</span><br><span class="line">            batch_target = batch_target.cpu()</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   将真实框转换一个形式</span></span><br><span class="line">            <span class="comment">#   num_true_box, 4</span></span><br><span class="line">            <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">            gt_box          = torch.FloatTensor(torch.cat((torch.zeros((batch_target.size(<span class="number">0</span>), <span class="number">2</span>)), batch_target[:, <span class="number">2</span>:<span class="number">4</span>]), <span class="number">1</span>))</span><br><span class="line">            <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   将先验框转换一个形式</span></span><br><span class="line">            <span class="comment">#   9, 4</span></span><br><span class="line">            <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">            anchor_shapes   = torch.FloatTensor(torch.cat((torch.zeros((<span class="built_in">len</span>(anchors), <span class="number">2</span>)), torch.FloatTensor(anchors)), <span class="number">1</span>))</span><br><span class="line">            <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   计算交并比</span></span><br><span class="line">            <span class="comment">#   self.calculate_iou(gt_box, anchor_shapes) = [num_true_box, 9]每一个真实框和9个先验框的重合情况</span></span><br><span class="line">            <span class="comment">#   best_ns:</span></span><br><span class="line">            <span class="comment">#   [每个真实框最大的重合度max_iou, 每一个真实框最重合的先验框的序号]</span></span><br><span class="line">            <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">            best_ns = torch.argmax(self.calculate_iou(gt_box, anchor_shapes), dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> t, best_n <span class="keyword">in</span> <span class="built_in">enumerate</span>(best_ns):</span><br><span class="line">                <span class="keyword">if</span> best_n <span class="keyword">not</span> <span class="keyword">in</span> self.anchors_mask[l]:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="comment">#----------------------------------------#</span></span><br><span class="line">                <span class="comment">#   判断这个先验框是当前特征点的哪一个先验框</span></span><br><span class="line">                <span class="comment">#----------------------------------------#</span></span><br><span class="line">                k = self.anchors_mask[l].index(best_n)</span><br><span class="line">                <span class="comment">#----------------------------------------#</span></span><br><span class="line">                <span class="comment">#   获得真实框属于哪个网格点</span></span><br><span class="line">                <span class="comment">#----------------------------------------#</span></span><br><span class="line">                i = torch.floor(batch_target[t, <span class="number">0</span>]).long()</span><br><span class="line">                j = torch.floor(batch_target[t, <span class="number">1</span>]).long()</span><br><span class="line">                <span class="comment">#----------------------------------------#</span></span><br><span class="line">                <span class="comment">#   取出真实框的种类</span></span><br><span class="line">                <span class="comment">#----------------------------------------#</span></span><br><span class="line">                c = batch_target[t, <span class="number">4</span>].long()</span><br><span class="line"></span><br><span class="line">                <span class="comment">#----------------------------------------#</span></span><br><span class="line">                <span class="comment">#   noobj_mask代表无目标的特征点</span></span><br><span class="line">                <span class="comment">#----------------------------------------#</span></span><br><span class="line">                noobj_mask[b, k, j, i] = <span class="number">0</span></span><br><span class="line">                <span class="comment">#----------------------------------------#</span></span><br><span class="line">                <span class="comment">#   tx、ty代表中心调整参数的真实值</span></span><br><span class="line">                <span class="comment">#----------------------------------------#</span></span><br><span class="line">                y_true[b, k, j, i, <span class="number">0</span>] = batch_target[t, <span class="number">0</span>] - i.<span class="built_in">float</span>()</span><br><span class="line">                y_true[b, k, j, i, <span class="number">1</span>] = batch_target[t, <span class="number">1</span>] - j.<span class="built_in">float</span>()</span><br><span class="line">                y_true[b, k, j, i, <span class="number">2</span>] = math.log(batch_target[t, <span class="number">2</span>] / anchors[best_n][<span class="number">0</span>])</span><br><span class="line">                y_true[b, k, j, i, <span class="number">3</span>] = math.log(batch_target[t, <span class="number">3</span>] / anchors[best_n][<span class="number">1</span>])</span><br><span class="line">                y_true[b, k, j, i, <span class="number">4</span>] = <span class="number">1</span></span><br><span class="line">                y_true[b, k, j, i, c + <span class="number">5</span>] = <span class="number">1</span></span><br><span class="line">                <span class="comment">#----------------------------------------#</span></span><br><span class="line">                <span class="comment">#   用于获得xywh的比例</span></span><br><span class="line">                <span class="comment">#   大目标loss权重小，小目标loss权重大</span></span><br><span class="line">                <span class="comment">#----------------------------------------#</span></span><br><span class="line">                box_loss_scale[b, k, j, i] = batch_target[t, <span class="number">2</span>] * batch_target[t, <span class="number">3</span>] / in_w / in_h</span><br><span class="line">        <span class="keyword">return</span> y_true, noobj_mask, box_loss_scale</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_ignore</span>(<span class="params">self, l, x, y, h, w, targets, scaled_anchors, in_h, in_w, noobj_mask</span>):</span><br><span class="line">        <span class="comment">#-----------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   计算一共有多少张图片</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------#</span></span><br><span class="line">        bs = <span class="built_in">len</span>(targets)</span><br><span class="line"></span><br><span class="line">        FloatTensor = torch.cuda.FloatTensor <span class="keyword">if</span> x.is_cuda <span class="keyword">else</span> torch.FloatTensor</span><br><span class="line">        LongTensor  = torch.cuda.LongTensor <span class="keyword">if</span> x.is_cuda <span class="keyword">else</span> torch.LongTensor</span><br><span class="line">        <span class="comment">#-----------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   生成网格，先验框中心，网格左上角</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------#</span></span><br><span class="line">        grid_x = torch.linspace(<span class="number">0</span>, in_w - <span class="number">1</span>, in_w).repeat(in_h, <span class="number">1</span>).repeat(</span><br><span class="line">            <span class="built_in">int</span>(bs * <span class="built_in">len</span>(self.anchors_mask[l])), <span class="number">1</span>, <span class="number">1</span>).view(x.shape).<span class="built_in">type</span>(FloatTensor)</span><br><span class="line">        grid_y = torch.linspace(<span class="number">0</span>, in_h - <span class="number">1</span>, in_h).repeat(in_w, <span class="number">1</span>).t().repeat(</span><br><span class="line">            <span class="built_in">int</span>(bs * <span class="built_in">len</span>(self.anchors_mask[l])), <span class="number">1</span>, <span class="number">1</span>).view(y.shape).<span class="built_in">type</span>(FloatTensor)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 生成先验框的宽高</span></span><br><span class="line">        scaled_anchors_l = np.array(scaled_anchors)[self.anchors_mask[l]]</span><br><span class="line">        anchor_w = FloatTensor(scaled_anchors_l).index_select(<span class="number">1</span>, LongTensor([<span class="number">0</span>]))</span><br><span class="line">        anchor_h = FloatTensor(scaled_anchors_l).index_select(<span class="number">1</span>, LongTensor([<span class="number">1</span>]))</span><br><span class="line">        </span><br><span class="line">        anchor_w = anchor_w.repeat(bs, <span class="number">1</span>).repeat(<span class="number">1</span>, <span class="number">1</span>, in_h * in_w).view(w.shape)</span><br><span class="line">        anchor_h = anchor_h.repeat(bs, <span class="number">1</span>).repeat(<span class="number">1</span>, <span class="number">1</span>, in_h * in_w).view(h.shape)</span><br><span class="line">        <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">        <span class="comment">#   计算调整后的先验框中心与宽高</span></span><br><span class="line">        <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">        pred_boxes_x    = torch.unsqueeze(x.data + grid_x, -<span class="number">1</span>)</span><br><span class="line">        pred_boxes_y    = torch.unsqueeze(y.data + grid_y, -<span class="number">1</span>)</span><br><span class="line">        pred_boxes_w    = torch.unsqueeze(torch.exp(w.data) * anchor_w, -<span class="number">1</span>)</span><br><span class="line">        pred_boxes_h    = torch.unsqueeze(torch.exp(h.data) * anchor_h, -<span class="number">1</span>)</span><br><span class="line">        pred_boxes      = torch.cat([pred_boxes_x, pred_boxes_y, pred_boxes_w, pred_boxes_h], dim = -<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(bs):           </span><br><span class="line">            <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   将预测结果转换一个形式</span></span><br><span class="line">            <span class="comment">#   pred_boxes_for_ignore      num_anchors, 4</span></span><br><span class="line">            <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">            pred_boxes_for_ignore = pred_boxes[b].view(-<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">            <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">            <span class="comment">#   计算真实框，并把真实框转换成相对于特征层的大小</span></span><br><span class="line">            <span class="comment">#   gt_box      num_true_box, 4</span></span><br><span class="line">            <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(targets[b]) &gt; <span class="number">0</span>:</span><br><span class="line">                batch_target = torch.zeros_like(targets[b])</span><br><span class="line">                <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">                <span class="comment">#   计算出正样本在特征层上的中心点</span></span><br><span class="line">                <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">                batch_target[:, [<span class="number">0</span>,<span class="number">2</span>]] = targets[b][:, [<span class="number">0</span>,<span class="number">2</span>]] * in_w</span><br><span class="line">                batch_target[:, [<span class="number">1</span>,<span class="number">3</span>]] = targets[b][:, [<span class="number">1</span>,<span class="number">3</span>]] * in_h</span><br><span class="line">                batch_target = batch_target[:, :<span class="number">4</span>]</span><br><span class="line">                <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">                <span class="comment">#   计算交并比</span></span><br><span class="line">                <span class="comment">#   anch_ious       num_true_box, num_anchors</span></span><br><span class="line">                <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">                anch_ious = self.calculate_iou(batch_target, pred_boxes_for_ignore)</span><br><span class="line">                <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">                <span class="comment">#   每个先验框对应真实框的最大重合度</span></span><br><span class="line">                <span class="comment">#   anch_ious_max   num_anchors</span></span><br><span class="line">                <span class="comment">#-------------------------------------------------------#</span></span><br><span class="line">                anch_ious_max, _    = torch.<span class="built_in">max</span>(anch_ious, dim = <span class="number">0</span>)</span><br><span class="line">                anch_ious_max       = anch_ious_max.view(pred_boxes[b].size()[:<span class="number">3</span>])</span><br><span class="line">                noobj_mask[b][anch_ious_max &gt; self.ignore_threshold] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> noobj_mask</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

  
  
    
    <div class="footer">
      
      
      
      
        <div class="donate">
          <div class="imgs">
            
              <img src="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png" srcset="data:image/png;base64,666">
            
              <img src="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png" srcset="data:image/png;base64,666">
            
          </div>
        </div>
      
    </div>
  
  
    


  <div class="article-meta" id="bottom">
    <div class="new-meta-box">
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2022-10-04T21:35:06+08:00">
  <a class="notlink">
    <i class="fa-solid fa-edit fa-fw" aria-hidden="true"></i>
    <p>更新于：2022年10月4日</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" rel="nofollow"><i class="fa-solid fa-hashtag fa-fw" aria-hidden="true"></i><p>论文笔记</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/yolov3/" rel="nofollow"><i class="fa-solid fa-hashtag fa-fw" aria-hidden="true"></i><p>yolov3</p></a></div>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title rel="external nofollow noopener noreferrer" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://pistachio0812.github.io/zh-CN/YOLOV3/&title=yolov3论文笔记 - 阿月浑子-Hexo博客&summary=">
          
            <img src="volantis-static/media/org.volantis/logo/128/qq.png" class="lazyload" data-srcset="volantis-static/media/org.volantis/logo/128/qq.png" srcset="data:image/png;base64,666">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title rel="external nofollow noopener noreferrer" target="_blank" href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://pistachio0812.github.io/zh-CN/YOLOV3/&title=yolov3论文笔记 - 阿月浑子-Hexo博客&summary=">
          
            <img src="volantis-static/media/org.volantis/logo/128/qzone.png" class="lazyload" data-srcset="volantis-static/media/org.volantis/logo/128/qzone.png" srcset="data:image/png;base64,666">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title rel="external nofollow noopener noreferrer" target="_blank" href="http://service.weibo.com/share/share.php?url=http://pistachio0812.github.io/zh-CN/YOLOV3/&title=yolov3论文笔记 - 阿月浑子-Hexo博客&summary=">
          
            <img src="volantis-static/media/org.volantis/logo/128/weibo.png" class="lazyload" data-srcset="volantis-static/media/org.volantis/logo/128/weibo.png" srcset="data:image/png;base64,666">
          
        </a>
      
    
      
        
        <div class="hoverbox">
          <a class="share"><img src="volantis-static/media/org.volantis/logo/128/wechat.png" class="lazyload" data-srcset="volantis-static/media/org.volantis/logo/128/wechat.png" srcset="data:image/png;base64,666"></a>
          <div class="target">
            <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAARgAAAEYCAAAAACi5bZQAAADBElEQVR42u3aSXLDMAwEQP3/08k9FZew0RaS5s2LJLJ1mQJwfVm/rgsBGDBgwIABswbmKq6f17/6HP0++ryp+708DxgwYMCAAQNmHUw4AAVhsmDd68bOAwYMGDBgwIBZC/PujZ4KjNXzgAEDBgwYMGD+D0w04E0Hwup+wIABAwYMGDBguo2uU0EPDBgwYMCAAfN/YbINqu7GowfoAr69EwkGDBgwYMCAeRvMqQHoT30eG4AGAwYMGDBgwDwWpruyg0F3/5sKnOXzgAEDBgwYMGDWwGQHebKFpCxINUhWC2blTiQYMGDAgAED5uMw2YNPBbMsTPWg0RcOBgwYMGDAgPk7MN0g1h2grjbQuoEUDBgwYMCAAbMHpluAuprrVIOvXOgCAwYMGDBgwKyBqT4g+nv34NHPUw06MGDAgAEDBswemKmBnCpUdtCn2wC8/R0MGDBgwIABsw6mfcNkQWoarNpwAwMGDBgwYMDsh+kGvKnCUzS4Tb8oMGDAgAEDBsw+mGhwCt+4eZ/pRl854IEBAwYMGDBgHg9THfCpBrYruKauT38PBgwYMGDAgFkD093AdBDrDiZFC2O3g0NgwIABAwYMmMfDTDXcsoNA2UbbVEHr7YNDYMCAAQMGDJjjMKeCWLeQNf3CbvcHBgwYMGDAgFkHE31guOBTHOTpDhh1G4RgwIABAwYMmD0w1QNHH5htgEV/7wbF9OAQGDBgwIABA+axMFMFompQnGq4hYMcGDBgwIABA2Y9TDYodQtH1eCX3V+5UAYGDBgwYMCAWQPTXdmg1z3A8UEkMGDAgAEDBswamKu4pgpG3QJWFw4MGDBgwIABsx+mGuiy12cLUdEXmN1vu+EGBgwYMGDAgHkcTDTQVQ9cHaDurnYnEgwYMGDAgAHz52C6G5kKfNX/Hwt4YMCAAQMGDJh1MNOFpej32eekG25gwIABAwYMmMfDVAd6qgDVwlZ1X7cFMjBgwIABAwbMOpipBla0QXcqKFYDJBgwYMCAAQNmH4wFBgwYMGDAgFm2vgFXkGHK+lNXtQAAAABJRU5ErkJggg==">
          </div>
        </div>
      
    
      
    
  </div>
</div>



        
      
    </div>
  </div>


  
  

  
    <div class="prev-next">
      
        <a class="prev" href="/zh-CN/Faster-rcnn/">
          <p class="title"><i class="fas fa-chevron-left" aria-hidden="true"></i>Faster-RCNN论文笔记</p>
          <p class="content">论文地址：Faster R-CNN
源码地址：ShaoqingRen/faster_rcnn: Faster R-CNN (github.com)
文章引用源码：https://github.c...</p>
        </a>
      
      
        <a class="next" href="/zh-CN/%E6%89%81%E5%B9%B3%E6%97%B6%E4%BB%A3%E7%9A%84%E5%86%99%E4%BD%9C/">
          <p class="title">扁平时代的写作·节选<i class="fas fa-chevron-right" aria-hidden="true"></i></p>
          <p class="content">​        一个「扁平」的世界里众声喧沸。从原则上说，由编辑、审查、批准一类关卡所组成的文化权力体系几近瓦解，每一个IP地址自由发声，都可能成为强大的文化媒体。英才惨遭埋没的可能，伪学与赝...</p>
        </a>
      
    </div>
  
</article>


  

  






</div>
<aside class="l_side">
  
  
    
    



  <section class="widget toc-wrapper sticky shadow desktop mobile" id="toc-div">
    
  <header>
    
      <i class="fa-solid fa-list fa-fw" aria-hidden="true"></i><span class="name">本文目录</span>
    
  </header>


    <div class="content">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E6%80%9D%E8%B7%AF"><span class="toc-text">实现思路</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E9%83%A8%E5%88%86"><span class="toc-text">预测部分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E5%B9%B2%E7%BD%91%E7%BB%9CDarknet53"><span class="toc-text">主干网络Darknet53</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8E%E7%89%B9%E5%BE%81%E5%B1%82%E8%8E%B7%E5%8F%96%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C"><span class="toc-text">从特征层获取预测结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E7%9A%84%E8%A7%A3%E7%A0%81"><span class="toc-text">预测结果的解码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E7%BB%98%E5%88%B6"><span class="toc-text">原图上进行绘制</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E9%83%A8%E5%88%86"><span class="toc-text">训练部分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97loss%E6%89%80%E9%9C%80%E5%8F%82%E6%95%B0"><span class="toc-text">计算loss所需参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#pred%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">pred是什么</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#target%E6%98%AF%E4%BB%80%E4%B9%88%E3%80%82"><span class="toc-text">target是什么。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#loss%E7%9A%84%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B"><span class="toc-text">loss的计算过程</span></a></li></ol></li></ol></li></ol>
    </div>
  </section>


  


</aside>



        
        
          <!--此文件用来存放一些不方便取值的变量-->
<!--思路大概是将值藏到重加载的区域内-->

<script>
  window.pdata={}
  pdata.ispage=true;
  pdata.postTitle="yolov3论文笔记";
  pdata.commentPath="";
  pdata.commentPlaceholder="";

  var l_header=document.getElementById("l_header");
  
  l_header.classList.add("show");
  
</script>

        
      </div>
      
  
  <footer class="footer clearfix">
    <br><br>
    
      
        <div class="aplayer-container">
          

  
    <meting-js theme="#1BCDFC" autoplay="false" volume="0.7" loop="all" order="list" fixed="false" list-max-height="320px" server="tencent" type="playlist" id="2185397204" list-folded="true">
    </meting-js>
  


        </div>
      
    
      
        <br>
        <div class="social-wrapper">
          
            
              <a href="/atom.xml" class="social fas fa-rss flat-btn" target="_blank" rel="external nofollow noopener noreferrer">
                
              </a>
            
          
            
              <a href="mailto:2395856915@qq.com" class="social fas fa-envelope flat-btn" target="_blank" rel="external nofollow noopener noreferrer">
                
              </a>
            
          
            
              <a href="https://github.com/pistachio0812" class="social fab fa-github flat-btn" target="_blank" rel="external nofollow noopener noreferrer">
                
              </a>
            
          
            
          
            
          
        </div>
      
    
      
        <div><p>博客内容遵循 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
      
    
      
        本站使用
        <a href="https://github.com/volantis-x/hexo-theme-volantis/tree/4.2.0" target="_blank" class="codename" rel="external nofollow noopener noreferrer">Volantis</a>
        作为主题
      
    
      
        <div class="copyright">
        <p><a href="/">Copyright ©2020-2023江西理工大学.All Rights Reserved</a></p>

        </div>
      
    
  </footer>


      <a id="s-top" class="fas fa-arrow-up fa-fw" href="javascript:void(0)"></a>
    </div>
  </div>
  <div>
    <script>
window.volantis={};
window.volantis.loadcss=document.getElementById("loadcss");
/********************脚本懒加载函数********************************/
function loadScript(src, cb) {
var HEAD = document.getElementsByTagName('head')[0] || document.documentElement;
var script = document.createElement('script');
script.setAttribute('type','text/javascript');
if (cb) script.onload = cb;
script.setAttribute('src', src);
HEAD.appendChild(script);
}
//https://github.com/filamentgroup/loadCSS
var loadCSS = function( href, before, media, attributes ){
	var doc = window.document;
	var ss = doc.createElement( "link" );
	var ref;
	if( before ){
		ref = before;
	}
	else {
		var refs = ( doc.body || doc.getElementsByTagName( "head" )[ 0 ] ).childNodes;
		ref = refs[ refs.length - 1];
	}
	var sheets = doc.styleSheets;
	if( attributes ){
		for( var attributeName in attributes ){
			if( attributes.hasOwnProperty( attributeName ) ){
				ss.setAttribute( attributeName, attributes[attributeName] );
			}
		}
	}
	ss.rel = "stylesheet";
	ss.href = href;
	ss.media = "only x";
	function ready( cb ){
		if( doc.body ){
			return cb();
		}
		setTimeout(function(){
			ready( cb );
		});
	}
	ready( function(){
		ref.parentNode.insertBefore( ss, ( before ? ref : ref.nextSibling ) );
	});
	var onloadcssdefined = function( cb ){
		var resolvedHref = ss.href;
		var i = sheets.length;
		while( i-- ){
			if( sheets[ i ].href === resolvedHref ){
				return cb();
			}
		}
		setTimeout(function() {
			onloadcssdefined( cb );
		});
	};
	function loadCB(){
		if( ss.addEventListener ){
			ss.removeEventListener( "load", loadCB );
		}
		ss.media = media || "all";
	}
	if( ss.addEventListener ){
		ss.addEventListener( "load", loadCB);
	}
	ss.onloadcssdefined = onloadcssdefined;
	onloadcssdefined( loadCB );
	return ss;
};
</script>
<script>
  
  loadCSS("volantis-static/libs/@fortawesome/fontawesome-free/css/all.min.css", window.volantis.loadcss);
  
  
  loadCSS("volantis-static/libs/font-awesome-animation/font-awesome-animation.min.css", window.volantis.loadcss);
  
  
  loadCSS("volantis-static/libs/node-waves/dist/waves.min.css", window.volantis.loadcss);
  
  
</script>
<!-- required -->

<script src="/volantis-static/libs/jquery/dist/jquery.min.js"></script>

<script>
  function pjax_fancybox() {
    $(".md .gallery").find("img").each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("class", "fancybox");
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 判断当前页面是否存在描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".md .gallery").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  function SCload_fancybox() {
    if ($(".md .gallery").find("img").length == 0) return;
    loadCSS("https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css", document.getElementById("loadcss"));
    setTimeout(function() {
      loadScript('https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js', pjax_fancybox)
    }, 1);
  };
  $(function () {
    SCload_fancybox();
  });
</script>


<!-- internal -->







  <script defer src="volantis-static/libs/vanilla-lazyload/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 0
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    lazyLoadInstance.update();
  });
  document.addEventListener('pjax:complete', function () {
    lazyLoadInstance.update();
  });
</script>




  
  
    <script>
      window.FPConfig = {
        delay: 0,
        ignoreKeywords: [],
        maxRPS: 5,
        hoverDelay: 25
      };
    </script>
    <script defer src="volantis-static/libs/flying-pages/flying-pages.min.js"></script>
  








  <script>
  let APlayerController = new Object();
  APlayerController.id = '2185397204';  // 设定全局音乐播放ID
  APlayerController.volume = '0.7';
  loadCSS("https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.css", window.volantis.loadcss);
  // APlayer 需要在  MetingJS 之前加载
  loadScript("volantis-static/libs/aplayer/dist/APlayer.min.js")
  window.volantis.LoadMetingJS=0
  var checkAPlayer = setInterval(function () {
    if (!window.APlayer) return
    clearInterval(checkAPlayer)
	if (!window.volantis.LoadMetingJS&&!window.MetingJSElement){
	  window.LoadMetingJS=1
      loadScript("volantis-static/libs/meting/dist/Meting.min.js")
	  }
  }, 2500)

</script>







  
<script src="/js/app.js"></script>



<!-- optional -->

  <script>
const SearchServiceimagePath="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@master/img/";
const ROOT =  ("/" || "/").endsWith('/') ? ("/" || "/") : ("//" || "/" );

$('.input.u-search-input').one('focus',function(){
	
		loadScript('/js/search/hexo.js',setSearchService);
	
})

function listenSearch(){
  
    customSearch = new HexoSearch({
      imagePath: SearchServiceimagePath
    });
  
}
function setSearchService() {
	listenSearch();
	
}
</script>





  
<script src="/volantis-static/libs/node-waves/dist/waves.min.js"></script>

  <script type="text/javascript">
    $(function () {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>



  
<script src="/volantis-static/libs/comment_typing/comment_typing.js"></script>












<script>
function listennSidebarTOC() {
  const navItems = document.querySelectorAll(".toc li");
  if (!navItems.length) return;
  const sections = [...navItems].map((element) => {
    const link = element.querySelector(".toc-link");
    const target = document.getElementById(
      decodeURI(link.getAttribute("href")).replace("#", "")
    );
    link.addEventListener("click", (event) => {
      event.preventDefault();
      window.scrollTo({
		top: target.offsetTop + 100,
		
		behavior: "smooth"
		
	  });
    });
    return target;
  });

  function activateNavByIndex(target) {
    if (target.classList.contains("active-current")) return;

    document.querySelectorAll(".toc .active").forEach((element) => {
      element.classList.remove("active", "active-current");
    });
    target.classList.add("active", "active-current");
    let parent = target.parentNode;
    while (!parent.matches(".toc")) {
      if (parent.matches("li")) parent.classList.add("active");
      parent = parent.parentNode;
    }
  }

  function findIndex(entries) {
    let index = 0;
    let entry = entries[index];
    if (entry.boundingClientRect.top > 0) {
      index = sections.indexOf(entry.target);
      return index === 0 ? 0 : index - 1;
    }
    for (; index < entries.length; index++) {
      if (entries[index].boundingClientRect.top <= 0) {
        entry = entries[index];
      } else {
        return sections.indexOf(entry.target);
      }
    }
    return sections.indexOf(entry.target);
  }

  function createIntersectionObserver(marginTop) {
    marginTop = Math.floor(marginTop + 10000);
    let intersectionObserver = new IntersectionObserver(
      (entries, observe) => {
        let scrollHeight = document.documentElement.scrollHeight + 100;
        if (scrollHeight > marginTop) {
          observe.disconnect();
          createIntersectionObserver(scrollHeight);
          return;
        }
        let index = findIndex(entries);
        activateNavByIndex(navItems[index]);
      },
      {
        rootMargin: marginTop + "px 0px -100% 0px",
        threshold: 0,
      }
    );
    sections.forEach((element) => {
      element && intersectionObserver.observe(element);
    });
  }
  createIntersectionObserver(document.documentElement.scrollHeight);
}

document.addEventListener("DOMContentLoaded", listennSidebarTOC);
document.addEventListener("pjax:success", listennSidebarTOC);
</script>

<!-- more -->




    
      


<script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script>


<script>
    var pjax;
    document.addEventListener('DOMContentLoaded', function () {
      pjax = new Pjax({
        elements: 'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([pjax-fancybox])',
        selectors: [
          "title",
          "#l_cover",
          "#pjax-container",
          "#pjax-header-nav-list"
        ],
        cacheBust: false,   // url 地址追加时间戳，用以避免浏览器缓存
        timeout: 5000
      });
    });

    document.addEventListener('pjax:send', function (e) {
      //window.stop(); // 相当于点击了浏览器的停止按钮

      try {
        var currentUrl = window.location.pathname;
        var targetUrl = e.triggerElement.href;
        var banUrl = [""];
        if (banUrl[0] != "") {
          banUrl.forEach(item => {
            if(currentUrl.indexOf(item) != -1 || targetUrl.indexOf(item) != -1) {
              window.location.href = targetUrl;
            }
          });
        }
      } catch (error) {}

      window.subData = null; // 移除标题（用于一二级导航栏切换处）
      if (typeof $.fancybox != "undefined") {
        $.fancybox.close();    // 关闭弹窗
      }
      volantis.$switcher.removeClass('active'); // 关闭移动端激活的搜索框
      volantis.$header.removeClass('z_search-open'); // 关闭移动端激活的搜索框
      volantis.$wrapper.removeClass('sub'); // 跳转页面时关闭二级导航

      // 解绑事件 避免重复监听
      volantis.$topBtn.unbind('click');
      $('.menu a').unbind('click');
      $(window).unbind('resize');
      $(window).unbind('scroll');
      $(document).unbind('scroll');
      $(document).unbind('click');
      $('body').unbind('click');
	  
    });

    document.addEventListener('pjax:complete', function () {
      // 关于百度统计对 SPA 页面的处理：
      // 方案一：百度统计>管理>单页应用设置中，打开开启按钮即可对SPA进行统计。 https://tongji.baidu.com/web/help/article?id=324
      // 方案二：取消注释下列代码。 https://tongji.baidu.com/web/help/article?id=235
       

      // 关于谷歌统计对 SPA 页面的处理：
      // 当应用以动态方式加载内容并更新地址栏中的网址时，也应该更新通过 gtag.js 存储的网页网址。
      // https://developers.google.cn/analytics/devguides/collection/gtagjs/single-page-applications?hl=zh-cn
      
	 

      $('.nav-main').find('.list-v').not('.menu-phone').removeAttr("style",""); // 移除小尾巴的移除
      $('.menu-phone.list-v').removeAttr("style",""); // 移除小尾巴的移除
      $('script[data-pjax], .pjax-reload script').each(function () {
        $(this).parent().append($(this).remove());
      });
      try{
          if (typeof $.fancybox == "undefined") {
            SCload_fancybox();
          } else {
            pjax_fancybox();
          }
        
        
        
        
        
        
        
        
        
        
      } catch (e) {
        console.log(e);
      }
	  
    });

    document.addEventListener('pjax:error', function (e) {
	  
      window.location.href = e.triggerElement.href;
    });
</script>

    
  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
