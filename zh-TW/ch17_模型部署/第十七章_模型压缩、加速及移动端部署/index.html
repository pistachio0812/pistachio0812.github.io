<!DOCTYPE html>
<html lang="zh-CN,en,zh-TW,default">
    <head hexo-theme="https://github.com/volantis-x/hexo-theme-volantis/tree/7.6.2">
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
    
  
  <!-- 渲染优化 -->
  <meta http-equiv="x-dns-prefetch-control" content="on">
  <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- 页面元数据 -->
  
  <title>模型压缩及移动端部署 - 阿月浑子-Hexo博客</title>
  

  

  <!-- feed -->
  
    <link rel="alternate" href="/atom.xml" title="阿月浑子-Hexo博客" type="application/atom+xml">
  

  <!-- import meta -->
  

  <!-- link -->
  

  <!-- import link -->
  

  
    
<link rel="stylesheet" href="/css/first.css">

  

  
  <link rel="stylesheet" href="/css/style.css" media="print" onload="this.media='all';this.onload=null">
  <noscript><link rel="stylesheet" href="/css/style.css"></noscript>
  

  <script id="loadcss"></script>


<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>  <script>
    function music_on() {
        var audio1 = document.getElementById('bg_music');
        if (audio1.paused) {
            audio1.play();
        }else{
            audio1.pause();
            audio1.currentTime = 0;//音乐从头播放
        }
    }
    function BackTOP() {
        $("#btn").hide();
        $(function () {
            $(window).scroll(function () {
                if ($(window).scrollTop() > 50) {
                    $("#btn").fadeIn(200);
                } else {
                    $("#btn").fadeOut(200);
                }
            });
            $("#btn").click(function () {
                $('body,html').animate({
                        scrollTop: 0
                    },
                    500);
                return false;
            });
        });
        $(function () {
            $("#say").click(function () {
                $('body,html').animate({
                        scrollTop: $('html, body').get(0).scrollHeight
                    },
                    500);
                return false;
            });
        })
    }
 
    $('#readmode').click(function () {
            $('body').toggleClass('read-mode')
        })
        
    function SiderMenu() {
        $('#main-container').toggleClass('open');
        $('.iconflat').css('width', '50px').css('height', '50px');
        $('.openNav').css('height', '50px');
        $('#main-container,#mo-nav,.openNav').toggleClass('open')
    }
 
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($("body")), setTimeout(
            function () {
                var DarkMode = document.cookie.replace(/(?:(?:^|.*;\s*)DarkMode\s*\=\s*([^;]*).*$)|^.*$/, "$1") ||
                    '0';
                (volantis.dark.mode == "dark") 
                ? 
                ($("html").addClass("DarkMode"), 
                document.cookie = "DarkMode=1;path=/", 
                $('#modeicon').attr("xlink:href", "#icon-sun")) 
                : 
                ($("html").removeClass("DarkMode"), 
                document.cookie = "DarkMode=0;path=/", 
                $('#modeicon').attr("xlink:href", "#icon-_moon")), 
                setTimeout(function () {
                    $(".Cuteen_DarkSky").fadeOut(1e3, function () {
                        $(this).remove()
                    })
                }, 2e3)
            }), 50
    }
 
    function checkNightMode() {
        if ($("html").hasClass("n-f")) {
            $("html").removeClass("day");
            $("html").addClass("DarkMode");
            $('#modeicon').attr("xlink:href", "#icon-sun")
            return;
        }
        if ($("html").hasClass("d-f")) {
            $("html").removeClass("DarkMode");
            $("html").addClass("day");
            $('#modeicon').attr("xlink:href", "#icon-_moon")
 
            return;
        }
        if (document.cookie.replace(/(?:(?:^|.*;\s*)DarkMode\s*\=\s*([^;]*).*$)|^.*$/, "$1") === '') {
            if (volantis.dark.mode == "dark") {
                $("html").addClass("DarkMode");
                document.cookie = "DarkMode=1;path=/";
                console.log('夜间模式开启');
                $('#modeicon').attr("xlink:href", "#icon-sun")
            } else {
                $("html").removeClass("DarkMode");
                document.cookie = "DarkMode=0;path=/";
                console.log('夜间模式关闭');
                $('#modeicon').attr("xlink:href", "#icon-_moon")
            }
        } else {
            var DarkMode = document.cookie.replace(/(?:(?:^|.*;\s*)DarkMode\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
            if (DarkMode == '0') {
                $("html").removeClass("DarkMode");
                $('#modeicon').attr("xlink:href", "#icon-_moon")
            } else if (DarkMode == '1') {
                $("html").addClass("DarkMode");
                $('#modeicon').attr("xlink:href", "#icon-sun")
            }
        }
    }
    BackTOP();
</script>
 
<style>
    #RightDownBtn {
        position: fixed;
        left: 1.875rem;
        bottom: 1.875rem;
        padding: 0.3125rem 0.625rem;
        background: #fff;
        border-radius: 0.1875rem;
        transition: 0.3s ease all;
        z-index: 1;
        align-items: flex-end;
        flex-direction: column;
        display: -moz-flex;
        display: flex;
        float: right;
    }
 
    #RightDownBtn>a,
    #RightDownBtn>label {
        width: 1.5em;
        height: 1.5em;
        margin: 0.3125rem 0;
        transition: .2s cubic-bezier(.25, .46, .45, .94);
    }
 
    /* font color */
    .DarkMode #page,
    .DarkMode #colophon,
    .DarkMode #vcomments .vbtn,
    .DarkMode .art-content #archives .al_mon_list .al_mon,
    .DarkMode .art-content #archives .al_mon_list span,
    .DarkMode body,
    .DarkMode .art-content #archives .al_mon_list .al_mon,
    .DarkMode .art-content #archives .al_mon_list span,
    .DarkMode button,
    .DarkMode .art .art-content #archives a,
    .DarkMode textarea,
    .DarkMode strong,
    .DarkMode a,
    .DarkMode p,
	.DarkMode li,
    .DarkMode .label {
        color: rgba(255, 255, 255, .6);
    }
 
	
    .DarkMode #page,
    .DarkMode body,
    .DarkMode #colophon,
    .DarkMode #main-container,
    .DarkMode #page .yya,
    .DarkMode #content,
    .DarkMode #contentss,
    .DarkMode #footer {
        background-color: #292a2d;
    }
    .DarkMode strong,
    .DarkMode img {
        filter: brightness(.7);
    }
 
    /* sun and noon */
    .Cuteen_DarkSky,
    .Cuteen_DarkSky:before {
        content: "";
        position: fixed;
        left: 0;
        right: 0;
        top: 0;
        bottom: 0;
        z-index: 88888888
    }
 
    .Cuteen_DarkSky {
        background: linear-gradient(#feb8b0, #fef9db)
    }
 
    .Cuteen_DarkSky:before {
        transition: 2s ease all;
        opacity: 0;
        background: linear-gradient(#4c3f6d, #6c62bb, #93b1ed)
    }
 
    .DarkMode .Cuteen_DarkSky:before {
        opacity: 1
    }
 
    .Cuteen_DarkPlanet {
        z-index: 99999999;
        position: fixed;
        left: -50%;
        top: -50%;
        width: 200%;
        height: 200%;
        -webkit-animation: CuteenPlanetMove 2s cubic-bezier(.7, 0, 0, 1);
        animation: CuteenPlanetMove 2s cubic-bezier(.7, 0, 0, 1);
        transform-origin: center bottom
    }
 
    @-webkit-keyframes CuteenPlanetMove {
        0% {
            transform: rotate(0)
        }
 
        to {
            transform: rotate(360deg)
        }
    }
 
    @keyframes CuteenPlanetMove {
        0% {
            transform: rotate(0)
        }
 
        to {
            transform: rotate(360deg)
        }
    }
 
    .Cuteen_DarkPlanet:after {
        position: absolute;
        left: 35%;
        top: 40%;
        width: 9.375rem;
        height: 9.375rem;
        border-radius: 50%;
        content: "";
        background: linear-gradient(#fefefe, #fffbe8)
    }
</style>
  <body itemscope itemtype="http://schema.org/WebPage">
    <!-- import body_begin begin-->
        <script></script>
    <!-- import body_begin end-->
    <!-- Custom Files bodyBegin begin-->
    
    <!-- 浏览器搞笑标题-->
    <script type="text/javascript" src="/js/FunnyTitle.js"></script>
    <!-- Custom Files bodyBegin end-->
    <!--樱花特效-->
    <script src="https://gcore.jsdelivr.net/gh/zyoushuo/Blog/hexo/js/sakura.js"></script>
    <!--鼠标滑动特效-->
    <script src="https://gcore.jsdelivr.net/gh/zyoushuo/Blog/hexo/js/mouse_slide.js"></script>
    <!--鼠标点击特效-->
    <script src="https://gcore.jsdelivr.net/gh/zyoushuo/Blog/hexo/js/mouse_click.js"></script>
    <!--动态线条背景-->
    <!--<script type="text/javascript" color="220, 220, 220" opacity="0.6" zIndex="-2" count="100" src="/cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script> -->
    <script src="https://unpkg.com/hls.js@latest"></script>
<header itemscope itemtype="http://schema.org/WPHeader" id="l_header" class="l_header auto shadow show" style="opacity: 0">
  <div class="container">
  <div id="wrapper">
    <div class="nav-sub">
      <p class="title"></p>
      <ul class="switcher nav-list-h m-phone" id="pjax-header-nav-list">
        <li><a id="s-comment" class="fa-solid fa-comments fa-fw" target="_self" href="/" onclick="return false;" title="comment"></a></li>
        
          <li><a id="s-toc" class="s-toc fa-solid fa-list fa-fw" target="_self" href="/" onclick="return false;" title="toc"></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href="/">
          
            <img no-lazy class="logo" src="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/Logo-NavBar@3x.png">
          
          
          
        </a>
      

			<div class="menu navigation">
				<ul class="nav-list-h m-pc">
          
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/" title="博客" active-action="action-home">
                  <i class="fa-solid fa-rss fa-fw"></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/categories/" title="分类" active-action="action-categories">
                  <i class="fa-solid fa-folder-open fa-fw"></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/archives/" title="归档" active-action="action-archives">
                  <i class="fa-solid fa-archive fa-fw"></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/friends/" title="友链" active-action="action-friends">
                  <i class="fa-solid fa-link fa-fw"></i>友链
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/tags/" title="留言箱" active-action="action-tags">
                  <i class="fa-solid fa-tags fa-fw"></i>留言箱
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/about/" title="关于" active-action="action-about">
                  <i class="fa-solid fa-info-circle fa-fw"></i>关于
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/" onclick="return false;" title="更多">
                  <i class="fa-solid fa-ellipsis-v fa-fw"></i>更多
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/volantis-x/hexo-theme-volantis/" title="主题源码" active-action="action-https:githubcomvolantis-xhexo-theme-volantis">
                  主题源码
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/volantis-x/hexo-theme-volantis/releases/" title="更新日志" active-action="action-https:githubcomvolantis-xhexo-theme-volantisreleases">
                  更新日志
                </a>
                
              </li>
            
          
                    
                      
            
              <hr>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/" onclick="return false;" title="有疑问？">
                  有疑问？
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/faqs/" title="看 FAQ" active-action="action-faqs">
                  看 FAQ
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/volantis-x/volantis-docs/" title="看 本站源码" active-action="action-https:githubcomvolantis-xvolantis-docs">
                  看 本站源码
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/volantis-x/hexo-theme-volantis/issues/" title="提 Issue" active-action="action-https:githubcomvolantis-xhexo-theme-volantisissues">
                  提 Issue
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
                    
                      
            
              <hr>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/" onclick="return false;" title="文学黑洞">
                  文学黑洞
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://meiriyiwen.com/random" title="每日一文" active-action="action-https:meiriyiwencomrandom">
                  每日一文
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://www.marxists.org/chinese/index.html" title="马克思主义文库" active-action="action-https:wwwmarxistsorgchineseindexhtml">
                  马克思主义文库
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://www.yikm.net/" title="游戏厅" active-action="action-https:wwwyikmnet">
                  游戏厅
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://www.xiaozhongjishu.com/" title="小众技术工具库" active-action="action-https:wwwxiaozhongjishucom">
                  小众技术工具库
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
          
				</ul>
			</div>
      
      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fa-solid fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search...">
        </form>
      </div>
      

			<ul class="switcher nav-list-h m-phone">
				
					<li><a class="s-search fa-solid fa-search fa-fw" target="_self" href="/" onclick="return false;" title="search"></a></li>
				
				<li>
          <a class="s-menu fa-solid fa-bars fa-fw" target="_self" href="/" onclick="return false;" title="menu"></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/" title="博客" active-action="action-home">
                  <i class="fa-solid fa-rss fa-fw"></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/categories/" title="分类" active-action="action-categories">
                  <i class="fa-solid fa-folder-open fa-fw"></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/archives/" title="归档" active-action="action-archives">
                  <i class="fa-solid fa-archive fa-fw"></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/friends/" title="友链" active-action="action-friends">
                  <i class="fa-solid fa-link fa-fw"></i>友链
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/tags/" title="留言箱" active-action="action-tags">
                  <i class="fa-solid fa-tags fa-fw"></i>留言箱
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/about/" title="关于" active-action="action-about">
                  <i class="fa-solid fa-info-circle fa-fw"></i>关于
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/" onclick="return false;" title="更多">
                  <i class="fa-solid fa-ellipsis-v fa-fw"></i>更多
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/volantis-x/hexo-theme-volantis/" title="主题源码" active-action="action-https:githubcomvolantis-xhexo-theme-volantis">
                  主题源码
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/volantis-x/hexo-theme-volantis/releases/" title="更新日志" active-action="action-https:githubcomvolantis-xhexo-theme-volantisreleases">
                  更新日志
                </a>
                
              </li>
            
          
                    
                      
            
              <hr>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/" onclick="return false;" title="有疑问？">
                  有疑问？
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/faqs/" title="看 FAQ" active-action="action-faqs">
                  看 FAQ
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/volantis-x/volantis-docs/" title="看 本站源码" active-action="action-https:githubcomvolantis-xvolantis-docs">
                  看 本站源码
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/volantis-x/hexo-theme-volantis/issues/" title="提 Issue" active-action="action-https:githubcomvolantis-xhexo-theme-volantisissues">
                  提 Issue
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
                    
                      
            
              <hr>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href="/" onclick="return false;" title="文学黑洞">
                  文学黑洞
                </a>
                
                  <ul class="list-v">
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://meiriyiwen.com/random" title="每日一文" active-action="action-https:meiriyiwencomrandom">
                  每日一文
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://www.marxists.org/chinese/index.html" title="马克思主义文库" active-action="action-https:wwwmarxistsorgchineseindexhtml">
                  马克思主义文库
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://www.yikm.net/" title="游戏厅" active-action="action-https:wwwyikmnet">
                  游戏厅
                </a>
                
              </li>
            
          
                    
                      
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" target="_blank" rel="external nofollow noopener noreferrer" href="https://www.xiaozhongjishu.com/" title="小众技术工具库" active-action="action-https:wwwxiaozhongjishucom">
                  小众技术工具库
                </a>
                
              </li>
            
          
                    
                  </ul>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>

      <!-- Custom Files header begin -->
      
      <!-- Custom Files header end -->
		</div>
	</div>
  </div>
</header>

     <!-- 春节灯笼 -->
        <div class="deng-box2">
          <div class="deng">
            <div class="xian">

            </div>
            <div class="deng-a">
              <div class="deng-b">
                <div class="deng-t">年</div>
              </div>
            </div>
            <div class="shui shui-a">
              <div class="shui-c">

              </div>
              <div class="shui-b"></div>
            </div>
          </div>
        </div>
        <div class="deng-box3">
          <div class="deng">
            <div class="xian">

            </div>
            <div class="deng-a">
              <div class="deng-b">
                <div class="deng-t">新</div>
              </div>
            </div>
            <div class="shui shui-a">
              <div class="shui-c"></div>
              <div class="shui-b">

              </div>
            </div>
          </div>
        </div>
        <div class="deng-box1">
          <div class="deng">
            <div class="xian">

            </div>
            <div class="deng-a">
              <div class="deng-b">
                <div class="deng-t">乐</div>
              </div>
            </div>
            <div class="shui shui-a">
              <div class="shui-c"></div>
              <div class="shui-b"></div>
            </div>
          </div>
        </div>
        <div class="deng-box">
          <div class="deng">
            <div class="xian">

            </div>
            <div class="deng-a">
              <div class="deng-b">
                <div class="deng-t">快</div>
              </div>
            </div>
            <div class="shui shui-a">
              <div class="shui-c">

              </div>
              <div class="shui-b"></div>
            </div>
          </div>
        </div>
        <!-- 春节灯笼 -->
    <div id="l_body">
    <canvas id="fireworks" style="position:fixed; height: 100%; width: 100%;"></canvas>
      <div id="l_cover">
  
    
      <!-- see: /layout/_partial/scripts/_ctrl/coverCtrl.ejs -->
      <div id="none" class="cover-wrapper post dock" style="display: none;">
        
  <div id="parallax-window"></div>

<div class="cover-body">
  <div class="top">
    
    
      <p class="title">相思似海深旧事如天远</p>
    
    
      <p class="subtitle">where there is a will there is a way</p>
    
  </div>
  <div class="bottom">
    <div class="menu navigation">
      <div class="list-h">
        
          
            <a href="/v5/getting-started/" active-action="action-v5getting-started">
              <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/twemoji/assets/svg/1f5c3.svg" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/twemoji/assets/svg/1f5c3.svg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><p>文档</p>
            </a>
          
            <a href="/faqs/" active-action="action-faqs">
              <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/twemoji/assets/svg/1f516.svg" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/twemoji/assets/svg/1f516.svg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><p>帮助</p>
            </a>
          
            <a href="/examples/" active-action="action-examples">
              <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/twemoji/assets/svg/1f396.svg" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/twemoji/assets/svg/1f396.svg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><p>示例</p>
            </a>
          
            <a href="/contributors/" active-action="action-contributors">
              <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/twemoji/assets/svg/1f389.svg" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/twemoji/assets/svg/1f389.svg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><p>社区</p>
            </a>
          
            <a href="/archives/" active-action="action-archives">
              <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/twemoji/assets/svg/1f4f0.svg" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/twemoji/assets/svg/1f4f0.svg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><p>博客</p>
            </a>
          
            <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/volantis-x/hexo-theme-volantis/" active-action="action-https:githubcomvolantis-xhexo-theme-volantis">
              <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/twemoji/assets/svg/1f9ec.svg" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/twemoji/assets/svg/1f9ec.svg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><p>源码</p>
            </a>
          
        
      </div>
    </div>
  </div>
</div>

        <div id="scroll-down" style="display: none;"><i class="fa fa-chevron-down scroll-down-effects"></i></div>
      </div>
    
  
</div>

    <!--Follow me on CSDN-->
    <a target="_blank" rel="external nofollow noopener noreferrer" href="https://blog.csdn.net/qq_38452951"> <img loading="lazy" width="149" height="149" style="position: absolute; top: 0; right: 0; border: 0;" src="https://img-blog.csdnimg.cn/1f8e1ef9be9f4f7db01fe3a2d57829de.png" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/1f8e1ef9be9f4f7db01fe3a2d57829de.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" class="attachment-full size-full lazyload" alt="Fork me on GitHub" data-recalc-dims="1"></a>
      <div id="safearea">
        <div class="body-wrapper">
          
<div id="l_main" class>
  <article itemscope itemtype="http://schema.org/Article" class="article post white-box reveal md shadow article-type-post" id="post" itemprop="blogPost">
  <link itemprop="mainEntityOfPage" href="http://pistachio0812.github.io/zh-TW/ch17_模型部署/第十七章_模型压缩、加速及移动端部署/">
  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="阿月浑子-Hexo博客">
  </span>
  <span hidden itemprop="post" itemscope itemtype="http://schema.org/Post">
    <meta itemprop="name" content="阿月浑子-Hexo博客">
    <meta itemprop="description" content="计算机视觉,文学,pytorch,hexo,江西理工大学,目标检测">
  </span>
  


  
    <span hidden>
      <meta itemprop="image" content="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png">
    </span>
  
  <div class="article-meta" id="top">
    
    
    
      <h1 class="title" itemprop="name headline">
        模型压缩及移动端部署
      </h1>
      <div class="new-meta-box">
        
          
            
<div class="new-meta-item author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <a itemprop="url" class="author" target="_blank" href="https://www.cnblogs.com/pistachio0812" rel="external nofollow noopener noreferrer">
    <img itemprop="image" src="https://img1.baidu.com/it/u=583582599,306470958&fm=253&fmt=auto&app=138&f=JPEG?w=500&h=500" class="lazyload" data-srcset="https://img1.baidu.com/it/u=583582599,306470958&fm=253&fmt=auto&app=138&f=JPEG?w=500&h=500" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
    <p itemprop="name">追风赶月的少年</p>
  </a>
</div>

          
        
          
            
  <div class="new-meta-item category">
    <i class="fa-solid fa-folder-open fa-fw" aria-hidden="true"></i>
    <a class="category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
    
      <span hidden itemprop="about" itemscope itemtype="http://schema.org/Thing">
        <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url"><span itemprop="name">深度学习</span></a>
      </span>
    
  </div>


          
        
          
            <div class="new-meta-item date" itemprop="dateCreated datePublished" datetime="2024-01-24T09:24:21+08:00">
  <a class="notlink">
    <i class="fa-solid fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2024年1月24日</p>
  </a>
</div>

          
        
          
            
  <div class="new-meta-item wordcount">
    <a class="notlink">
      <i class="fa-solid fa-keyboard fa-fw" aria-hidden="true"></i>
      <p>字數：21.5k字</p>
    </a>
  </div>
  <div class="new-meta-item readtime">
    <a class="notlink">
      <i class="fa-solid fa-hourglass-half fa-fw" aria-hidden="true"></i>
      <p>時長：84分鐘</p>
    </a>
  </div>


          
        
        <!-- Custom Files topMeta begin-->
        
        <!-- Custom Files topMeta end-->
      </div>
    
  </div>


  <div id="layoutHelper-page-plugins"></div>
  <div id="post-body" itemprop="articleBody">
    <h1 id="模型压缩及移动端部署"><a href="#模型压缩及移动端部署" class="headerlink" title="模型压缩及移动端部署"></a>模型压缩及移动端部署</h1><p>​    深度神经网络在人工智能的应用中，包括语音识别、计算机视觉、自然语言处理等各方面，在取得巨大成功的同时，这些深度神经网络需要巨大的计算开销和内存开销，严重阻碍了资源受限下的使用。本章总结了模型压缩、加速一般原理和方法，以及在移动端如何部署。</p>
<h2 id="17-1-模型压缩理解"><a href="#17-1-模型压缩理解" class="headerlink" title="17.1 模型压缩理解"></a>17.1 模型压缩理解</h2><p>​    模型压缩是指利用数据集对已经训练好的深度模型进行精简，进而得到一个轻量且准确率相当的网络，压缩后的网络具有更小的结构和更少的参数，可以有效降低计算和存储开销，便于部署再受限的硬件环境中。</p>
<h2 id="17-2-为什么需要模型压缩和加速？"><a href="#17-2-为什么需要模型压缩和加速？" class="headerlink" title="17.2 为什么需要模型压缩和加速？"></a>17.2 为什么需要模型压缩和加速？</h2><p>（1）随着AI技术的飞速发展，越来越多的公司希望在自己的移动端产品中注入AI能力。</p>
<p>（2）对于在线学习和增量学习等实时应用而言，如何减少含有大量层级及结点的大型神经网络所需要的内存和计算量显得极为重要。  </p>
<p>（3）模型的参数在一定程度上能够表达其复杂性,相关研究表明,并不是所有的参数都在模型中发挥作用,部分参数作用有限、表达冗余,甚至会降低模型的性能。</p>
<p>（4）复杂的模型固然具有更好的性能，但是高额的存储空间、计算资源消耗是使其难以有效的应用在各硬件平台上的重要原因。</p>
<p>（5）智能设备的流行提供了内存、CPU、能耗和宽带等资源，使得深度学习模型部署在智能移动设备上变得可行。<br>（6）高效的深度学习方法可以有效的帮助嵌入式设备、分布式系统完成复杂工作，在移动端部署深度学习有很重要的意义。   </p>
<h2 id="17-3-模型压缩的必要性及可行性"><a href="#17-3-模型压缩的必要性及可行性" class="headerlink" title="17.3 模型压缩的必要性及可行性"></a>17.3 模型压缩的必要性及可行性</h2><div class="table-container">
<table>
<thead>
<tr>
<th>必要性</th>
<th>首先是资源受限，其次在许多网络结构中，如VGG-16网络，参数数量1亿3千多万，占用500MB空间，需要进行309亿次浮点运算才能完成一次图像识别任务。</th>
</tr>
</thead>
<tbody>
<tr>
<td>可行性</td>
<td>模型的参数在一定程度上能够表达其复杂性,相关研究表明,并不是所有的参数都在模型中发挥作用,部分参数作用有限、表达冗余,甚至会降低模型的性能。论文<predicting parameters in deep learning>提出，很多的深度神经网络仅仅使用很少一部分（5%）权值就足以预测剩余的权值。该论文还提出这些剩下的权值甚至可以直接不用被学习。也就是说，仅仅训练一小部分原来的权值参数就有可能达到和原来网络相近甚至超过原来网络的性能（可以看作一种正则化）。</predicting></td>
</tr>
<tr>
<td>最终目的</td>
<td>最大程度的减小模型复杂度，减少模型存储需要的空间，也致力于加速模型的训练和推测</td>
</tr>
</tbody>
</table>
</div>
<h2 id="17-4-目前有哪些深度学习模型压缩方法？"><a href="#17-4-目前有哪些深度学习模型压缩方法？" class="headerlink" title="17.4 目前有哪些深度学习模型压缩方法？"></a>17.4 目前有哪些深度学习模型压缩方法？</h2><p>​    目前深度学习模型压缩方法主要分为更精细化模型设计、模型裁剪、核的稀疏化、量化、低秩分解、迁移学习等方法，而这些方法又可分为前端压缩和后端压缩。</p>
<h3 id="17-4-1-前端压缩和后端压缩对比"><a href="#17-4-1-前端压缩和后端压缩对比" class="headerlink" title="17.4.1 前端压缩和后端压缩对比"></a>17.4.1 前端压缩和后端压缩对比</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">对比项目</th>
<th style="text-align:center">前端压缩</th>
<th style="text-align:center">后端压缩</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">含义</td>
<td style="text-align:center">不会改变原始网络结构的压缩技术</td>
<td style="text-align:center">会大程度上改变原始网络结构的压缩技术</td>
</tr>
<tr>
<td style="text-align:center">主要方法</td>
<td style="text-align:center">知识蒸馏、紧凑的模型结构设计、滤波器层面的剪枝</td>
<td style="text-align:center">低秩近似、未加限制的剪枝、参数量化、二值网络</td>
</tr>
<tr>
<td style="text-align:center">实现难度</td>
<td style="text-align:center">较简单</td>
<td style="text-align:center">较难</td>
</tr>
<tr>
<td style="text-align:center">是否可逆</td>
<td style="text-align:center">可逆</td>
<td style="text-align:center">不可逆</td>
</tr>
<tr>
<td style="text-align:center">成熟应用</td>
<td style="text-align:center">剪枝</td>
<td style="text-align:center">低秩近似、参数量化</td>
</tr>
<tr>
<td style="text-align:center">待发展应用</td>
<td style="text-align:center">知识蒸馏</td>
<td style="text-align:center">二值网络</td>
</tr>
</tbody>
</table>
</div>
<h3 id="17-4-2-网络剪枝"><a href="#17-4-2-网络剪枝" class="headerlink" title="17.4.2 网络剪枝"></a>17.4.2 网络剪枝</h3><p>深度学习模型因其<strong>稀疏性</strong>，可以被裁剪为结构精简的网络模型，具体包括结构性剪枝与非结构性剪枝。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>事项</th>
<th>特点</th>
<th>举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>非结构化剪枝</td>
<td>通常是连接级、细粒度的剪枝方法，精度相对较高，但依赖于特定算法库或硬件平台的支持</td>
<td>Deep Compression [5], Sparse-Winograd [6] 算法等；</td>
</tr>
<tr>
<td>结构化剪枝</td>
<td>是filter级或layer级、粗粒度的剪枝方法，精度相对较低，但剪枝策略更为有效，不需要特定算法库或硬件平台的支持，能够直接在成熟深度学习框架上运行。</td>
<td>如局部方式的、通过layer by layer方式的、最小化输出FM重建误差的Channel Pruning [7], ThiNet [8], Discrimination-aware Channel Pruning [9]；全局方式的、通过训练期间对BN层Gamma系数施加L1正则约束的Network Slimming [10]；全局方式的、按Taylor准则对Filter作重要性排序的Neuron Pruning [11]；全局方式的、可动态重新更新pruned filters参数的剪枝方法 [12];<br><a target="_blank" rel="external nofollow noopener noreferrer" href="https://blog.csdn.net/baidu_31437863/article/details/84474847">https://blog.csdn.net/baidu_31437863/article/details/84474847</a></td>
</tr>
</tbody>
</table>
</div>
<p>如果按剪枝粒度分，从粗到细，可分为中间隐含层剪枝、通道剪枝、卷积核剪枝、核内剪枝、单个权重剪枝。下面按照剪枝粒度的分类从粗（左）到细（右）。</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/剪枝粒度分类.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/剪枝粒度分类.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p>（a）层间剪枝   （b）特征图剪枝    （c）k*k核剪枝   （d）核内剪枝</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>事项</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>单个权重粒度</td>
<td>早期 Le Cun[16]提出的 OBD(optimal brain damage)将网络中的任意权重参数都看作单个参数,能够有效地提高预测准确率,却不能减小运行时间;同时,剪枝代价过高,只适用于小网络</td>
</tr>
<tr>
<td>核内权重粒度</td>
<td>网络中的任意权重被看作是单个参数并进行随机非结构化剪枝,该粒度的剪枝导致网络连接不规整,需要通过稀疏表达来减少内存占用,进而导致在前向传播预测时,需要大量的条件判断和额外空间来标明零或非零参数的位置,因此不适用于并行计算</td>
</tr>
<tr>
<td>卷积核粒度与通道粒度</td>
<td>卷积核粒度与通道粒度属于粗粒度剪枝,不依赖任何稀疏卷积计算库及专用硬件;同时,能够在获得高压缩率的同时大量减小测试阶段的计算时间.由</td>
</tr>
</tbody>
</table>
</div>
<p>从剪枝目标上分类，可分为减少参数/网络复杂度、减少过拟合/增加泛化能力/提高准确率、减小部署运行时间/提高网络效率及减小训练时间等。</p>
<h3 id="17-4-3-典型剪枝方法对比"><a href="#17-4-3-典型剪枝方法对比" class="headerlink" title="17.4.3 典型剪枝方法对比"></a>17.4.3 典型剪枝方法对比</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">剪枝方法</th>
<th style="text-align:center">修剪对象</th>
<th style="text-align:center">修剪方式</th>
<th style="text-align:center">效果</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Deep Compression</td>
<td style="text-align:center">权重</td>
<td style="text-align:center">随机修剪</td>
<td style="text-align:center">50倍压缩</td>
</tr>
<tr>
<td style="text-align:center">Structured Pruning</td>
<td style="text-align:center">权重</td>
<td style="text-align:center">组稀疏+排他性稀疏</td>
<td style="text-align:center">性能提升</td>
</tr>
<tr>
<td style="text-align:center">Network Slimming</td>
<td style="text-align:center">特征图通道</td>
<td style="text-align:center">根据尺度因子修剪</td>
<td style="text-align:center">节省计算资源</td>
</tr>
<tr>
<td style="text-align:center">mProp</td>
<td style="text-align:center">梯度</td>
<td style="text-align:center">修剪幅值小的梯度</td>
<td style="text-align:center">加速</td>
</tr>
</tbody>
</table>
</div>
<h3 id="17-4-4-网络蒸馏"><a href="#17-4-4-网络蒸馏" class="headerlink" title="17.4.4 网络蒸馏"></a>17.4.4 网络蒸馏</h3><p>​    网络精馏是指利用大量未标记的迁移数据(transfer data),让小模型去拟合大模型,从而让小模型学到与大模型相似的函数映射.网络精馏可以看成在同一个域上迁移学习[34]的一种特例,目的是获得一个比原模型更为精简的网络,整体的框架图如图 4所示. </p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/网络蒸馏.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/网络蒸馏.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<h3 id="17-4-5-前端压缩"><a href="#17-4-5-前端压缩" class="headerlink" title="17.4.5 前端压缩"></a>17.4.5 前端压缩</h3><p>（1）知识蒸馏</p>
<p>​    一个复杂模型可由多个简单模型或者强约束条件训练得到。复杂模型特点是性能好，但其参数量大，计算效率低。小模型特点是计算效率高，但是其性能较差。知识蒸馏是让复杂模型学习到的知识迁移到小模型当中,使其保持其快速的计算速度前提下，同时拥有复杂模型的性能，达到模型压缩的目的。<br>（2）紧凑的模型结构设计<br>​    紧凑的模型结构设计主要是对神经网络卷积的方式进行改进，比如使用两个3x3的卷积替换一个5x5的卷积、使用深度可分离卷积等等方式降低计算参数量。  目前很多网络基于模块化设计思想，在深度和宽度两个维度上都很大，导致参数冗余。因此有很多关于模型设计的研究，如SqueezeNet、MobileNet等，使用更加细致、高效的模型设计，能够很大程度的减少模型尺寸，并且也具有不错的性能。<br>（3）滤波器层面的剪枝<br>​    滤波器层面的剪枝属于非结构花剪枝，主要是对较小的权重矩阵整个剔除，然后对整个神经网络进行微调。此方式由于剪枝过于粗放，容易导致精度损失较大，而且部分权重矩阵中会存留一些较小的权重造成冗余，剪枝不彻底。  具体操作是在训练时使用稀疏约束（加入权重的稀疏正则项，引导模型的大部分权重趋向于0）。完成训练后，剪去滤波器上的这些 0 。</p>
<p>​    优点是简单，缺点是剪得不干净，非结构化剪枝会增加内存访问成本。</p>
<h3 id="17-4-6-后端压缩"><a href="#17-4-6-后端压缩" class="headerlink" title="17.4.6 后端压缩"></a>17.4.6 后端压缩</h3><p>（1）低秩近似<br>​    在卷积神经网络中，卷积运算都是以矩阵相乘的方式进行。对于复杂网络，权重矩阵往往非常大，非常消耗存储和计算资源。低秩近似就是用若干个低秩矩阵组合重构大的权重矩阵，以此降低存储和计算资源消耗。  </p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">事项</th>
<th style="text-align:left">特点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">优点</td>
<td style="text-align:left">可以降低存储和计算消耗；<br>一般可以压缩2-3倍；精度几乎没有损失；</td>
</tr>
<tr>
<td style="text-align:left">缺点</td>
<td style="text-align:left">模型越复杂，权重矩阵越大，利用低秩近似重构参数矩阵不能保证模型的性能 ；   <br>超参数的数量随着网络层数的增加呈线性变化趋势，例如中间层的特征通道数等等。 <br>随着模型复杂度的提升，搜索空间急剧增大。</td>
</tr>
</tbody>
</table>
</div>
<p>（2）未加限制的剪枝    </p>
<p>​    完成训练后，不加限制地剪去那些冗余参数。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>事项</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>优点</td>
<td>保持模型性能不损失的情况下，减少参数量9-11倍； <br>剔除不重要的权重，可以加快计算速度，同时也可以提高模型的泛化能力；</td>
</tr>
<tr>
<td>缺点</td>
<td>极度依赖专门的运行库和特殊的运行平台，不具有通用性；<br> 压缩率过大时，破坏性能；</td>
</tr>
</tbody>
</table>
</div>
<p>（3）参数量化    </p>
<p>​    神经网络的参数类型一般是32位浮点型，使用较小的精度代替32位所表示的精度。或者是将多个权重映射到同一数值，权重共享。<strong>量化其实是一种权值共享的策略</strong>。量化后的权值张量是一个高度稀疏的有很多共享权值的矩阵，对非零参数，我们还可以进行定点压缩，以获得更高的压缩率。 </p>
<div class="table-container">
<table>
<thead>
<tr>
<th>事项</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>优点</td>
<td>模型性能损失很小，大小减少8-16倍；</td>
</tr>
<tr>
<td>缺点</td>
<td>压缩率大时，性能显著下降； <br>依赖专门的运行库，通用性较差；</td>
</tr>
<tr>
<td>举例</td>
<td>二值化网络：XNORnet [13], ABCnet with Multiple Binary Bases [14], <br>Bin-net with High-Order Residual Quantization [15], Bi-Real Net [16]；<br>三值化网络：Ternary weight networks [17], Trained Ternary Quantization [18]；</td>
</tr>
</tbody>
</table>
</div>
<p>W1-A8 或 W2-A8量化： Learning Symmetric Quantization [19]；<br>INT8量化：TensorFlow-lite [20], TensorRT [21]；<br>其他（非线性）：Intel INQ [22], log-net, CNNPack [23] 等；<br>原文：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://blog.csdn.net/baidu_31437863/article/details/84474847">https://blog.csdn.net/baidu_31437863/article/details/84474847</a> |<br>| 总结 | 最为典型就是二值网络、XNOR网络等。其主要原理就是采用1bit对网络的输入、权重、响应进行编码。减少模型大小的同时，原始网络的卷积操作可以被bit-wise运算代替，极大提升了模型的速度。但是，如果原始网络结果不够复杂（模型描述能力），由于二值网络会较大程度降低模型的表达能力。因此现阶段有相关的论文开始研究n-bit编码方式成为n值网络或者多值网络或者变bit、组合bit量化来克服二值网络表达能力不足的缺点。 |</p>
<p>（4）二值网络</p>
<p>​    相对量化更为极致，对于32bit浮点型数用1bit二进制数-1或者1表示，可大大减小模型尺寸。  </p>
<div class="table-container">
<table>
<thead>
<tr>
<th>事项</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>优点</td>
<td>网络体积小，运算速度快，有时可避免部分网络的overfitting</td>
</tr>
<tr>
<td>缺点</td>
<td>二值神经网络损失的信息相对于浮点精度是非常大；<br>粗糙的二值化近似导致训练时模型收敛速度非常慢</td>
</tr>
</tbody>
</table>
</div>
<p>（5）三值网络</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>事项</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>优点</td>
<td>相对于二值神经网络，三值神经网络(Ternary Weight Networks)在同样的模型结构下可以达到成百上千倍的表达能力提升;并且，在计算时间复杂度上，三元网络和二元网络的计算复杂度是一样的。<br>例如，对于ResNet-18层网络中最常出现的卷积核(3x3大小)，二值神经网络模型最多可以表达2的3x3次方(=512)种结构，而三元神经网络则可以表达3的3x3次方(=19683)种卷积核结构。在表达能力上，三元神经网络相对要高19683/512 = 38倍。因此，三元神经网络模型能够在保证计算复杂度很低的情况下大幅的提高网络的表达能力，进而可以在精度上相对于二值神经网络有质的飞跃。另外，由于对中间信息的保存更多，三元神经网络可以极大的加快网络训练时的收敛速度，从而更快、更稳定的达到最优的结果。</td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
</div>
<h3 id="17-4-6-低秩分解"><a href="#17-4-6-低秩分解" class="headerlink" title="17.4.6 低秩分解"></a>17.4.6 低秩分解</h3><p>基于低秩分解的深度神经网络压缩与加速的核心思想是利用矩阵或张量分解技术估计并分解深度模型中的原始卷积核．卷积计算是整个卷积神经网络中计算复杂 度 最 高 的 计 算 操 作，通 过 分 解４Ｄ 卷积核张量，可以有效地减少模型内部的冗余性．此外对于２Ｄ的全 连 接 层 矩 阵 参 数，同样可以利用低秩分解技术进行处理．但由于卷积层与全连接层的分解方式不同，本文分别从卷积层和全连接层２个不同角度回顾与分析低秩分解技术在深度神经网络中的应用.</p>
<p>在２０１３年，Ｄｅｎｉｌ等人［５７］从理论上利用低秩分解的技术并分析了深度神经网络存在大量的冗余信<br>息，开创了基于低秩分解的深度网络模型压缩与加速的新思路．如图７所示，展示了主流的张量分解后卷积 计 算．</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/img\ch17\低秩分解模型压缩加速.jpg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/img\ch17\低秩分解模型压缩加速.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p>(出自《深度神经网络压缩与加速综述》)</p>
<h3 id="17-4-7-总体压缩效果评价指标有哪些？"><a href="#17-4-7-总体压缩效果评价指标有哪些？" class="headerlink" title="17.4.7 总体压缩效果评价指标有哪些？"></a>17.4.7 总体压缩效果评价指标有哪些？</h3><p>​    网络压缩评价指标包括运行效率、参数压缩率、准确率.与基准模型比较衡量性能提升时,可以使用提升倍数(speedup)或提升比例(ratio)。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>评价指标</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>准确率</td>
<td>目前,大部分研究工作均会测量 Top-1 准确率,只有在 ImageNet 这类大型数据集上才会只用 Top-5 准确率.为方便比较</td>
</tr>
<tr>
<td>参数压缩率</td>
<td>统计网络中所有可训练的参数,根据机器浮点精度转换为字节(byte)量纲,通常保留两位有效数字以作近似估计.</td>
</tr>
<tr>
<td>运行效率</td>
<td>可以从网络所含浮点运算次数(FLOP)、网络所含乘法运算次数(MULTS)或随机实验测得的网络平均前向传播所需时间这 3 个角度来评价</td>
</tr>
</tbody>
</table>
</div>
<h3 id="17-4-8-几种轻量化网络结构对比"><a href="#17-4-8-几种轻量化网络结构对比" class="headerlink" title="17.4.8 几种轻量化网络结构对比"></a>17.4.8 几种轻量化网络结构对比</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">网络结构</th>
<th style="text-align:center">TOP1 准确率/%</th>
<th style="text-align:center">参数量/M</th>
<th style="text-align:center">CPU运行时间/ms</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">MobileNet V1</td>
<td style="text-align:center">70.6</td>
<td style="text-align:center">4.2</td>
<td style="text-align:center">123</td>
</tr>
<tr>
<td style="text-align:center">ShuffleNet(1.5)</td>
<td style="text-align:center">69.0</td>
<td style="text-align:center">2.9</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">ShuffleNet(x2)</td>
<td style="text-align:center">70.9</td>
<td style="text-align:center">4.4</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">MobileNet V2</td>
<td style="text-align:center">71.7</td>
<td style="text-align:center">3.4</td>
<td style="text-align:center">80</td>
</tr>
<tr>
<td style="text-align:center">MobileNet V2(1.4)</td>
<td style="text-align:center">74.7</td>
<td style="text-align:center">6.9</td>
<td style="text-align:center">149</td>
</tr>
</tbody>
</table>
</div>
<h3 id="17-4-9-网络压缩未来研究方向有哪些？"><a href="#17-4-9-网络压缩未来研究方向有哪些？" class="headerlink" title="17.4.9 网络压缩未来研究方向有哪些？"></a>17.4.9 网络压缩未来研究方向有哪些？</h3><p>网络剪枝、网络精馏和网络分解都能在一定程度上实现网络压缩的目的.回归到深度网络压缩的本质目的上,即提取网络中的有用信息,以下是一些值得研究和探寻的方向.<br>(1) 权重参数对结果的影响度量.深度网络的最终结果是由全部的权重参数共同作用形成的,目前,关于单个卷积核/卷积核权重的重要性的度量仍然是比较简单的方式,尽管文献[14]中给出了更为细节的分析,但是由于计算难度大,并不实用.因此,如何通过更有效的方式来近似度量单个参数对模型的影响,具有重要意义.<br>(2) 学生网络结构的构造.学生网络的结构构造目前仍然是由人工指定的,然而,不同的学生网络结构的训练难度不同,最终能够达到的效果也有差异.因此,如何根据教师网络结构设计合理的网络结构在精简模型的条件下获取较高的模型性能,是未来的一个研究重点.<br>(3) 参数重建的硬件架构支持.通过分解网络可以无损地获取压缩模型,在一些对性能要求高的场景中是非常重要的.然而,参数的重建步骤会拖累预测阶段的时间开销,如何通过硬件的支持加速这一重建过程,将是未来的一个研究方向.<br>(4) 任务或使用场景层面的压缩.大型网络通常是在量级较大的数据集上训练完成的,比如,在 ImageNet上训练的模型具备对 1 000 类物体的分类,但在一些具体场景的应用中,可能仅需要一个能识别其中几类的小型模型.因此,如何从一个全功能的网络压缩得到部分功能的子网络,能够适应很多实际应用场景的需求.<br>(5) 网络压缩效用的评价.目前,对各类深度网络压缩算法的评价是比较零碎的,侧重于和被压缩的大型网络在参数量和运行时间上的比较.未来的研究可以从提出更加泛化的压缩评价标准出发,一方面平衡运行速度和模型大小在不同应用场景下的影响;另一方面,可以从模型本身的结构性出发,对压缩后的模型进行评价. </p>
<p>（出自《深度网络模型压缩综述》）</p>
<h2 id="17-5-目前有哪些深度学习模型优化加速方法？"><a href="#17-5-目前有哪些深度学习模型优化加速方法？" class="headerlink" title="17.5 目前有哪些深度学习模型优化加速方法？"></a>17.5 目前有哪些深度学习模型优化加速方法？</h2><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://blog.csdn.net/nature553863/article/details/81083955">https://blog.csdn.net/nature553863/article/details/81083955</a></p>
<h3 id="17-5-1-模型优化加速方法"><a href="#17-5-1-模型优化加速方法" class="headerlink" title="17.5.1 模型优化加速方法"></a>17.5.1 模型优化加速方法</h3><p>模型优化加速能够提升网络的计算效率，具体包括：<br>（1）Op-level的快速算法：FFT Conv2d (7x7, 9x9), Winograd Conv2d (3x3, 5x5) 等；<br>（2）Layer-level的快速算法：Sparse-block net [1] 等；<br>（3）优化工具与库：TensorRT (Nvidia), Tensor Comprehension (Facebook) 和 Distiller (Intel) 等；   </p>
<p>原文：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://blog.csdn.net/nature553863/article/details/81083955">https://blog.csdn.net/nature553863/article/details/81083955</a>   </p>
<h3 id="17-5-2-TensorRT加速原理"><a href="#17-5-2-TensorRT加速原理" class="headerlink" title="17.5.2 TensorRT加速原理"></a>17.5.2 TensorRT加速原理</h3><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://blog.csdn.net/xh_hit/article/details/79769599">https://blog.csdn.net/xh_hit/article/details/79769599</a></p>
<p>​    在计算资源并不丰富的嵌入式设备上，TensorRT之所以能加速神经网络的的推断主要得益于两点：</p>
<ul>
<li><p>首先是TensorRT支持int8和fp16的计算，通过在减少计算量和保持精度之间达到一个理想的trade-off，达到加速推断的目的。</p>
</li>
<li><p>更为重要的是TensorRT对于网络结构进行了重构和优化，主要体现在一下几个方面。</p>
<p>(1) TensorRT通过解析网络模型将网络中无用的输出层消除以减小计算。</p>
<p>(2) 对于网络结构的垂直整合，即将目前主流神经网络的Conv、BN、Relu三个层融合为了一个层，例如将图1所示的常见的Inception结构重构为图2所示的网络结构。</p>
<p>(3) 对于网络结构的水平组合，水平组合是指将输入为相同张量和执行相同操作的层融合一起，例如图2向图3的转化。</p>
</li>
</ul>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/tensorRT1.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/tensorRT1.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/tensorRT2.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/tensorRT2.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/tensorRT3.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/tensorRT3.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p>​    以上3步即是TensorRT对于所部署的深度学习网络的优化和重构，根据其优化和重构策略，第一和第二步适用于所有的网络架构，但是第三步则对于含有Inception结构的神经网络加速效果最为明显。</p>
<p>​    Tips: 想更好地利用TensorRT加速网络推断，可在基础网络中多采用Inception模型结构，充分发挥TensorRT的优势。</p>
<h3 id="17-5-3-TensorRT如何优化重构模型？"><a href="#17-5-3-TensorRT如何优化重构模型？" class="headerlink" title="17.5.3 TensorRT如何优化重构模型？"></a>17.5.3 TensorRT如何优化重构模型？</h3><div class="table-container">
<table>
<thead>
<tr>
<th>条件</th>
<th>方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>若训练的网络模型包含TensorRT支持的操作</td>
<td>1、对于Caffe与TensorFlow训练的模型，若包含的操作都是TensorRT支持的，则可以直接由TensorRT优化重构</td>
</tr>
<tr>
<td></td>
<td>2、对于MXnet, PyTorch或其他框架训练的模型，若包含的操作都是TensorRT支持的，可以采用TensorRT API重建网络结构，并间接优化重构；</td>
</tr>
<tr>
<td>若训练的网络模型包含TensorRT不支持的操作</td>
<td>1、TensorFlow模型可通过tf.contrib.tensorrt转换，其中不支持的操作会保留为TensorFlow计算节点；</td>
</tr>
<tr>
<td></td>
<td>2、不支持的操作可通过Plugin API实现自定义并添加进TensorRT计算图；</td>
</tr>
<tr>
<td></td>
<td>3、将深度网络划分为两个部分，一部分包含的操作都是TensorRT支持的，可以转换为TensorRT计算图。另一部则采用其他框架实现，如MXnet或PyTorch；</td>
</tr>
</tbody>
</table>
</div>
<h3 id="17-5-4-TensorRT加速效果如何？"><a href="#17-5-4-TensorRT加速效果如何？" class="headerlink" title="17.5.4 TensorRT加速效果如何？"></a>17.5.4 TensorRT加速效果如何？</h3><p>以下是在TitanX (Pascal)平台上，TensorRT对大型分类网络的优化加速效果：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Network</th>
<th style="text-align:center">Precision</th>
<th style="text-align:center">Framework/GPU:TitanXP</th>
<th style="text-align:center">Avg.Time(Batch=8,unit:ms)</th>
<th style="text-align:center">Top1 Val.Acc.(ImageNet-1k)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Resnet50</td>
<td style="text-align:center">fp32</td>
<td style="text-align:center">TensorFlow</td>
<td style="text-align:center">24.1</td>
<td style="text-align:center">0.7374</td>
</tr>
<tr>
<td style="text-align:center">Resnet50</td>
<td style="text-align:center">fp32</td>
<td style="text-align:center">MXnet</td>
<td style="text-align:center">15.7</td>
<td style="text-align:center">0.7374</td>
</tr>
<tr>
<td style="text-align:center">Resnet50</td>
<td style="text-align:center">fp32</td>
<td style="text-align:center">TRT4.0.1</td>
<td style="text-align:center">12.1</td>
<td style="text-align:center">0.7374</td>
</tr>
<tr>
<td style="text-align:center">Resnet50</td>
<td style="text-align:center">int8</td>
<td style="text-align:center">TRT4.0.1</td>
<td style="text-align:center">6</td>
<td style="text-align:center">0.7226</td>
</tr>
<tr>
<td style="text-align:center">Resnet101</td>
<td style="text-align:center">fp32</td>
<td style="text-align:center">TensorFlow</td>
<td style="text-align:center">36.7</td>
<td style="text-align:center">0.7612</td>
</tr>
<tr>
<td style="text-align:center">Resnet101</td>
<td style="text-align:center">fp32</td>
<td style="text-align:center">MXnet</td>
<td style="text-align:center">25.8</td>
<td style="text-align:center">0.7612</td>
</tr>
<tr>
<td style="text-align:center">Resnet101</td>
<td style="text-align:center">fp32</td>
<td style="text-align:center">TRT4.0.1</td>
<td style="text-align:center">19.3</td>
<td style="text-align:center">0.7612</td>
</tr>
<tr>
<td style="text-align:center">Resnet101</td>
<td style="text-align:center">int8</td>
<td style="text-align:center">TRT4.0.1</td>
<td style="text-align:center">9</td>
<td style="text-align:center">0.7574</td>
</tr>
</tbody>
</table>
</div>
<h2 id="17-6-影响神经网络速度的4个因素（再稍微详细一点）"><a href="#17-6-影响神经网络速度的4个因素（再稍微详细一点）" class="headerlink" title="17.6 影响神经网络速度的4个因素（再稍微详细一点）"></a>17.6 影响神经网络速度的4个因素（再稍微详细一点）</h2><ol>
<li><p>FLOPs(FLOPs就是网络执行了多少multiply-adds操作)；  </p>
</li>
<li><p>MAC(内存访问成本)；   </p>
</li>
<li><p>并行度(如果网络并行度高，速度明显提升)；   </p>
</li>
<li><p>计算平台(GPU，ARM)   </p>
</li>
</ol>
<h2 id="17-7-压缩和加速方法如何选择？"><a href="#17-7-压缩和加速方法如何选择？" class="headerlink" title="17.7 压缩和加速方法如何选择？"></a>17.7 压缩和加速方法如何选择？</h2><p>​    １）对于在线计算内存存储有限的应用场景或设备，可以选择参数共享和参数剪枝方法，特别是二值量化权值和激活、结构化剪枝．其他方法虽然能够有效的压缩模型中的权值参数，但无法减小计算中隐藏的内存大小（如特征图）．<br>​    ２）如果在应用中用到的紧性模型需要利用预训练模型，那么参数剪枝、参数共享以及低秩分解将成为首要考虑的方法．相反地，若不需要借助预训练模型，则可以考虑紧性滤波设计及知识蒸馏方法．<br>​    ３）若需要一次性端对端训练得到压缩与加速后模型，可以利用基于紧性滤波设计的深度神经网络压缩与加速方法．<br>​    ４）一般情况下，参数剪枝，特别是非结构化剪枝，能大大压缩模型大小，且不容易丢失分类精度．对于需要稳定的模型分类的应用，非结构化剪枝成为首要选择．<br>​    ５）若采用的数据集较小时，可以考虑知识蒸馏方法．对于小样本的数据集，学生网络能够很好地迁移教师模型的知识，提高学生网络的判别性．<br>​    ６）主流的５个深度神经网络压缩与加速算法相互之间是正交的，可以结合不同技术进行进一步的压缩与加速．如：韩 松 等 人［３０］结合了参数剪枝和参数共享；温伟等人［６４］以及 Ａｌｖａｒｅｚ等人［８５］结合了参数剪枝和低秩分解．此外对于特定的应用场景，如目标检测，可以对卷积层和全连接层使用不同的压缩与加速技术分别处理．</p>
<p>参考《深度神经网络压缩与加速综述》</p>
<h2 id="17-8-改变网络结构设计为什么会实现模型压缩、加速？"><a href="#17-8-改变网络结构设计为什么会实现模型压缩、加速？" class="headerlink" title="17.8 改变网络结构设计为什么会实现模型压缩、加速？"></a>17.8 改变网络结构设计为什么会实现模型压缩、加速？</h2><h3 id="17-8-1-Group-convolution"><a href="#17-8-1-Group-convolution" class="headerlink" title="17.8.1 Group convolution"></a>17.8.1 Group convolution</h3><p>​    Group convolution最早出现在AlexNet中，是为了解决单卡显存不够，将网络部署到多卡上进行训练而提出。Group convolution可以减少单个卷积1/g的参数量。如何计算的呢？  </p>
<p>​    假设</p>
<ul>
<li>输入特征的的维度为$H<em>W</em>C_1$;</li>
<li>卷积核的维度为$H_1<em>W_1</em>C_1$，共$C_2$个；</li>
<li>输出特征的维度为$H_1<em>W_1</em>C_2$ 。  </li>
</ul>
<p>传统卷积计算方式如下：<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/1.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/1.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>传统卷积运算量为：  </p>
<script type="math/tex; mode=display">
A = H*W * h1 * w1 * c1 * c2</script><p>Group convolution是将输入特征的维度c1分成g份，每个group对应的channel数为c1/g，特征维度H * W * c1/g；，每个group对应的卷积核的维度也相应发生改变为h1 * w1 * c1/9，共c2/g个；每个group相互独立运算，最后将结果叠加在一起。<br>Group convolution计算方式如下：<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/2.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/2.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>Group convolution运算量为：  </p>
<script type="math/tex; mode=display">
B = H * W * h1 * w1 * c1/g * c2/g * g</script><p>Group卷积相对于传统卷积的运算量：  </p>
<script type="math/tex; mode=display">
\dfrac{B}{A} = \dfrac{ H * W * h1 * w1 * c1/g * c2/g * g}{H * W * h1 * w1 * c1 * c2} = \dfrac{1}{g}</script><p>由此可知：group卷积相对于传统卷积减少了1/g的参数量。</p>
<h3 id="17-8-2-Depthwise-separable-convolution"><a href="#17-8-2-Depthwise-separable-convolution" class="headerlink" title="17.8.2. Depthwise separable convolution"></a>17.8.2. Depthwise separable convolution</h3><p>Depthwise separable convolution是由depthwise conv和pointwise conv构成。<br>depthwise conv(DW)有效减少参数数量并提升运算速度。但是由于每个feature map只被一个卷积核卷积，因此经过DW输出的feature map不能只包含输入特征图的全部信息，而且特征之间的信息不能进行交流，导致“信息流通不畅”。<br>pointwise conv(PW)实现通道特征信息交流，解决DW卷积导致“信息流通不畅”的问题。<br>假设输入特征的的维度为H * W * c1；卷积核的维度为h1 * w1 * c1，共c2个；输出特征的维度为 H1 * W1 * c2。<br>传统卷积计算方式如下：<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/3.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/3.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>传统卷积运算量为：  </p>
<script type="math/tex; mode=display">
A = H * W * h1 * w1 * c1 * c2</script><p>DW卷积的计算方式如下：<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/4.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/4.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>DW卷积运算量为： </p>
<script type="math/tex; mode=display">
B_DW = H * W * h1 * w1 * 1 * c1</script><p>PW卷积的计算方式如下：<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/5.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/5.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"></p>
<script type="math/tex; mode=display">
B_PW = H_m * W_m * 1 * 1 * c_1 * c_2</script><p>Depthwise separable convolution运算量为：</p>
<script type="math/tex; mode=display">
B = B_DW + B_PW</script><p>Depthwise separable convolution相对于传统卷积的运算量：</p>
<script type="math/tex; mode=display">
\dfrac{B}{A} = \dfrac{ H * W * h_1 * w_1 * 1 * c_1 + H_m * W_m * 1 * 1 * c_1 * c_2}{H * W * h1 * w1 * c_1 * c_2}  

= \dfrac{1}{c_2} + \dfrac{1}{h_1 * w_1}</script><p>由此可知，随着卷积通道数的增加，Depthwise separable convolution的运算量相对于传统卷积更少。</p>
<h3 id="17-8-3-输入输出的channel相同时，MAC最小"><a href="#17-8-3-输入输出的channel相同时，MAC最小" class="headerlink" title="17.8.3 输入输出的channel相同时，MAC最小"></a>17.8.3 输入输出的channel相同时，MAC最小</h3><p><strong>卷积层的输入和输出特征通道数相等时MAC最小，此时模型速度最快。</strong><br>假设feature map的大小为h*w，输入通道$c_1$，输出通道$c_2$。<br>已知：</p>
<script type="math/tex; mode=display">
FLOPs = B = h * w * c1 * c2   
=> c1 * c2 = \dfrac{B}{h * w}</script><script type="math/tex; mode=display">
MAC = h * w * (c1 + c2) + c1 * c2</script><script type="math/tex; mode=display">
=> MAC \geq 2 * h * w \sqrt{\dfrac{B}{h * w}} + \dfrac{B}{h * w}</script><p>根据均值不等式得到(c1-c2)^2&gt;=0，等式成立的条件是c1=c2，也就是输入特征通道数和输出特征通道数相等时，在给定FLOPs前提下，MAC达到取值的下界。</p>
<h3 id="17-8-4-减少组卷积的数量"><a href="#17-8-4-减少组卷积的数量" class="headerlink" title="17.8.4 减少组卷积的数量"></a>17.8.4 减少组卷积的数量</h3><p><strong>过多的group操作会增大MAC，从而使模型速度变慢</strong><br>由以上公式可知，group卷积想比与传统的卷积可以降低计算量，提高模型的效率；如果在相同的FLOPs时，group卷积为了满足FLOPs会是使用更多channels，可以提高模型的精度。但是随着channel数量的增加，也会增加MAC。<br>FLOPs：</p>
<script type="math/tex; mode=display">
B = \dfrac{h * w * c1 * c2}{g}</script><p>MAC：</p>
<script type="math/tex; mode=display">
MAC = h * w * (c1 + c2) + \dfrac{c1 * c2}{g}</script><p>由MAC，FLOPs可知：</p>
<script type="math/tex; mode=display">
MAC = h * w * c1 + \dfrac{B*g}{c1} + \dfrac{B}{h * w}</script><p>当FLOPs固定(B不变)时，g越大，MAC越大。</p>
<h3 id="17-8-5-减少网络碎片化程度-分支数量"><a href="#17-8-5-减少网络碎片化程度-分支数量" class="headerlink" title="17.8.5 减少网络碎片化程度(分支数量)"></a>17.8.5 减少网络碎片化程度(分支数量)</h3><p><strong>模型中分支数量越少，模型速度越快</strong><br>此结论主要是由实验结果所得。<br>以下为网络分支数和各分支包含的卷积数目对神经网络速度的影响。<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/6.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/6.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>实验中使用的基本网络结构，分别将它们重复10次，然后进行实验。实验结果如下：<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/7.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/7.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>由实验结果可知，随着网络分支数量的增加，神经网络的速度在降低。网络碎片化程度对GPU的影响效果明显，对CPU不明显，但是网络速度同样在降低。</p>
<h3 id="17-8-7-减少元素级操作"><a href="#17-8-7-减少元素级操作" class="headerlink" title="17.8.7 减少元素级操作"></a>17.8.7 减少元素级操作</h3><p><strong>元素级操作所带来的时间消耗也不能忽视</strong><br>ReLU ，Tensor 相加，Bias相加的操作，分离卷积（depthwise convolution）都定义为元素级操作。<br>FLOPs大多数是对于卷积计算而言的，因为元素级操作的FLOPs相对要低很多。但是过的元素级操作也会带来时间成本。ShuffleNet作者对ShuffleNet v1和MobileNet v2的几种层操作的时间消耗做了分析，发现元素级操作对于网络速度的影响也很大。<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/8.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/8.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"></p>
<h2 id="17-9-常用的轻量级网络有哪些？"><a href="#17-9-常用的轻量级网络有哪些？" class="headerlink" title="17.9 常用的轻量级网络有哪些？"></a>17.9 常用的轻量级网络有哪些？</h2><h3 id="17-9-1-SequeezeNet"><a href="#17-9-1-SequeezeNet" class="headerlink" title="17.9.1 SequeezeNet"></a>17.9.1 SequeezeNet</h3><p>SqueenzeNet出自F. N. Iandola, S.Han等人发表的论文《SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt; 0.5MB model size》，作者在保证精度不损失的同时，将原始AlexNet压缩至原来的510倍。  </p>
<h4 id="1-1-设计思想"><a href="#1-1-设计思想" class="headerlink" title="1.1 设计思想"></a>1.1 设计思想</h4><p>在网络结构设计方面主要采取以下三种方式：</p>
<ul>
<li>用1*1卷积核替换3*3卷积<ul>
<li>理论上一个1*1卷积核的参数是一个3*3卷积核的1/9，可以将模型尺寸压缩9倍。</li>
</ul>
</li>
<li>减小3*3卷积的输入通道数<ul>
<li>根据上述公式，减少输入通道数不仅可以减少卷积的运算量，而且输入通道数与输出通道数相同时还可以减少MAC。</li>
</ul>
</li>
<li>延迟降采样<ul>
<li>分辨率越大的输入能够提供更多特征的信息，有利于网络的训练判断，延迟降采样可以提高网络精度。<h4 id="1-2-网络架构"><a href="#1-2-网络架构" class="headerlink" title="1.2 网络架构"></a>1.2 网络架构</h4>SqueezeNet提出一种多分支结构——fire model，其中是由Squeeze层和expand层构成。Squeeze层是由s1个1*1卷积组成，主要是通过1*1的卷积降低expand层的输入维度；expand层利用e1个1*1和e3个3*3卷积构成多分支结构提取输入特征，以此提高网络的精度(其中e1=e3=4*s1)。<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/9.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/9.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>SqueezeNet整体网络结构如下图所示：<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/10.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/10.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"></li>
</ul>
</li>
</ul>
<h4 id="1-3实验结果"><a href="#1-3实验结果" class="headerlink" title="1.3实验结果"></a>1.3实验结果</h4><p>不同压缩方法在ImageNet上的对比实验结果<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/11.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/11.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>由实验结果可知，SqueezeNet不仅保证了精度，而且将原始AlexNet从240M压缩至4.8M，压缩50倍，说明此轻量级网络设计是可行。</p>
<h3 id="17-9-2-MobileNet"><a href="#17-9-2-MobileNet" class="headerlink" title="17.9.2 MobileNet"></a>17.9.2 MobileNet</h3><p>MobileNet 是Google团队于CVPR-2017的论文《MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications》中针对手机等嵌入式设备提出的一种轻量级的深层神经网络，该网络结构在VGG的基础上使用DW+PW的组合，在保证不损失太大精度的同时，降低模型参数量。</p>
<h4 id="2-1-设计思想"><a href="#2-1-设计思想" class="headerlink" title="2.1 设计思想"></a>2.1 设计思想</h4><ul>
<li>采用深度可分离卷积代替传统卷积<ul>
<li>采用DW卷积在减少参数数量的同时提升运算速度。但是由于每个feature map只被一个卷积核卷积，因此经过DW输出的feature map不能只包含输入特征图的全部信息，而且特征之间的信息不能进行交流，导致“信息流通不畅”。</li>
<li>采用PW卷积实现通道特征信息交流，解决DW卷积导致“信息流通不畅”的问题。</li>
</ul>
</li>
<li>使用stride=2的卷积替换pooling<ul>
<li>直接在卷积时利用stride=2完成了下采样，从而节省了需要再去用pooling再去进行一次下采样的时间，可以提升运算速度。同时，因为pooling之前需要一个stride=1的 conv，而与stride=2 conv的计算量想比要高近4倍(<strong>个人理解</strong>)。<h4 id="2-2-网络架构"><a href="#2-2-网络架构" class="headerlink" title="2.2 网络架构"></a>2.2 网络架构</h4></li>
</ul>
</li>
<li><p>DW conv和PW conv<br>MobileNet的网络架构主要是由DW conv和PW conv组成，相比于传统卷积可以降低$\dfrac{1}{N} + \dfrac{1}{Dk}$倍的计算量。<br>标准卷积与DW conv和PW conv如图所示:<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/12.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/12.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>深度可分离卷积与传统卷积运算量对比：<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/13.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/13.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>网络结构：<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/14.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/14.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"></p>
</li>
<li><p>MobileNets的架构<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/15.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/15.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"></p>
</li>
</ul>
<h4 id="2-3-实验结果"><a href="#2-3-实验结果" class="headerlink" title="2.3 实验结果"></a>2.3 实验结果</h4><p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/16.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/16.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>由上表可知，使用相同的结构，深度可分离卷积虽然准确率降低1%，但是参数量减少了6/7。</p>
<h3 id="17-9-3-MobileNet-v2"><a href="#17-9-3-MobileNet-v2" class="headerlink" title="17.9.3 MobileNet-v2"></a>17.9.3 MobileNet-v2</h3><p>MobileNet-V2是2018年1月公开在arXiv上论文《Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation》，是对MobileNet-V1的改进，同样是一个轻量化卷积神经网络。</p>
<h4 id="3-1-设计思想"><a href="#3-1-设计思想" class="headerlink" title="3.1 设计思想"></a>3.1 设计思想</h4><ul>
<li>采用Inverted residuals<ul>
<li>为了保证网络可以提取更多的特征，在residual block中第一个1*1 Conv和3*3 DW Conv之前进行通道扩充</li>
</ul>
</li>
<li>Linear bottlenecks<ul>
<li>为了避免Relu对特征的破坏，在residual block的Eltwise sum之前的那个 1*1 Conv 不再采用Relu</li>
</ul>
</li>
<li>stride=2的conv不使用shot-cot，stride=1的conv使用shot-cut</li>
</ul>
<h4 id="3-2-网络架构"><a href="#3-2-网络架构" class="headerlink" title="3.2 网络架构"></a>3.2 网络架构</h4><ul>
<li>Inverted residuals<br>ResNet中Residuals block先经过1*1的Conv layer，把feature map的通道数降下来，再经过3*3 Conv layer，最后经过一个1*1 的Conv layer，将feature map 通道数再“扩张”回去。即采用先压缩，后扩张的方式。而 inverted residuals采用先扩张，后压缩的方式。<br>MobileNet采用DW conv提取特征，由于DW conv本身提取的特征数就少，再经过传统residuals block进行“压缩”，此时提取的特征数会更少，因此inverted residuals对其进行“扩张”，保证网络可以提取更多的特征。<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/17.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/17.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"></li>
<li>Linear bottlenecks<br>ReLu激活函数会破坏特征。ReLu对于负的输入，输出全为0，而本来DW conv特征通道已经被“压缩”，再经过ReLu的话，又会损失一部分特征。采用Linear，目的是防止Relu破坏特征。<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/18.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/18.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"></li>
<li>shortcut<br>stride=2的conv不使用shot-cot，stride=1的conv使用shot-cut<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/19.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/19.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"></li>
<li>网络架构<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/20.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/20.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"></li>
</ul>
<h3 id="17-9-4-Xception"><a href="#17-9-4-Xception" class="headerlink" title="17.9.4 Xception"></a>17.9.4 Xception</h3><p>Xception是Google提出的，arXiv 的V1 于2016年10月公开《Xception: Deep Learning with Depthwise Separable Convolutions 》，Xception是对Inception v3的另一种改进，主要是采用depthwise separable convolution来替换原来Inception v3中的卷积操作。</p>
<h4 id="4-1设计思想"><a href="#4-1设计思想" class="headerlink" title="4.1设计思想"></a>4.1设计思想</h4><ul>
<li>采用depthwise separable convolution来替换原来Inception v3中的卷积操作<br>  与原版的Depth-wise convolution有两个不同之处：<ul>
<li>第一个：原版Depth-wise convolution，先逐通道卷积，再1<em>1卷积; 而Xception是反过来，先1\</em>1卷积，再逐通道卷积；</li>
<li>第二个：原版Depth-wise convolution的两个卷积之间是不带激活函数的，而Xception在经过1*1卷积之后会带上一个Relu的非线性激活函数；</li>
</ul>
</li>
</ul>
<h4 id="4-2网络架构"><a href="#4-2网络架构" class="headerlink" title="4.2网络架构"></a>4.2网络架构</h4><p>feature map在空间和通道上具有一定的相关性，通过Inception模块和非线性激活函数实现通道之间的解耦。增多3*3的卷积的分支的数量，使它与1*1的卷积的输出通道数相等，此时每个3*3的卷积只作用与一个通道的特征图上，作者称之为“极致的Inception（Extream Inception）”模块，这就是Xception的基本模块。<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/21.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/21.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"></p>
<h3 id="17-9-5-ShuffleNet-v1"><a href="#17-9-5-ShuffleNet-v1" class="headerlink" title="17.9.5 ShuffleNet-v1"></a>17.9.5 ShuffleNet-v1</h3><p>ShuffleNet 是Face++团队提出的，晚于MobileNet两个月在arXiv上公开《ShuffleNet： An Extremely Efficient Convolutional Neural Network for Mobile Devices 》用于移动端前向部署的网络架构。ShuffleNet基于MobileNet的group思想，将卷积操作限制到特定的输入通道。而与之不同的是，ShuffleNet将输入的group进行打散，从而保证每个卷积核的感受野能够分散到不同group的输入中，增加了模型的学习能力。</p>
<h4 id="5-1-设计思想"><a href="#5-1-设计思想" class="headerlink" title="5.1 设计思想"></a>5.1 设计思想</h4><ul>
<li>采用group conv减少大量参数<ul>
<li>roup conv与DW conv存在相同的“信息流通不畅”问题 </li>
</ul>
</li>
<li>采用channel shuffle解决上述问题<ul>
<li>MobileNet中采用PW conv解决上述问题，SheffleNet中采用channel shuffle</li>
</ul>
</li>
<li>采用concat替换add操作<ul>
<li>avg pooling和DW conv(s=2)会减小feature map的分辨率，采用concat增加通道数从而弥补分辨率减小而带来信息的损失</li>
</ul>
</li>
</ul>
<h4 id="5-2-网络架构"><a href="#5-2-网络架构" class="headerlink" title="5.2 网络架构"></a>5.2 网络架构</h4><p>MobileNet中1*1卷积的操作占据了约95%的计算量，所以作者将1*1也更改为group卷积，使得相比MobileNet的计算量大大减少。<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/22.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/22.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>group卷积与DW存在同样使“通道信息交流不畅”的问题，MobileNet中采用PW conv解决上述问题，SheffleNet中采用channel shuffle。<br>ShuffleNet的shuffle操作如图所示<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/24.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/24.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>avg pooling和DW conv(s=2)会减小feature map的分辨率，采用concat增加通道数从而弥补分辨率减小而带来信息的损失；实验表明：多多使用通道(提升通道的使用率)，有助于提高小模型的准确率。<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/23.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/23.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>网络结构：<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/25.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/25.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"></p>
<h3 id="17-9-6-ShuffleNet-v2"><a href="#17-9-6-ShuffleNet-v2" class="headerlink" title="17.9.6 ShuffleNet-v2"></a>17.9.6 ShuffleNet-v2</h3><p>huffleNet-v2 是Face++团队提出的《ShuffleNet V2: Practical Guidelines for Ecient CNN Architecture Design》，旨在设计一个轻量级但是保证精度、速度的深度网络。</p>
<h4 id="6-1-设计思想"><a href="#6-1-设计思想" class="headerlink" title="6.1 设计思想"></a>6.1 设计思想</h4><ul>
<li>文中提出影响神经网络速度的4个因素：<ul>
<li>a. FLOPs(FLOPs就是网络执行了多少multiply-adds操作)</li>
<li>b. MAC(内存访问成本)</li>
<li>c. 并行度(如果网络并行度高，速度明显提升)</li>
<li>d. 计算平台(GPU，ARM)</li>
</ul>
</li>
<li>ShuffleNet-v2 提出了4点网络结构设计策略：<ul>
<li>G1.输入输出的channel相同时，MAC最小</li>
<li>G2.过度的组卷积会增加MAC</li>
<li>G3.网络碎片化会降低并行度</li>
<li>G4.元素级运算不可忽视  </li>
</ul>
</li>
</ul>
<h4 id="6-2-网络结构"><a href="#6-2-网络结构" class="headerlink" title="6.2 网络结构"></a>6.2 网络结构</h4><p>depthwise convolution 和 瓶颈结构增加了 MAC，用了太多的 group，跨层连接中的 element-wise Add 操作也是可以优化的点。所以在 shuffleNet V2 中增加了几种新特性。<br>所谓的 channel split 其实就是将通道数一分为2，化成两分支来代替原先的分组卷积结构（G2），并且每个分支中的卷积层都是保持输入输出通道数相同（G1），其中一个分支不采取任何操作减少基本单元数（G3），最后使用了 concat 代替原来的 elementy-wise add，并且后面不加 ReLU 直接（G4），再加入channle shuffle 来增加通道之间的信息交流。 对于下采样层，在这一层中对通道数进行翻倍。 在网络结构的最后，即平均值池化层前加入一层 1x1 的卷积层来进一步的混合特征。<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/26.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/26.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"><br>网络结构<br><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/27.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/27.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="image"></p>
<h4 id="6-4-ShuffleNet-v2具有高精度的原因"><a href="#6-4-ShuffleNet-v2具有高精度的原因" class="headerlink" title="6.4  ShuffleNet-v2具有高精度的原因"></a>6.4  ShuffleNet-v2具有高精度的原因</h4><ul>
<li>由于高效，可以增加更多的channel，增加网络容量</li>
<li>采用split使得一部分特征直接与下面的block相连，特征复用(DenseNet)</li>
</ul>
<h2 id="17-10-现有移动端开源框架及其特点"><a href="#17-10-现有移动端开源框架及其特点" class="headerlink" title="17.10 现有移动端开源框架及其特点"></a>17.10 现有移动端开源框架及其特点</h2><h3 id="17-10-1-NCNN"><a href="#17-10-1-NCNN" class="headerlink" title="17.10.1 NCNN"></a>17.10.1 NCNN</h3><p>１、开源时间：2017年7月　　　</p>
<p>２、开源用户：腾讯优图　　　　</p>
<p>３、GitHub地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/Tencent/ncnn">https://github.com/Tencent/ncnn</a> 　　</p>
<p>4、特点：</p>
<ul>
<li>1）NCNN考虑了手机端的硬件和系统差异以及调用方式，架构设计以手机端运行为主要原则。</li>
<li>2）无第三方依赖，跨平台，手机端 CPU 的速度快于目前所有已知的开源框架（以开源时间为参照对象）。</li>
<li>3）基于 ncnn，开发者能够将深度学习算法轻松移植到手机端高效执行，开发出人工智能 APP。   </li>
</ul>
<p>5、功能：    </p>
<ul>
<li>1、NCNN支持卷积神经网络、多分支多输入的复杂网络结构，如vgg、googlenet、resnet、squeezenet 等。</li>
<li>2、NCNN无需依赖任何第三方库。    </li>
<li>3、NCNN全部使用C/C++实现，以及跨平台的cmake编译系统，可轻松移植到其他系统和设备上。    </li>
<li>4、汇编级优化，计算速度极快。使用ARM NEON指令集实现卷积层，全连接层，池化层等大部分 CNN 关键层。 </li>
<li>5、精细的数据结构设计，没有采用需消耗大量内存的通常框架——im2col + 矩阵乘法，使得内存占用极低。   </li>
<li>6、支持多核并行计算，优化CPU调度。   </li>
<li>7、整体库体积小于500K，可精简到小于300K。   </li>
<li>8、可扩展的模型设计，支持8bit 量化和半精度浮点存储。   </li>
<li>9、支持直接内存引用加载网络模型。   </li>
<li>10、可注册自定义层实现并扩展。   </li>
</ul>
<p>6、NCNN在Android端部署示例</p>
<ul>
<li>1）选择合适的Android Studio版本并安装。</li>
<li>2）根据需求选择NDK版本并安装。</li>
<li>3）在Android Studio上配置NDK的环境变量。</li>
<li>4）根据自己需要编译NCNN sdk</li>
</ul>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir build-android cd build-android cmake -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake \ -DANDROID_ABI="armeabi-v7a" -DANDROID_ARM_NEON=ON \ -DANDROID_PLATFORM=android-14 .. make make install</span><br></pre></td></tr></tbody></table></figure>
<p>​    安装完成之后，install下有include和lib两个文件夹。</p>
<p>​    备注：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ANDROID_ABI 是架构名字，"armeabi-v7a" 支持绝大部分手机硬件 </span><br><span class="line">ANDROID_ARM_NEON 是否使用 NEON 指令集，设为 ON 支持绝大部分手机硬件 </span><br><span class="line">ANDROID_PLATFORM 指定最低系统版本，"android-14" 就是 android-4.0</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>5）进行NDK开发。</li>
</ul>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1）assets文件夹下放置你的bin和param文件。</span><br><span class="line">2）jni文件夹下放置你的cpp和mk文件。</span><br><span class="line">3）修改你的app gradle文件。</span><br><span class="line">4）配置Android.mk和Application.mk文件。</span><br><span class="line">5）进行java接口的编写。</span><br><span class="line">6）读取拷贝bin和param文件（有些则是pb文件，根据实际情况）。</span><br><span class="line">7）进行模型的初始化和执行预测等操作。</span><br><span class="line">8）build。</span><br><span class="line">9）cd到src/main/jni目录下，执行ndk-build，生成.so文件。</span><br><span class="line">10）接着就可写自己的操作处理需求。</span><br></pre></td></tr></tbody></table></figure>
<h3 id="17-10-2-QNNPACK"><a href="#17-10-2-QNNPACK" class="headerlink" title="17.10.2 QNNPACK"></a>17.10.2 QNNPACK</h3><p>全称：Quantized Neural Network PACKage（量化神经网络包）　　　</p>
<p>１、开源时间：2018年10月　　　</p>
<p>２、开源用户：Facebook　　　　</p>
<p>３、GitHub地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/pytorch/QNNPACK">https://github.com/pytorch/QNNPACK</a>　　　　</p>
<p>４、特点：　　　</p>
<p>​    １）低密度卷积优化函数库；　　　</p>
<p>　    ２）可在手机上实时运行Mask R-CNN 和 DensePose;</p>
<p>​    ３） 能在性能受限的移动设备中用 100ms 以内的时间实施图像分类；　　　</p>
<p>5、QNNPACK 如何提高效率？</p>
<p>1)<strong>QNNPACK 使用与安卓神经网络 API 兼容的线性量化方案</strong></p>
<p>QNNPACK 的输入矩阵来自低精度、移动专用的计算机视觉模型。其它库在计算A和B矩阵相乘时，重新打包 A 和 B 矩阵以更好地利用缓存层次结构，希望在大量计算中分摊打包开销，QNNPACK 删除所有计算非必需的内存转换，针对 A和B矩阵相乘适用于一级缓存的情况进行了优化。</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/QNNPACK1.jpeg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/QNNPACK1.jpeg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p>​    1）优化了L1缓存计算，不需要输出中间结果，直接输出最终结果，节省内存带宽和缓存占用。</p>
<p>具体分析：</p>
<ul>
<li>常规实现：在量化矩阵-矩阵乘法中，8位整数的乘积通常会被累加至 32 位的中间结果中，随后重新量化以产生 8 位的输出。遇到大矩阵尺寸时，比如有时K太大，A和B的面板无法直接转入缓存，此时，需利用缓存层次结构，借助GEMM将A和B的面板沿着K维分割成固定大小的子面板，以便于每个子面板都能适应L1缓存，随后为每个子面板调用微内核。这一缓存优化需要 PDOT 为内核输出 32  位中间结果，最终将它们相加并重新量化为 8 位整数。</li>
<li>优化实现：由于  ONNPACK 对于面板 A 和 B 总是适应 L1 缓存的移动神经网络进行了优化，因此它在调用微内核时处理整个 A 和 B  的面板。而由于无需在微内核之外积累 32 位的中间结果，QNNPACK 会将 32 位的中间结果整合进微内核中并写出 8  位值，这节省了内存带宽和缓存占用。</li>
</ul>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/QNNPACK2.jpeg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/QNNPACK2.jpeg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p>​    2）取消了矩阵 A 的重新打包。</p>
<ul>
<li><p>常规实现：</p>
<pre><code>  矩阵 B 包含静态权重，可以一次性转换成任何内存布局，但矩阵  A 包含卷积输入，每次推理运行都会改变。因此，重新打包矩阵 A 在每次运行时都会产生开销。尽管存在开销，传统的 GEMM实现还是出于以下两个原因对矩阵 A 进行重新打包：

  a 缓存关联性及微内核效率受限。如果不重新打包，微内核将不得不读取被潜在的大跨距隔开的几行A。如果这个跨距恰好是 2 的许多次幂的倍数，面板中不同行 A  的元素可能会落入同一缓存集中。如果冲突的行数超过了缓存关联性，它们就会相互驱逐，性能也会大幅下降。

  b 打包对微内核效率的影响与当前所有移动处理器支持的  SIMD  向量指令的使用密切相关。这些指令加载、存储或者计算小型的固定大小元素向量，而不是单个标量（scalar）。在矩阵相乘中，充分利用向量指令达到高性能很重要。在传统的  GEMM 实现中，微内核把 MR 元素重新打包到向量暂存器里的 MR 线路中。
</code></pre></li>
<li><p>优化实现：</p>
<pre><code>  a 当面板适配一级缓存时，不会存在缓存关联性及微内核效率受限的问题。

  b 在 QNNPACK 实现中，MR  元素在存储中不是连续的，微内核需要把它们加载到不同的向量暂存器中。越来越大的暂存器压力迫使 QNNPACK 使用较小的 MRxNR  拼贴，但实际上这种差异很小，而且可以通过消除打包开销来补偿。例如，在 32 位 ARM 架构上，QNNPACK 使用 4×8 微内核，其中  57% 的向量指令是乘-加；另一方面，gemmlowp 库使用效率稍高的 4×12 微内核，其中 60% 的向量指令是乘-加。微内核加载 A  的多个行，乘以 B 的满列，结果相加，然后完成再量化并记下量化和。A 和 B 的元素被量化为 8 位整数，但乘积结果相加到 32 位。大部分  ARM 和 ARM64 处理器没有直接完成这一运算的指令，所以它必须分解为多个支持运算。QNNPACK  提供微内核的两个版本，其不同之处在于用于乘以 8 位值并将它们累加到 32 位的指令序列。
</code></pre></li>
</ul>
<p>2)<strong>从矩阵相乘到卷积</strong></p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/QNNPACK3.jpeg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/QNNPACK3.jpeg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p>​    传统实现：</p>
<p>​    简单的 1×1  卷积可直接映射到矩阵相乘</p>
<p>​    但对于具备较大卷积核、padding 或子采样（步幅）的卷积而言则并非如此。但是，这些较复杂的卷积能够通过记忆变换  im2col 映射到矩阵相乘。对于每个输出像素，im2col 复制输入图像的图像块并将其计算为 2D 矩阵。由于每个输出像素都受 KHxKWxC  输入像素值的影响（KH 和 KW 分别指卷积核的高度和宽度，C 指输入图像中的通道数），因此该矩阵的大小是输入图像的 KHxKW  倍，im2col 给内存占用和性能都带来了一定的开销。和 Caffe 一样，大部分深度学习框架转而使用基于 im2col  的实现，利用现有的高度优化矩阵相乘库来执行卷积操作。</p>
<p>​    优化实现：</p>
<p>​    Facebook  研究者在 QNNPACK 中实现了一种更高效的算法。</p>
<ul>
<li>他们没有变换卷积输入使其适应矩阵相乘的实现，而是调整 PDOT 微内核的实现，在运行中执行  im2col 变换。这样就无需将输入张量的实际输入复制到 im2col 缓存，而是使用输入像素行的指针设置 indirection  buffer，输入像素与每个输出像素的计算有关。</li>
<li>研究者还修改了矩阵相乘微内核，以便从 indirection buffer  加载虚构矩阵（imaginary matrix）A 的行指针，indirection buffer 通常比 im2col buffer  小得多。</li>
<li>此外，如果两次推断运行的输入张量存储位置不变，则 indirection buffer  还可使用输入张量行的指针进行初始化，然后在多次推断运行中重新使用。研究者观察到具备 indirection buffer 的微内核不仅消除了  im2col 变换的开销，其性能也比矩阵相乘微内核略好（可能由于输入行在计算不同输出像素时被重用）。</li>
</ul>
<p>3)<strong>深度卷积</strong></p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/QNNPACK4.jpeg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/QNNPACK4.jpeg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p>分组卷积（grouped   convolution）将输入和输出通道分割成多组，然后对每个组进行分别处理。在有限条件下，当组数等于通道数时，该卷积就是深度卷积，常用于当前的神经网络架构中。深度卷积对每个通道分别执行空间滤波，展示了与正常卷积非常不同的计算模式。因此，通常要向深度卷积提供单独实现，QNNPACK  包括一个高度优化版本 3×3 深度卷积。</p>
<p>深度卷积的传统实现是每次都在卷积核元素上迭代，然后将一个卷积核行和一个输入行的结果累加到输出行。对于一个  3×3 的深度卷积，此类实现将把每个输出行更新 9 次。在 QNNPACK 中，研究者计算所有 3×3 卷积核行和 3×3  输入行的结果，一次性累加到输出行，然后再处理下个输出行。</p>
<p>QNNPACK  实现高性能的关键因素在于完美利用通用暂存器（GPR）来展开卷积核元素上的循环，同时避免在 hot loop 中重新加载地址寄存器。32-bit  ARM 架构将实现限制在 14 个 GPR。在 3×3 深度卷积中，需要读取 9 个输入行和 9 个卷积核行。这意味着如果想完全展开循环必须存储  18 个地址。然而，实践中推断时卷积核不会发生变化。因此 Facebook 研究者使用之前在 CxKHxKW 中的滤波器，将它们封装进  [C/8]xKWxKHx8，这样就可以仅使用具备地址增量（address increment）的一个 GPR 访问所有滤波器。（研究者使用数字 8  的原因在于，在一个命令中加载 8 个元素然后减去零，在 128-bit NEON 暂存器中生成 8 个 16-bit 值。）然后使用 9  个输入行指针，指针将滤波器重新装进 10 个 GPR，完全展开滤波器元素上的循环。64-bit ARM 架构相比 32-bit 架构，GPR  的数量翻了一倍。QNNPACK 利用额外的 ARM64 GPR，一次性存储 3×5 输入行的指针，并计算 3 个输出行。</p>
<p>7、性能优势：</p>
<p>​    测试结果显示出 QNNPACK 在端到端基准上的性能优势。在量化当前最优 MobileNetV2 架构上，基于QNNPACK 的 Caffe2 算子的速度大约是 TensorFlow Lite 速度的 2 倍，在多种手机上都是如此。除了 QNNPACK 之外，Facebook 还开源了 Caffe2 quantized MobileNet v2 模型，其 top-1 准确率比相应的 TensorFlow 模型高出 1.3%。    </p>
<p><strong>MobileNetV1</strong></p>
<p>MobileNetV1  架构在使用深度卷积（depthwise convolution）使模型更适合移动设备方面具备开创性。MobileNetV1 包括几乎整个  1×1 卷积和 3×3 卷积。Facebook 研究者将量化 MobileNetV1 模型从 TensorFlow Lite 转换而来，并在  TensorFlow Lite 和 QNNPACK 的 32-bit ARM 设备上对 MobileNetV1 进行基准测试。二者运行时均使用 4  线程，研究者观察到 QNNPACK 的运行速度几何平均值是 TensorFlow Lite 的 1.8 倍。</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/mv1.jpg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/mv1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p><strong>MobileNetV2</strong></p>
<p>作为移动视觉任务的当前最优架构之一，MobileNetV2  引入了瓶颈构造块和瓶颈之间的捷径连接。研究者在 MobileNetV2 分类模型的量化版上对比基于 QNNPACK 的 Caffe2 算子和  TensorFlow Lite 实现。使用的量化 Caffe2 MobileNetV2 模型已开源，量化 TensorFlow Lite  模型来自官方库：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md。下表展示了二者在常用测试集上的">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md。下表展示了二者在常用测试集上的</a>  top1 准确率：</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/mv2.jpg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/mv2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p>​    Facebook 研究者利用这些模型建立了 Facebook AI 性能评估平台（<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/facebook/FAI-PEP）的基准，该基准基于">https://github.com/facebook/FAI-PEP）的基准，该基准基于</a> 32-bit ARM 环境的大量手机设备。对于 TensorFlow Lite 线程设置，研究者尝试了一到四个线程，并报告了最快速的结果。结果显示 TensorFlow Lite 使用四线程的性能最优，因此后续研究中使用四线程来对比 TensorFlow Lite 和 QNNPACK。下表展示了结果，以及在典型智能手机和高端机上，基于 QNNPACK 的算子速度比 TensorFlow Lite 快得多。</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/mv3.jpg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/mv3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p>Facebook开源高性能内核库QNNPACK<br><a target="_blank" rel="external nofollow noopener noreferrer" href="https://baijiahao.baidu.com/s?id=1615725346726413945&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1615725346726413945&amp;wfr=spider&amp;for=pc</a><br><a target="_blank" rel="external nofollow noopener noreferrer" href="http://www.sohu.com/a/272158070_610300">http://www.sohu.com/a/272158070_610300</a></p>
<p>支持移动端深度学习的几种开源框架<br><a target="_blank" rel="external nofollow noopener noreferrer" href="https://blog.csdn.net/zchang81/article/details/74280019">https://blog.csdn.net/zchang81/article/details/74280019</a></p>
<h3 id="17-10-3-Prestissimo"><a href="#17-10-3-Prestissimo" class="headerlink" title="17.10.3 Prestissimo"></a>17.10.3 Prestissimo</h3><p>１、开源时间：2017年11月　　　</p>
<p>２、开源用户：九言科技　　　　</p>
<p>３、GitHub地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/in66-dev/In-Prestissimo">https://github.com/in66-dev/In-Prestissimo</a>　　</p>
<p>４、功能特点：　</p>
<p><strong>基础功能</strong></p>
<ul>
<li>支持卷积神经网络，支持多输入和多分支结构</li>
<li>精炼简洁的API设计，使用方便</li>
<li>提供调试接口，支持打印各个层的数据以及耗时</li>
<li>不依赖任何第三方计算框架，整体库体积 500K 左右（32位 约400k，64位 约600k）</li>
<li>纯 C++ 实现，跨平台，支持 android 和 ios</li>
<li>模型为纯二进制文件，不暴露开发者设计的网络结构</li>
</ul>
<p><strong>极快的速度</strong></p>
<ul>
<li>大到框架设计，小到汇编书写上全方位的优化，iphone7 上跑 SqueezeNet 仅需 26ms（单线程）</li>
<li>支持浮点(float)和整型(int)两种运算模式，float模式精度与caffe相同，int模式运算速度快，大部分网络用int的精度便已经足够</li>
<li>以巧妙的内存布局提升cpu的cache命中率，在中低端机型上性能依然强劲</li>
<li>针对 float-arm32, float-arm64, int-arm32, int-arm64 四个分支均做了细致的优化，保证arm32位和arm64位版本都有非常好的性能</li>
</ul>
<p><strong>SqueezeNet-v1.1 测试结果</strong></p>
<p><strong>Note</strong>: 手机测试性能存在一定的抖动，连续多次运算取平均时间</p>
<p><strong>Note</strong>: 像华为mate8, mate9，Google nexus 6 虽然是64位的CPU，但测试用的是 32位的库，因此cpu架构依然写 arm-v7a</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">CPU架构</th>
<th style="text-align:center">机型</th>
<th style="text-align:center">CPU</th>
<th style="text-align:center">ncnn（4线程）</th>
<th style="text-align:center">mdl</th>
<th style="text-align:center">Prestissimo_float(单线程)</th>
<th style="text-align:center">Prestissimo_int(单线程)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">arm-v7a</td>
<td style="text-align:center">小米2</td>
<td style="text-align:center">高通APQ8064 1.5GHz</td>
<td style="text-align:center">185 ms</td>
<td style="text-align:center">370 ms</td>
<td style="text-align:center">184 ms</td>
<td style="text-align:center">115 ms</td>
</tr>
<tr>
<td style="text-align:center">arm-v7a</td>
<td style="text-align:center">小米2s</td>
<td style="text-align:center">四核 骁龙APQ8064 Pro 1.7GHz</td>
<td style="text-align:center">166 ms</td>
<td style="text-align:center">-</td>
<td style="text-align:center">136 ms</td>
<td style="text-align:center">96 ms</td>
</tr>
<tr>
<td style="text-align:center">arm-v7a</td>
<td style="text-align:center">红米Note 4x</td>
<td style="text-align:center">骁龙625 四核2.0GHz</td>
<td style="text-align:center">124 ms</td>
<td style="text-align:center">306 ms</td>
<td style="text-align:center">202 ms</td>
<td style="text-align:center">110 ms</td>
</tr>
<tr>
<td style="text-align:center">arm-v7a</td>
<td style="text-align:center">Google Nexus 6</td>
<td style="text-align:center">骁龙805 四核 2.7GHz</td>
<td style="text-align:center">84 ms</td>
<td style="text-align:center">245 ms</td>
<td style="text-align:center">103 ms</td>
<td style="text-align:center">63 ms</td>
</tr>
<tr>
<td style="text-align:center">arm-v7a</td>
<td style="text-align:center">Vivo x6d</td>
<td style="text-align:center">联发科 MT6752 1.7GHz</td>
<td style="text-align:center">245 ms</td>
<td style="text-align:center">502 ms</td>
<td style="text-align:center">370 ms</td>
<td style="text-align:center">186 ms</td>
</tr>
<tr>
<td style="text-align:center">arm-v7a</td>
<td style="text-align:center">华为 Mate 8</td>
<td style="text-align:center">海思麒麟950 4大4小 2.3GHz 1.8GHz</td>
<td style="text-align:center">75 ms</td>
<td style="text-align:center">180 ms</td>
<td style="text-align:center">95 ms</td>
<td style="text-align:center">57 ms</td>
</tr>
<tr>
<td style="text-align:center">arm-v7a</td>
<td style="text-align:center">华为 Mate 9</td>
<td style="text-align:center">海思麒麟960 4大4小 2.4GHz 1.8GHz</td>
<td style="text-align:center">61 ms</td>
<td style="text-align:center">170 ms</td>
<td style="text-align:center">94 ms</td>
<td style="text-align:center">48 ms</td>
</tr>
<tr>
<td style="text-align:center">arm-v8</td>
<td style="text-align:center">iphone7</td>
<td style="text-align:center">Apple A10 Fusion 2.34GHz</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">27 ms</td>
<td style="text-align:center">26 ms</td>
</tr>
</tbody>
</table>
</div>
<p><strong>未开放特性</strong></p>
<ul>
<li>多核并行加速（多核机器可以再提升30%-100% 的速度）</li>
<li>depthwise卷积运算（支持mobilenet）</li>
<li>模型压缩功能，压缩后的模型体积可缩小到20%以下</li>
<li>GPU 运算模式（Android 基于opengl es 3.1，ios 基于metal）</li>
</ul>
<p><strong>同类框架对比</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">框架</th>
<th style="text-align:center">caffe</th>
<th style="text-align:center">tensorflow</th>
<th style="text-align:center">mdl-android</th>
<th style="text-align:center">mdl-ios</th>
<th style="text-align:center">ncnn</th>
<th style="text-align:center">CoreML</th>
<th style="text-align:center">Prestissimo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">计算硬件</td>
<td style="text-align:center">cpu</td>
<td style="text-align:center">cpu</td>
<td style="text-align:center">cpu</td>
<td style="text-align:center">gpu</td>
<td style="text-align:center">cpu</td>
<td style="text-align:center">gpu</td>
<td style="text-align:center">cpu （gpu版本未开放）</td>
</tr>
<tr>
<td style="text-align:center">计算速度</td>
<td style="text-align:center">慢</td>
<td style="text-align:center">慢</td>
<td style="text-align:center">慢</td>
<td style="text-align:center">很快</td>
<td style="text-align:center">很快</td>
<td style="text-align:center">极快</td>
<td style="text-align:center">极快</td>
</tr>
<tr>
<td style="text-align:center">库大小</td>
<td style="text-align:center">大</td>
<td style="text-align:center">较大</td>
<td style="text-align:center">中等</td>
<td style="text-align:center">小</td>
<td style="text-align:center">小</td>
<td style="text-align:center">小</td>
<td style="text-align:center">小</td>
</tr>
<tr>
<td style="text-align:center">兼容性</td>
<td style="text-align:center">好</td>
<td style="text-align:center">好</td>
<td style="text-align:center">好</td>
<td style="text-align:center">限ios8以上</td>
<td style="text-align:center">很好</td>
<td style="text-align:center">仅支持 ios11</td>
<td style="text-align:center">很好</td>
</tr>
<tr>
<td style="text-align:center">模型支持度</td>
<td style="text-align:center">很好</td>
<td style="text-align:center">好</td>
<td style="text-align:center">-</td>
<td style="text-align:center">差（仅限指定模型）</td>
<td style="text-align:center">较好</td>
<td style="text-align:center">-</td>
<td style="text-align:center">中等（当前版本不支持mobilenet）</td>
</tr>
</tbody>
</table>
</div>
<p><strong>使用方法-模型转换</strong></p>
<p>绝影支持的是私有的模型文件格式，需要把 caffe 训练出来的模型转换为 .prestissimo 格式，模型转换工具为 caffe2Prestissimo.out。caffe2Prestissimo.out 依赖 protobuf 3.30。将 XXX.prototxt 和 YYY.caffemodel 转化为 Prestissimo 模型 ZZZ.prestissimo：（得到）./caffe2Prestissimo.out XXX.prototxt YYY.caffemodel ZZZ.prestissimo</p>
<h3 id="17-10-4-MDL（mobile-deep-learning）"><a href="#17-10-4-MDL（mobile-deep-learning）" class="headerlink" title="17.10.4 MDL（mobile-deep-learning）"></a>17.10.4 MDL（mobile-deep-learning）</h3><p>１、开源时间：2017年9月（已暂停更新）　　　</p>
<p>２、开源用户：百度　　　　</p>
<p>３、GitHub地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/allonli/mobile-deep-learning">https://github.com/allonli/mobile-deep-learning</a></p>
<p>４、功能特点：</p>
<ul>
<li>一键部署，脚本参数就可以切换ios或者android</li>
<li>支持iOS  gpu运行MobileNet、squeezenet模型</li>
<li>已经测试过可以稳定运行MobileNet、GoogLeNet v1、squeezenet、ResNet-50模型</li>
<li>体积极小，无任何第三方依赖。纯手工打造。</li>
<li>提供量化函数，对32位float转8位uint直接支持，模型体积量化后4M上下</li>
<li>与ARM相关算法团队线上线下多次沟通，针对ARM平台会持续优化</li>
<li>NEON使用涵盖了卷积、归一化、池化所有方面的操作</li>
<li>汇编优化，针对寄存器汇编操作具体优化</li>
<li>loop unrolling 循环展开，为提升性能减少不必要的CPU消耗，全部展开判断操作</li>
<li>将大量繁重的计算任务前置到overhead过程</li>
</ul>
<p>5、框架结构</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/MDL1.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/MDL1.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p>MDL 框架主要包括：<strong>模型转换模块（MDL Converter）、模型加载模块（Loader）、网络管理模块（Net）、矩阵运算模块（Gemmers）及供 Android 端调用的 JNI 接口层（JNI Interfaces）。</strong></p>
<p>​    其中，模型转换模块主要负责将Caffe 模型转为 MDL 模型，同时支持将 32bit 浮点型参数量化为 8bit 参数，从而极大地压缩模型体积；模型加载模块主要完成模型的反量化及加载校验、网络注册等过程，网络管理模块主要负责网络中各层 Layer 的初始化及管理工作；MDL 提供了供 Android 端调用的 JNI 接口层，开发者可以通过调用 JNI 接口轻松完成加载及预测过程。</p>
<p>6、MDL 的性能及兼容性</p>
<ul>
<li>体积 armv7 300k+</li>
<li>速度 iOS GPU mobilenet 可以达到 40ms、squeezenet 可以达到 30ms</li>
</ul>
<p>​        MDL  从立项到开源，已经迭代了一年多。移动端比较关注的多个指标都表现良好，如体积、功耗、速度。百度内部产品线在应用前也进行过多次对比，和已开源的相关项目对比，MDL  能够在保证速度和能耗的同时支持多种深度学习模型，如 mobilenet、googlenet v1、squeezenet 等，且具有 iOS  GPU 版本，squeezenet 一次运行最快可以达到 3-40ms。</p>
<p><strong>同类框架对比</strong></p>
<p>​     框架Caffe2TensorFlowncnnMDL(CPU)MDL(GPU)硬件CPUCPUCPUCPUGPU速度慢慢快快极快体积大大小小小兼容Android&amp;iOSAndroid&amp;iOSAndroid&amp;iOSAndroid&amp;iOSiOS</p>
<p>​     与支持 CNN 的移动端框架对比，MDL 速度快、性能稳定、兼容性好、demo 完备。</p>
<p><strong>兼容性</strong></p>
<p>​     MDL 在 iOS 和 Android 平台均可以稳定运行，其中 iOS10 及以上平台有基于 GPU 运算的 API，性能表现非常出色，在 Android 平台则是纯 CPU 运行。高中低端机型运行状态和手机百度及其他 App 上的覆盖都有绝对优势。</p>
<p>​     MDL 同时也支持 Caffe 模型直接转换为 MDL 模型。</p>
<h3 id="17-10-5-Paddle-Mobile"><a href="#17-10-5-Paddle-Mobile" class="headerlink" title="17.10.5 Paddle-Mobile"></a>17.10.5 Paddle-Mobile</h3><p>１、开源时间：持续更新，已到3.0版本　　　</p>
<p>２、开源用户：百度　　　　</p>
<p>３、GitHub地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/PaddlePaddle/paddle-mobile">https://github.com/PaddlePaddle/paddle-mobile</a>　</p>
<p>４、功能特点：</p>
<p><strong>功能特点</strong></p>
<ul>
<li><p>高性能支持ARM CPU </p>
</li>
<li><p>支持Mali GPU</p>
</li>
<li><p>支持Andreno GPU</p>
</li>
<li><p>支持苹果设备的GPU Metal实现</p>
</li>
<li><p>支持ZU5、ZU9等FPGA开发板</p>
</li>
<li><p>支持树莓派等arm-linux开发板</p>
</li>
</ul>
<h3 id="17-10-6-MACE（-Mobile-AI-Compute-Engine）"><a href="#17-10-6-MACE（-Mobile-AI-Compute-Engine）" class="headerlink" title="17.10.6 MACE（ Mobile AI Compute Engine）"></a>17.10.6 MACE（ Mobile AI Compute Engine）</h3><p>１、开源时间：2018年4月(持续更新，v0.9.0 (2018-07-20))　　　</p>
<p>２、开源用户：小米　　　　</p>
<p>３、GitHub地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/XiaoMi/mace">https://github.com/XiaoMi/mace</a>    </p>
<p>４、简介：Mobile AI Compute Engine (MACE) 是一个专为移动端异构计算设备优化的深度学习前向预测框架。<br>MACE覆盖了常见的移动端计算设备（CPU，GPU和DSP），并且提供了完整的工具链和文档，用户借助MACE能够很方便地在移动端部署深度学习模型。MACE已经在小米内部广泛使用并且被充分验证具有业界领先的性能和稳定性。</p>
<p>5、MACE的基本框架：</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/mace-arch.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/mace-arch.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p><strong>MACE Model</strong></p>
<p>MACE定义了自有的模型格式（类似于Caffe2），通过MACE提供的工具可以将Caffe和TensorFlow的模型 转为MACE模型。</p>
<p><strong>MACE Interpreter</strong></p>
<p>MACE Interpreter主要负责解析运行神经网络图（DAG）并管理网络中的Tensors。</p>
<p><strong>Runtime</strong></p>
<p>CPU/GPU/DSP Runtime对应于各个计算设备的算子实现。</p>
<p>6、MACE使用的基本流程</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/mace-work-flow-zh.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/mace-work-flow-zh.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p><strong>1. 配置模型部署文件(.yml)</strong></p>
<p>模型部署文件详细描述了需要部署的模型以及生成库的信息，MACE根据该文件最终生成对应的库文件。</p>
<p><strong>2.编译MACE库</strong></p>
<p>编译MACE的静态库或者动态库。</p>
<p><strong>3.转换模型</strong></p>
<p>将TensorFlow 或者 Caffe的模型转为MACE的模型。</p>
<p><strong>4.1. 部署</strong></p>
<p>根据不同使用目的集成Build阶段生成的库文件，然后调用MACE相应的接口执行模型。</p>
<p><strong>4.2. 命令行运行</strong></p>
<p>MACE提供了命令行工具，可以在命令行运行模型，可以用来测试模型运行时间，内存占用和正确性。</p>
<p><strong>4.3. Benchmark</strong></p>
<p>MACE提供了命令行benchmark工具，可以细粒度的查看模型中所涉及的所有算子的运行时间。</p>
<p>7、MACE在哪些角度进行了优化?</p>
<p><strong>MACE</strong> 专为移动端异构计算平台优化的神经网络计算框架。主要从以下的角度做了专门的优化：</p>
<ul>
<li>性能<ul>
<li>代码经过NEON指令，OpenCL以及Hexagon HVX专门优化，并且采用<br><a target="_blank" rel="external nofollow noopener noreferrer" href="https://arxiv.org/abs/1509.09308">Winograd算法</a>来进行卷积操作的加速。<br>此外，还对启动速度进行了专门的优化。</li>
</ul>
</li>
<li><p>功耗</p>
<ul>
<li>支持芯片的功耗管理，例如ARM的big.LITTLE调度，以及高通Adreno GPU功耗选项。</li>
</ul>
</li>
<li>系统响应<ul>
<li>支持自动拆解长时间的OpenCL计算任务，来保证UI渲染任务能够做到较好的抢占调度，<br>从而保证系统UI的相应和用户体验。</li>
</ul>
</li>
<li>内存占用<ul>
<li>通过运用内存依赖分析技术，以及内存复用，减少内存的占用。另外，保持尽量少的外部<br>依赖，保证代码尺寸精简。</li>
</ul>
</li>
<li><p>模型加密与保护</p>
<ul>
<li>模型保护是重要设计目标之一。支持将模型转换成C++代码，以及关键常量字符混淆，增加逆向的难度。</li>
</ul>
</li>
<li>硬件支持范围<ul>
<li>支持高通，联发科，以及松果等系列芯片的CPU，GPU与DSP(目前仅支持Hexagon)计算加速。</li>
<li>同时支持在具有POSIX接口的系统的CPU上运行。</li>
</ul>
</li>
</ul>
<p>8、性能对比：</p>
<p>MACE 支持 TensorFlow 和 Caffe 模型，提供转换工具，可以将训练好的模型转换成专有的模型数据文件，同时还可以选择将模型转换成C++代码，支持生成动态库或者静态库，提高模型保密性。</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/maca_com.jpg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/maca_com.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<h3 id="17-10-7-FeatherCNN"><a href="#17-10-7-FeatherCNN" class="headerlink" title="17.10.7 FeatherCNN"></a>17.10.7 FeatherCNN</h3><p>１、开源时间：持续更新，已到3.0版本　　　</p>
<p>２、开源用户：腾讯AI　　　　</p>
<p>３、GitHub地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/Tencent/FeatherCNN">https://github.com/Tencent/FeatherCNN</a></p>
<p>４、功能特点：</p>
<p><strong>FeatherCNN 是由腾讯 AI 平台部研发的基于 ARM 架构的高效 CNN 推理库，该项目支持 Caffe 模型，且具有高性能、易部署、轻量级三大特性。</strong></p>
<p><strong>该项目具体特性如下：</strong></p>
<ul>
<li><p>高性能：无论是在移动设备（iOS / Android），嵌入式设备（Linux）还是基于 ARM 的服务器（Linux）上，FeatherCNN 均能发挥最先进的推理计算性能；</p>
</li>
<li><p>易部署：FeatherCNN 的所有内容都包含在一个代码库中，以消除第三方依赖关系。因此，它便于在移动平台上部署。FeatherCNN 自身的模型格式与 Caffe 模型完全兼容。</p>
</li>
<li><p>轻量级：编译后的 FeatherCNN 库的体积仅为数百 KB。</p>
</li>
</ul>
<h3 id="17-10-8-TensorFlow-Lite"><a href="#17-10-8-TensorFlow-Lite" class="headerlink" title="17.10.8 TensorFlow Lite"></a>17.10.8 TensorFlow Lite</h3><p>１、开源时间：2017年11月　　　</p>
<p>２、开源用户：谷歌　　　</p>
<p>３、GitHub地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite</a></p>
<p>４、简介：</p>
<p>Google 表示 Lite 版本 TensorFlow 是 TensorFlow Mobile 的一个延伸版本。此前，通过TensorFlow Mobile API，TensorFlow已经支持手机上的模型嵌入式部署。TensorFlow Lite应该被视为TensorFlow Mobile的升级版。</p>
<p>TensorFlow Lite可以与Android 8.1中发布的神经网络API完美配合，即便在没有硬件加速时也能调用CPU处理，确保模型在不同设备上的运行。 而Android端版本演进的控制权是掌握在谷歌手中的，从长期看，TensorFlow Lite会得到Android系统层面上的支持。</p>
<p>5、架构：</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/tflite_artc.JPEG" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/tflite_artc.JPEG" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p>其组件包括：</p>
<ul>
<li>TensorFlow 模型（TensorFlow Model）：保存在磁盘中的训练模型。</li>
<li>TensorFlow Lite 转化器（TensorFlow Lite Converter）：将模型转换成 TensorFlow Lite 文件格式的项目。</li>
<li>TensorFlow Lite 模型文件（TensorFlow Lite Model File）：基于 FlatBuffers，适配最大速度和最小规模的模型。</li>
</ul>
<p>6、移动端开发步骤：</p>
<p>Android Studio 3.0, SDK Version API26, NDK Version 14</p>
<p>步骤：</p>
<ol>
<li><p>将此项目导入到Android Studio：<br> <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/java/demo">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/java/demo</a></p>
</li>
<li><p>下载移动端的模型（model）和标签数据（lables）：<br> <a target="_blank" rel="external nofollow noopener noreferrer" href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_224_android_quant_2017_11_08.zip">https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_224_android_quant_2017_11_08.zip</a></p>
</li>
<li><p>下载完成解压mobilenet_v1_224_android_quant_2017_11_08.zip文件得到一个xxx.tflite和labes.txt文件，分别是模型和标签文件，并且把这两个文件复制到assets文件夹下。</p>
</li>
<li><p>构建app，run……</p>
</li>
</ol>
<p>17.7.9 TensorFlow Lite和TensorFlow Mobile的区别？</p>
<ul>
<li>TensorFlow Lite是TensorFlow Mobile的进化版。</li>
<li>在大多数情况下，TensorFlow Lite拥有跟小的二进制大小，更少的依赖以及更好的性能。</li>
<li>相比TensorFlow Mobile是对完整TensorFlow的裁减，TensorFlow Lite基本就是重新实现了。从内部实现来说，在TensorFlow内核最基本的OP，Context等数据结构，都是新的。从外在表现来说，模型文件从PB格式改成了FlatBuffers格式，TensorFlow的size有大幅度优化，降至300K，然后提供一个converter将普通TensorFlow模型转化成TensorFlow Lite需要的格式。因此，无论从哪方面看，TensorFlow Lite都是一个新的实现方案。</li>
</ul>
<h3 id="17-10-9-PocketFlow"><a href="#17-10-9-PocketFlow" class="headerlink" title="17.10.9 PocketFlow"></a>17.10.9 PocketFlow</h3><p>１、开源时间：2018年9月　　　</p>
<p>２、开源用户：腾讯　　　</p>
<p>３、GitHub地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/Tencent/PocketFlow">https://github.com/Tencent/PocketFlow</a></p>
<p>４、简介：</p>
<p>全球首个自动模型压缩框架</p>
<p>一款面向移动端AI开发者的自动模型压缩框架，集成了当前主流的模型压缩与训练算法，结合自研超参数优化组件实现了全程自动化托管式的模型压缩与加速。开发者无需了解具体算法细节，即可快速地将AI技术部署到移动端产品上，实现了自动托管式模型压缩与加速，实现用户数据的本地高效处理。</p>
<p>5、框架介绍</p>
<p>PocketFlow 框架主要由两部分组件构成，分别是模型压缩/加速算法组件和超参数优化组件，具体结构如下图所示。</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/framework_design.png" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/framework_design.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p>​    开发者将未压缩的原始模型作为 PocketFlow 框架的输入，同时指定期望的性能指标，例如模型的压缩和/或加速倍数；在每一轮迭代过程中，超参数优化组件选取一组超参数取值组合，之后模型压缩/加速算法组件基于该超参数取值组合，对原始模型进行压缩，得到一个压缩后的候选模型；基于对候选模型进行性能评估的结果，超参数优化组件调整自身的模型参数，并选取一组新的超参数取值组合，以开始下一轮迭代过程；当迭代终止时，PocketFlow 选取最优的超参数取值组合以及对应的候选模型，作为最终输出，返回给开发者用作移动端的模型部署。</p>
<p>6、PocketFlow如何实现模型压缩与加速？</p>
<p>​    具体地，PocketFlow 通过下列各个算法组件的有效结合，实现了精度损失更小、自动化程度更高的深度学习模型的压缩与加速：</p>
<ul>
<li><p>a) 通道剪枝（channel pruning）组件：在CNN网络中，通过对特征图中的通道维度进行剪枝，可以同时降低模型大小和计算复杂度，并且压缩后的模型可以直接基于现有的深度学习框架进行部署。在CIFAR-10图像分类任务中，通过对  ResNet-56 模型进行通道剪枝，可以实现2.5倍加速下分类精度损失0.4%，3.3倍加速下精度损失0.7%。</p>
</li>
<li><p>b) 权重稀疏化（weight sparsification）组件：通过对网络权重引入稀疏性约束，可以大幅度降低网络权重中的非零元素个数；压缩后模型的网络权重可以以稀疏矩阵的形式进行存储和传输，从而实现模型压缩。对于  MobileNet 图像分类模型，在删去50%网络权重后，在 ImageNet 数据集上的 Top-1 分类精度损失仅为0.6%。</p>
</li>
<li><p>c) 权重量化（weight quantization）组件：通过对网络权重引入量化约束，可以降低用于表示每个网络权重所需的比特数；团队同时提供了对于均匀和非均匀两大类量化算法的支持，可以充分利用  ARM 和 FPGA 等设备的硬件优化，以提升移动端的计算效率，并为未来的神经网络芯片设计提供软件支持。以用于 ImageNet  图像分类任务的 ResNet-18 模型为例，在8比特定点量化下可以实现精度无损的4倍压缩。</p>
</li>
<li><p>d)网络蒸馏（network distillation）组件：对于上述各种模型压缩组件，通过将未压缩的原始模型的输出作为额外的监督信息，指导压缩后模型的训练，在压缩/加速倍数不变的前提下均可以获得0.5%-2.0%不等的精度提升。</p>
</li>
<li><p>e) 多GPU训练（multi-GPU training）组件：深度学习模型训练过程对计算资源要求较高，单个GPU难以在短时间内完成模型训练，因此团队提供了对于多机多卡分布式训练的全面支持，以加快使用者的开发流程。无论是基于  ImageNet 数据的Resnet-50图像分类模型还是基于 WMT14 数据的 Transformer  机器翻译模型，均可以在一个小时内训练完毕。[1] </p>
</li>
<li><p>f) 超参数优化（hyper-parameter optimization）组件：多数开发者对模型压缩算法往往不甚了解，但超参数取值对最终结果往往有着巨大的影响，因此团队引入了超参数优化组件，采用了包括强化学习等算法以及  AI Lab 自研的 AutoML  自动超参数优化框架来根据具体性能需求，确定最优超参数取值组合。例如，对于通道剪枝算法，超参数优化组件可以自动地根据原始模型中各层的冗余程度，对各层采用不同的剪枝比例，在保证满足模型整体压缩倍数的前提下，实现压缩后模型识别精度的最大化。</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/packflow1.jpg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/packflow1.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
</li>
</ul>
<p>7、PocketFlow 性能</p>
<p>​    通过引入超参数优化组件，不仅避免了高门槛、繁琐的人工调参工作，同时也使得  PocketFlow 在各个压缩算法上全面超过了人工调参的效果。以图像分类任务为例，在 CIFAR-10 和 ImageNet  等数据集上，PocketFlow 对 ResNet 和 MobileNet 等多种 CNN 网络结构进行有效的模型压缩与加速。</p>
<p>​    在  CIFAR-10 数据集上，PocketFlow 以 ResNet-56  作为基准模型进行通道剪枝，并加入了超参数优化和网络蒸馏等训练策略，实现了 2.5 倍加速下分类精度损失 0.4%，3.3 倍加速下精度损失  0.7%，且显著优于未压缩的 ResNet-44 模型； 在 ImageNet 数据集上，PocketFlow 可以对原本已经十分精简的  MobileNet 模型继续进行权重稀疏化，以更小的模型尺寸取得相似的分类精度；与 Inception-V1、ResNet-18  等模型相比，模型大小仅为后者的约 20~40%，但分类精度基本一致（甚至更高）。</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/packflow2.jpg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/packflow2.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/packflow3.jpg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/packflow3.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p>相比于费时费力的人工调参，PocketFlow 框架中的 AutoML 自动超参数优化组件仅需 10<br>余次迭代就能达到与人工调参类似的性能，在经过 100 次迭代后搜索得到的超参数组合可以降低约 0.6%<br>的精度损失；通过使用超参数优化组件自动地确定网络中各层权重的量化比特数，PocketFlow 在对用于 ImageNet 图像分类任务的<br>ResNet-18 模型进行压缩时，取得了一致性的性能提升；当平均量化比特数为 4 比特时，超参数优化组件的引入可以将分类精度从 63.6%<br>提升至 68.1%（原始模型的分类精度为 70.3%）。</p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/packflow4.jpg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/packflow4.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p><img src="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/packflow5.jpg" class="lazyload" data-srcset="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/ch17/packflow5.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt></p>
<p><strong>参考文献</strong></p>
<p>[1]  Zhuangwei Zhuang, Mingkui Tan, Bohan Zhuang, Jing Liu, Jiezhang Cao,  Qingyao Wu, Junzhou Huang, Jinhui Zhu,「Discrimination-aware Channel  Pruning for Deep Neural Networks”, In Proc. of the 32nd Annual  Conference on Neural Information Processing Systems, NIPS ‘18, Montreal,  Canada, December 2018.</p>
<p>[2] Jiaxiang  Wu, Weidong Huang, Junzhou Huang, Tong Zhang,「Error Compensated  Quantized SGD and its Applications to Large-scale Distributed  Optimization」, In Proc. of the 35th International Conference on Machine  Learning, ICML’18, Stockholm, Sweden, July 2018.</p>
<h3 id="17-10-10-其他几款支持移动端深度学习的开源框架"><a href="#17-10-10-其他几款支持移动端深度学习的开源框架" class="headerlink" title="17.10.10 其他几款支持移动端深度学习的开源框架"></a>17.10.10 其他几款支持移动端深度学习的开源框架</h3><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://blog.csdn.net/zchang81/article/details/74280019">https://blog.csdn.net/zchang81/article/details/74280019</a></p>
<h3 id="17-10-11-MDL、NCNN和-TFLite比较"><a href="#17-10-11-MDL、NCNN和-TFLite比较" class="headerlink" title="17.10.11 MDL、NCNN和 TFLite比较"></a>17.10.11 MDL、NCNN和 TFLite比较</h3><p>百度-MDL框架、腾讯-NCNN框架和谷歌TFLite框架比较。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">MDL</th>
<th style="text-align:center">NCNN</th>
<th style="text-align:center">TFLite</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">代码质量</td>
<td style="text-align:center">中</td>
<td style="text-align:center">高</td>
<td style="text-align:center">很高</td>
</tr>
<tr>
<td style="text-align:center">跨平台</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
</tr>
<tr>
<td style="text-align:center">支持caffe模型</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">×</td>
</tr>
<tr>
<td style="text-align:center">支持TensorFlow模型</td>
<td style="text-align:center">×</td>
<td style="text-align:center">×</td>
<td style="text-align:center">√</td>
</tr>
<tr>
<td style="text-align:center">CPU NEON指令优化</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
</tr>
<tr>
<td style="text-align:center">GPU加速</td>
<td style="text-align:center">√</td>
<td style="text-align:center">×</td>
<td style="text-align:center">×</td>
</tr>
</tbody>
</table>
</div>
<p>相同点：</p>
<ul>
<li>只含推理（inference）功能，使用的模型文件需要通过离线的方式训练得到。</li>
<li>最终生成的库尺寸较小，均小于500kB。</li>
<li>为了提升执行速度，都使用了ARM NEON指令进行加速。</li>
<li>跨平台，iOS和Android系统都支持。</li>
</ul>
<p>不同点：</p>
<ul>
<li>MDL和NCNN均是只支持Caffe框架生成的模型文件，而TfLite则毫无意外的只支持自家大哥TensorFlow框架生成的模型文件。</li>
<li>MDL支持利用iOS系统的Matal框架进行GPU加速，能够显著提升在iPhone上的运行速度，达到准实时的效果。而NCNN和TFLite还没有这个功能。</li>
</ul>
<h2 id="17-11-移动端开源框架部署"><a href="#17-11-移动端开源框架部署" class="headerlink" title="17.11 移动端开源框架部署"></a>17.11 移动端开源框架部署</h2><h3 id="17-8-1-以NCNN为例"><a href="#17-8-1-以NCNN为例" class="headerlink" title="17.8.1 以NCNN为例"></a>17.8.1 以NCNN为例</h3><p>部署步骤   </p>
<h3 id="17-8-2-以QNNPACK为例"><a href="#17-8-2-以QNNPACK为例" class="headerlink" title="17.8.2 以QNNPACK为例"></a>17.8.2 以QNNPACK为例</h3><p>部署步骤     </p>
<h3 id="17-8-4-在Android手机上使用MACE实现图像分类"><a href="#17-8-4-在Android手机上使用MACE实现图像分类" class="headerlink" title="17.8.4 在Android手机上使用MACE实现图像分类"></a>17.8.4 在Android手机上使用MACE实现图像分类</h3><h3 id="17-8-3-在Android手机上使用PaddleMobile实现图像分类"><a href="#17-8-3-在Android手机上使用PaddleMobile实现图像分类" class="headerlink" title="17.8.3 在Android手机上使用PaddleMobile实现图像分类"></a>17.8.3 在Android手机上使用PaddleMobile实现图像分类</h3><p><strong>编译paddle-mobile库</strong></p>
<p>1）编译Android能够使用的CPP库：编译Android的paddle-mobile库，可选择使用Docker编译和Ubuntu交叉编译，这里介绍使用Ubuntu交叉编译paddle-mobile库。</p>
<p><em>注</em>：在Android项目，Java代码调用CPP代码，CPP的函数需要遵循一定的命名规范，比如Java<em>包名</em>类名_对应的Java的方法名。</p>
<p>​    目前官方提供了5个可以给Java调用的函数，该代码在：paddle-mobile/src/jni/paddle_mobile_jni.cpp，如果想要让这些函数能够在自己的包名下的类调用，就要修改CPP的函数名称修改如下：</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">JNIEXPORT jboolean JNICALL <span class="title function_">Java_com_baidu_paddle_PML_load</span><span class="params">(JNIEnv *env, </span></span><br><span class="line"><span class="params">	jclass thiz,</span></span><br><span class="line"><span class="params">	jstring modelPath)</span> { </span><br><span class="line">		ANDROIDLOGI(<span class="string">"load invoked"</span>); </span><br><span class="line">		<span class="type">bool</span> <span class="variable">optimize</span> <span class="operator">=</span> <span class="literal">true</span>; </span><br><span class="line">		<span class="keyword">return</span> getPaddleMobileInstance()-&gt;Load(jstring2cppstring(env, modelPath), optimize); }</span><br></pre></td></tr></tbody></table></figure>
<p>​    笔者项目的包名为<code>com.example.paddlemobile1</code>，在这个包下有一个<code>ImageRecognition.java</code>的程序来对应这个CPP程序，那么修改<code>load</code>函数如下：</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">JNIEXPORT jboolean JNICALL <span class="title function_">Java_com_example_paddlemobile1_ImageRecognition_load</span><span class="params">(JNIEnv *env,</span></span><br><span class="line"><span class="params">                                                          jclass thiz,</span></span><br><span class="line"><span class="params">                                                          jstring modelPath)</span> {</span><br><span class="line">  ANDROIDLOGI(<span class="string">"load invoked"</span>);</span><br><span class="line">  <span class="type">bool</span> <span class="variable">optimize</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">return</span> getPaddleMobileInstance()-&gt;Load(jstring2cppstring(env, modelPath),</span><br><span class="line">                                         optimize);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><strong>使用Ubuntu交叉编译paddle-mobile库</strong></p>
<p>1、下载和解压NDK。</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://dl.google.com/android/repository/android-ndk-r17b-linux-x86_64.zip</span><br><span class="line">unzip android-ndk-r17b-linux-x86_64.zip</span><br></pre></td></tr></tbody></table></figure>
<p>2、设置NDK环境变量，目录是NDK的解压目录。</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export NDK_ROOT="/home/test/paddlepaddle/android-ndk-r17b"</span><br></pre></td></tr></tbody></table></figure>
<p>设置好之后，可以使用以下的命令查看配置情况。</p>
<pre><code>root@test:/home/test/paddlepaddle# echo $NDK_ROOT
/home/test/paddlepaddle/android-ndk-r17b
</code></pre><p>3、安装cmake，需要安装较高版本的，笔者的cmake版本是3.11.2。</p>
<p>下载cmake源码</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://cmake.org/files/v3.11/cmake-3.11.2.tar.gz</span><br></pre></td></tr></tbody></table></figure>
<p>解压cmake源码</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf cmake-3.11.2.tar.gz</span><br></pre></td></tr></tbody></table></figure>
<p>进入到cmake源码根目录，并执行bootstrap。</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd cmake-3.11.2</span><br><span class="line">./bootstrap</span><br></pre></td></tr></tbody></table></figure>
<p>最后执行以下两条命令开始安装cmake。</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></tbody></table></figure>
<p>安装完成之后，可以使用cmake —version是否安装成功.</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@test:/home/test/paddlepaddle# cmake --version</span><br><span class="line">cmake version 3.11.2</span><br><span class="line"></span><br><span class="line">CMake suite maintained and supported by Kitware (kitware.com/cmake).</span><br></pre></td></tr></tbody></table></figure>
<p>4、克隆paddle-mobile源码。</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/PaddlePaddle/paddle-mobile.git</span><br></pre></td></tr></tbody></table></figure>
<p>5、进入到paddle-mobile的tools目录下，执行编译。</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd paddle-mobile/tools/</span><br><span class="line">sh build.sh android</span><br></pre></td></tr></tbody></table></figure>
<p>（可选）如果想编译针对某一个网络编译更小的库时，可以在命令后面加上相应的参数，如下：</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh build.sh android googlenet</span><br></pre></td></tr></tbody></table></figure>
<p>6、最后会在paddle-mobile/build/release/arm-v7a/build目录下生产paddle-mobile库。</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root<span class="meta">@test</span>:/home/test/paddlepaddle/paddle-mobile/build/release/arm-v7a/build# ls</span><br><span class="line">libpaddle-mobile.so</span><br></pre></td></tr></tbody></table></figure>
<p>libpaddle-mobile.so就是我们在开发Android项目的时候使用到的paddle-mobile库。</p>
<p><strong>创建Android项目</strong></p>
<p>1、首先使用Android Studio创建一个普通的Android项目，包名为<code>com.example.paddlemobile1</code></p>
<p>2、在main目录下创建l两个assets/paddle_models文件夹，这个文件夹存放PaddleFluid训练好的预测模型。PaddleMobile支持量化模型，使用模型量化可以把模型缩小至原来的四分之一，如果使用量化模型，那加载模型的接口也有修改一下，使用以下的接口加载模型：</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="type">boolean</span> <span class="title function_">loadQualified</span><span class="params">(String modelDir)</span>;</span><br></pre></td></tr></tbody></table></figure>
<p>3、在<code>main</code>目录下创建一个<code>jniLibs</code>文件夹，这个文件夹是存放CPP编译库的，在本项目中就存放上一部分编译的<code>libpaddle-mobile.so</code></p>
<p>4、在Android项目的配置文件夹中加上权限声明，因为我们要使用到读取相册和使用相机，所以加上以下的权限声明：</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;uses-permission android:name=<span class="string">"android.permission.CAMERA"</span> /&gt;</span><br><span class="line">&lt;uses-permission android:name=<span class="string">"android.permission.WRITE_EXTERNAL_STORAGE"</span> /&gt;</span><br><span class="line">&lt;uses-permission android:name=<span class="string">"android.permission.READ_EXTERNAL_STORAGE"</span> /&gt;</span><br></pre></td></tr></tbody></table></figure>
<p>5、修改<code>activity_main.xml</code>界面，修改成如下：</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">"1.0"</span> encoding=<span class="string">"utf-8"</span>?&gt;</span><br><span class="line">&lt;RelativeLayout xmlns:android=<span class="string">"http://schemas.android.com/apk/res/android"</span></span><br><span class="line">    xmlns:app=<span class="string">"http://schemas.android.com/apk/res-auto"</span></span><br><span class="line">    xmlns:tools=<span class="string">"http://schemas.android.com/tools"</span></span><br><span class="line">    android:layout_width=<span class="string">"match_parent"</span></span><br><span class="line">    android:layout_height=<span class="string">"match_parent"</span></span><br><span class="line">    tools:context=<span class="string">".MainActivity"</span>&gt;</span><br><span class="line">&lt;LinearLayout</span><br><span class="line">    android:id=<span class="string">"@+id/btn_ll"</span></span><br><span class="line">    android:layout_alignParentBottom=<span class="string">"true"</span></span><br><span class="line">    android:layout_width=<span class="string">"match_parent"</span></span><br><span class="line">    android:layout_height=<span class="string">"wrap_content"</span></span><br><span class="line">    android:orientation=<span class="string">"horizontal"</span>&gt;</span><br><span class="line"></span><br><span class="line">    &lt;Button</span><br><span class="line">        android:id=<span class="string">"@+id/use_photo"</span></span><br><span class="line">        android:layout_weight=<span class="string">"1"</span></span><br><span class="line">        android:layout_width=<span class="string">"0dp"</span></span><br><span class="line">        android:layout_height=<span class="string">"wrap_content"</span></span><br><span class="line">        android:text=<span class="string">"相册"</span> /&gt;</span><br><span class="line"></span><br><span class="line">    &lt;Button</span><br><span class="line">        android:id=<span class="string">"@+id/start_camera"</span></span><br><span class="line">        android:layout_weight=<span class="string">"1"</span></span><br><span class="line">        android:layout_width=<span class="string">"0dp"</span></span><br><span class="line">        android:layout_height=<span class="string">"wrap_content"</span></span><br><span class="line">        android:text=<span class="string">"拍照"</span> /&gt;</span><br><span class="line">&lt;/LinearLayout&gt;</span><br><span class="line"></span><br><span class="line">&lt;TextView</span><br><span class="line">    android:layout_above=<span class="string">"@id/btn_ll"</span></span><br><span class="line">    android:id=<span class="string">"@+id/result_text"</span></span><br><span class="line">    android:textSize=<span class="string">"16sp"</span></span><br><span class="line">    android:layout_width=<span class="string">"match_parent"</span></span><br><span class="line">    android:hint=<span class="string">"预测结果会在这里显示"</span></span><br><span class="line">    android:layout_height=<span class="string">"100dp"</span> /&gt;</span><br><span class="line"></span><br><span class="line">&lt;ImageView</span><br><span class="line">    android:layout_alignParentTop=<span class="string">"true"</span></span><br><span class="line">    android:layout_above=<span class="string">"@id/result_text"</span></span><br><span class="line">    android:id=<span class="string">"@+id/show_image"</span></span><br><span class="line">    android:layout_width=<span class="string">"match_parent"</span></span><br><span class="line">    android:layout_height=<span class="string">"match_parent"</span> /&gt;</span><br><span class="line">&lt;/RelativeLayout&gt;</span><br></pre></td></tr></tbody></table></figure>
<p>6、创建一个<code>ImageRecognition.java</code>的Java程序，这个程序的作用就是调用<code>paddle-mobile/src/jni/paddle_mobile_jni.cpp</code>的函数，对应的是里面的函数。目前支持一下几个接口。</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.paddlemobile1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ImageRecognition</span> {</span><br><span class="line">    <span class="comment">// set thread num</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title function_">setThread</span><span class="params">(<span class="type">int</span> threadCount)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Load seperated parameters</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="type">boolean</span> <span class="title function_">load</span><span class="params">(String modelDir)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// load qualified model</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="type">boolean</span> <span class="title function_">loadQualified</span><span class="params">(String modelDir)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Load combined parameters</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="type">boolean</span> <span class="title function_">loadCombined</span><span class="params">(String modelPath, String paramPath)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// load qualified model</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="type">boolean</span> <span class="title function_">loadCombinedQualified</span><span class="params">(String modelPath, String paramPath)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// object detection</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="type">float</span>[] predictImage(<span class="type">float</span>[] buf, <span class="type">int</span>[]ddims);</span><br><span class="line"></span><br><span class="line"><span class="comment">// predict yuv image</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="type">float</span>[] predictYuv(<span class="type">byte</span>[] buf, <span class="type">int</span> imgWidth, <span class="type">int</span> imgHeight, <span class="type">int</span>[] ddims, <span class="type">float</span>[]meanValues);</span><br><span class="line"></span><br><span class="line"><span class="comment">// clear model</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title function_">clear</span><span class="params">()</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>7、然后编写一个<code>PhotoUtil.java</code>的工具类。</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.paddlemobile1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> android.app.Activity;</span><br><span class="line"><span class="keyword">import</span> android.content.Context;</span><br><span class="line"><span class="keyword">import</span> android.content.Intent;</span><br><span class="line"><span class="keyword">import</span> android.database.Cursor;</span><br><span class="line"><span class="keyword">import</span> android.graphics.Bitmap;</span><br><span class="line"><span class="keyword">import</span> android.graphics.BitmapFactory;</span><br><span class="line"><span class="keyword">import</span> android.net.Uri;</span><br><span class="line"><span class="keyword">import</span> android.os.Build;</span><br><span class="line"><span class="keyword">import</span> android.provider.MediaStore;</span><br><span class="line"><span class="keyword">import</span> android.support.v4.content.FileProvider;</span><br><span class="line"><span class="keyword">import</span> android.util.Log;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PhotoUtil</span> {</span><br><span class="line"><span class="comment">// start camera</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Uri <span class="title function_">start_camera</span><span class="params">(Activity activity, <span class="type">int</span> requestCode)</span> {</span><br><span class="line">    Uri imageUri;</span><br><span class="line">    <span class="comment">// save image in cache path</span></span><br><span class="line">    <span class="type">File</span> <span class="variable">outputImage</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(activity.getExternalCacheDir(), <span class="string">"out_image.jpg"</span>);</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        <span class="keyword">if</span> (outputImage.exists()) {</span><br><span class="line">            outputImage.delete();</span><br><span class="line">        }</span><br><span class="line">        outputImage.createNewFile();</span><br><span class="line">    } <span class="keyword">catch</span> (IOException e) {</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">if</span> (Build.VERSION.SDK_INT &gt;= <span class="number">24</span>) {</span><br><span class="line">        <span class="comment">// compatible with Android 7.0 or over</span></span><br><span class="line">        imageUri = FileProvider.getUriForFile(activity,</span><br><span class="line">                <span class="string">"com.example.paddlemobile1"</span>, outputImage);</span><br><span class="line">    } <span class="keyword">else</span> {</span><br><span class="line">        imageUri = Uri.fromFile(outputImage);</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// set system camera Action</span></span><br><span class="line">    <span class="type">Intent</span> <span class="variable">intent</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Intent</span>(MediaStore.ACTION_IMAGE_CAPTURE);</span><br><span class="line">    <span class="comment">// set save photo path</span></span><br><span class="line">    intent.putExtra(MediaStore.EXTRA_OUTPUT, imageUri);</span><br><span class="line">    <span class="comment">// set photo quality, min is 0, max is 1</span></span><br><span class="line">    intent.putExtra(MediaStore.EXTRA_VIDEO_QUALITY, <span class="number">0</span>);</span><br><span class="line">    activity.startActivityForResult(intent, requestCode);</span><br><span class="line">    <span class="keyword">return</span> imageUri;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// get picture in photo</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">use_photo</span><span class="params">(Activity activity, <span class="type">int</span> requestCode)</span>{</span><br><span class="line">    <span class="type">Intent</span> <span class="variable">intent</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Intent</span>(Intent.ACTION_PICK);</span><br><span class="line">    intent.setType(<span class="string">"image/*"</span>);</span><br><span class="line">    activity.startActivityForResult(intent, requestCode);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// get photo from Uri</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title function_">get_path_from_URI</span><span class="params">(Context context, Uri uri)</span> {</span><br><span class="line">    String result;</span><br><span class="line">    <span class="type">Cursor</span> <span class="variable">cursor</span> <span class="operator">=</span> context.getContentResolver().query(uri, <span class="literal">null</span>, <span class="literal">null</span>, <span class="literal">null</span>, <span class="literal">null</span>);</span><br><span class="line">    <span class="keyword">if</span> (cursor == <span class="literal">null</span>) {</span><br><span class="line">        result = uri.getPath();</span><br><span class="line">    } <span class="keyword">else</span> {</span><br><span class="line">        cursor.moveToFirst();</span><br><span class="line">        <span class="type">int</span> <span class="variable">idx</span> <span class="operator">=</span> cursor.getColumnIndex(MediaStore.Images.ImageColumns.DATA);</span><br><span class="line">        result = cursor.getString(idx);</span><br><span class="line">        cursor.close();</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// Compress the image to the size of the training image，and change RGB</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">float</span>[] getScaledMatrix(Bitmap bitmap, <span class="type">int</span> desWidth,</span><br><span class="line">                               <span class="type">int</span> desHeight) {</span><br><span class="line">    <span class="type">float</span>[] dataBuf = <span class="keyword">new</span> <span class="title class_">float</span>[<span class="number">3</span> * desWidth * desHeight];</span><br><span class="line">    <span class="type">int</span> rIndex;</span><br><span class="line">    <span class="type">int</span> gIndex;</span><br><span class="line">    <span class="type">int</span> bIndex;</span><br><span class="line">    <span class="type">int</span>[] pixels = <span class="keyword">new</span> <span class="title class_">int</span>[desWidth * desHeight];</span><br><span class="line">    <span class="type">Bitmap</span> <span class="variable">bm</span> <span class="operator">=</span> Bitmap.createScaledBitmap(bitmap, desWidth, desHeight, <span class="literal">false</span>);</span><br><span class="line">    bm.getPixels(pixels, <span class="number">0</span>, desWidth, <span class="number">0</span>, <span class="number">0</span>, desWidth, desHeight);</span><br><span class="line">    <span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> <span class="variable">k</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; pixels.length; i++) {</span><br><span class="line">        <span class="type">int</span> <span class="variable">clr</span> <span class="operator">=</span> pixels[i];</span><br><span class="line">        j = i / desHeight;</span><br><span class="line">        k = i % desWidth;</span><br><span class="line">        rIndex = j * desWidth + k;</span><br><span class="line">        gIndex = rIndex + desHeight * desWidth;</span><br><span class="line">        bIndex = gIndex + desHeight * desWidth;</span><br><span class="line">        dataBuf[rIndex] = (<span class="type">float</span>) ((clr &amp; <span class="number">0x00ff0000</span>) &gt;&gt; <span class="number">16</span>) - <span class="number">148</span>;</span><br><span class="line">        dataBuf[gIndex] = (<span class="type">float</span>) ((clr &amp; <span class="number">0x0000ff00</span>) &gt;&gt; <span class="number">8</span>) - <span class="number">148</span>;</span><br><span class="line">        dataBuf[bIndex] = (<span class="type">float</span>) ((clr &amp; <span class="number">0x000000ff</span>)) - <span class="number">148</span>;</span><br><span class="line"></span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">if</span> (bm.isRecycled()) {</span><br><span class="line">        bm.recycle();</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> dataBuf;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// compress picture</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Bitmap <span class="title function_">getScaleBitmap</span><span class="params">(String filePath)</span> {</span><br><span class="line">    BitmapFactory.<span class="type">Options</span> <span class="variable">opt</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BitmapFactory</span>.Options();</span><br><span class="line">    opt.inJustDecodeBounds = <span class="literal">true</span>;</span><br><span class="line">    BitmapFactory.decodeFile(filePath, opt);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> <span class="variable">bmpWidth</span> <span class="operator">=</span> opt.outWidth;</span><br><span class="line">    <span class="type">int</span> <span class="variable">bmpHeight</span> <span class="operator">=</span> opt.outHeight;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> <span class="variable">maxSize</span> <span class="operator">=</span> <span class="number">500</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// compress picture with inSampleSize</span></span><br><span class="line">    opt.inSampleSize = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) {</span><br><span class="line">        <span class="keyword">if</span> (bmpWidth / opt.inSampleSize &lt; maxSize || bmpHeight / opt.inSampleSize &lt; maxSize) {</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        }</span><br><span class="line">        opt.inSampleSize *= <span class="number">2</span>;</span><br><span class="line">    }</span><br><span class="line">    opt.inJustDecodeBounds = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">return</span> BitmapFactory.decodeFile(filePath, opt);</span><br><span class="line">}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>start_camera()方法是启动相机并返回图片的URI。</li>
<li>use_photo()方法是打开相册，获取到的图片URI在回到函数中获取。</li>
<li>get_path_from_URI()方法是把图片的URI转换成绝对路径。</li>
<li>getScaledMatrix()方法是把图片压缩成跟训练时的大小，并转换成预测需要用的数据格式浮点数组。</li>
<li>getScaleBitmap()方法是对图片进行等比例压缩，减少内存的支出。</li>
</ul>
<p>8、最后修改<code>MainActivity.java</code>，修改如下：</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.paddlemobile1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> android.Manifest;</span><br><span class="line"><span class="keyword">import</span> android.annotation.SuppressLint;</span><br><span class="line"><span class="keyword">import</span> android.app.Activity;</span><br><span class="line"><span class="keyword">import</span> android.content.Context;</span><br><span class="line"><span class="keyword">import</span> android.content.Intent;</span><br><span class="line"><span class="keyword">import</span> android.content.pm.PackageManager;</span><br><span class="line"><span class="keyword">import</span> android.graphics.Bitmap;</span><br><span class="line"><span class="keyword">import</span> android.net.Uri;</span><br><span class="line"><span class="keyword">import</span> android.os.Bundle;</span><br><span class="line"><span class="keyword">import</span> android.os.Environment;</span><br><span class="line"><span class="keyword">import</span> android.support.annotation.NonNull;</span><br><span class="line"><span class="keyword">import</span> android.support.annotation.Nullable;</span><br><span class="line"><span class="keyword">import</span> android.support.v4.app.ActivityCompat;</span><br><span class="line"><span class="keyword">import</span> android.support.v4.content.ContextCompat;</span><br><span class="line"><span class="keyword">import</span> android.support.v7.app.AppCompatActivity;</span><br><span class="line"><span class="keyword">import</span> android.util.Log;</span><br><span class="line"><span class="keyword">import</span> android.view.View;</span><br><span class="line"><span class="keyword">import</span> android.widget.Button;</span><br><span class="line"><span class="keyword">import</span> android.widget.ImageView;</span><br><span class="line"><span class="keyword">import</span> android.widget.TextView;</span><br><span class="line"><span class="keyword">import</span> android.widget.Toast;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.bumptech.glide.Glide;</span><br><span class="line"><span class="keyword">import</span> com.bumptech.glide.load.engine.DiskCacheStrategy;</span><br><span class="line"><span class="keyword">import</span> com.bumptech.glide.request.RequestOptions;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MainActivity</span> <span class="keyword">extends</span> <span class="title class_">AppCompatActivity</span> {</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">TAG</span> <span class="operator">=</span> MainActivity.class.getName();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">USE_PHOTO</span> <span class="operator">=</span> <span class="number">1001</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">START_CAMERA</span> <span class="operator">=</span> <span class="number">1002</span>;</span><br><span class="line">    <span class="keyword">private</span> Uri image_uri;</span><br><span class="line">    <span class="keyword">private</span> ImageView show_image;</span><br><span class="line">    <span class="keyword">private</span> TextView result_text;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">assets_path</span> <span class="operator">=</span> <span class="string">"paddle_models"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">boolean</span> <span class="variable">load_result</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span>[] ddims = {<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>};</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String[] PADDLE_MODEL = {</span><br><span class="line">        <span class="string">"lenet"</span>,</span><br><span class="line">        <span class="string">"alexnet"</span>,</span><br><span class="line">        <span class="string">"vgg16"</span>,</span><br><span class="line">        <span class="string">"resnet"</span>,</span><br><span class="line">        <span class="string">"googlenet"</span>,</span><br><span class="line">        <span class="string">"mobilenet_v1"</span>,</span><br><span class="line">        <span class="string">"mobilenet_v2"</span>,</span><br><span class="line">        <span class="string">"inception_v1"</span>,</span><br><span class="line">        <span class="string">"inception_v2"</span>,</span><br><span class="line">        <span class="string">"squeezenet"</span></span><br><span class="line">};</span><br><span class="line"></span><br><span class="line"><span class="comment">// load paddle-mobile api</span></span><br><span class="line"><span class="keyword">static</span> {</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        System.loadLibrary(<span class="string">"paddle-mobile"</span>);</span><br><span class="line"></span><br><span class="line">    } <span class="keyword">catch</span> (SecurityException e) {</span><br><span class="line">        e.printStackTrace();</span><br><span class="line"></span><br><span class="line">    } <span class="keyword">catch</span> (UnsatisfiedLinkError e) {</span><br><span class="line">        e.printStackTrace();</span><br><span class="line"></span><br><span class="line">    } <span class="keyword">catch</span> (NullPointerException e) {</span><br><span class="line">        e.printStackTrace();</span><br><span class="line"></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onCreate</span><span class="params">(Bundle savedInstanceState)</span> {</span><br><span class="line">    <span class="built_in">super</span>.onCreate(savedInstanceState);</span><br><span class="line">    setContentView(R.layout.activity_main);</span><br><span class="line"></span><br><span class="line">    init();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// initialize view</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> {</span><br><span class="line">    request_permissions();</span><br><span class="line">    show_image = (ImageView) findViewById(R.id.show_image);</span><br><span class="line">    result_text = (TextView) findViewById(R.id.result_text);</span><br><span class="line">    <span class="type">Button</span> <span class="variable">use_photo</span> <span class="operator">=</span> (Button) findViewById(R.id.use_photo);</span><br><span class="line">    <span class="type">Button</span> <span class="variable">start_photo</span> <span class="operator">=</span> (Button) findViewById(R.id.start_camera);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// use photo click</span></span><br><span class="line">    use_photo.setOnClickListener(<span class="keyword">new</span> <span class="title class_">View</span>.OnClickListener() {</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onClick</span><span class="params">(View view)</span> {</span><br><span class="line">            PhotoUtil.use_photo(MainActivity.<span class="built_in">this</span>, USE_PHOTO);</span><br><span class="line">            <span class="comment">//                load_model();</span></span><br><span class="line">            }</span><br><span class="line">        });</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">// start camera click</span></span><br><span class="line">    start_photo.setOnClickListener(<span class="keyword">new</span> <span class="title class_">View</span>.OnClickListener() {</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onClick</span><span class="params">(View view)</span> {</span><br><span class="line">            image_uri = PhotoUtil.start_camera(MainActivity.<span class="built_in">this</span>, START_CAMERA);</span><br><span class="line">        }</span><br><span class="line">    });</span><br><span class="line"></span><br><span class="line">    <span class="comment">// copy file from assets to sdcard</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">sdcard_path</span> <span class="operator">=</span> Environment.getExternalStorageDirectory()</span><br><span class="line">            + File.separator + assets_path;</span><br><span class="line">    copy_file_from_asset(<span class="built_in">this</span>, assets_path, sdcard_path);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// load model</span></span><br><span class="line">    load_model();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// load infer model</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">load_model</span><span class="params">()</span> {</span><br><span class="line">    <span class="type">String</span> <span class="variable">model_path</span> <span class="operator">=</span> Environment.getExternalStorageDirectory()</span><br><span class="line">            + File.separator + assets_path + File.separator + PADDLE_MODEL[<span class="number">4</span>];</span><br><span class="line">    Log.d(TAG, model_path);</span><br><span class="line">    load_result = ImageRecognition.load(model_path);</span><br><span class="line">    <span class="keyword">if</span> (load_result) {</span><br><span class="line">        Log.d(TAG, <span class="string">"model load success"</span>);</span><br><span class="line">    } <span class="keyword">else</span> {</span><br><span class="line">        Log.d(TAG, <span class="string">"model load fail"</span>);</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// clear infer model</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">clear_model</span><span class="params">()</span> {</span><br><span class="line">    ImageRecognition.clear();</span><br><span class="line">    Log.d(TAG, <span class="string">"model is clear"</span>);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// copy file from asset to sdcard</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">copy_file_from_asset</span><span class="params">(Context context, String oldPath, String newPath)</span> {</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        String[] fileNames = context.getAssets().list(oldPath);</span><br><span class="line">        <span class="keyword">if</span> (fileNames.length &gt; <span class="number">0</span>) {</span><br><span class="line">            <span class="comment">// directory</span></span><br><span class="line">            <span class="type">File</span> <span class="variable">file</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(newPath);</span><br><span class="line">            <span class="keyword">if</span> (!file.exists()) {</span><br><span class="line">                file.mkdirs();</span><br><span class="line">            }</span><br><span class="line">            <span class="comment">// copy recursivelyC</span></span><br><span class="line">            <span class="keyword">for</span> (String fileName : fileNames) {</span><br><span class="line">                copy_file_from_asset(context, oldPath + <span class="string">"/"</span> + fileName, newPath + <span class="string">"/"</span> + fileName);</span><br><span class="line">            }</span><br><span class="line">            Log.d(TAG, <span class="string">"copy files finish"</span>);</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            <span class="comment">// file</span></span><br><span class="line">            <span class="type">File</span> <span class="variable">file</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(newPath);</span><br><span class="line">            <span class="comment">// if file exists will never copy</span></span><br><span class="line">            <span class="keyword">if</span> (file.exists()) {</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            }</span><br><span class="line"></span><br><span class="line">            <span class="comment">// copy file to new path</span></span><br><span class="line">            <span class="type">InputStream</span> <span class="variable">is</span> <span class="operator">=</span> context.getAssets().open(oldPath);</span><br><span class="line">            <span class="type">FileOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(file);</span><br><span class="line">            <span class="type">byte</span>[] buffer = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">            <span class="type">int</span> byteCount;</span><br><span class="line">            <span class="keyword">while</span> ((byteCount = is.read(buffer)) != -<span class="number">1</span>) {</span><br><span class="line">                fos.write(buffer, <span class="number">0</span>, byteCount);</span><br><span class="line">            }</span><br><span class="line">            fos.flush();</span><br><span class="line">            is.close();</span><br><span class="line">            fos.close();</span><br><span class="line">        }</span><br><span class="line">    } <span class="keyword">catch</span> (Exception e) {</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onActivityResult</span><span class="params">(<span class="type">int</span> requestCode, <span class="type">int</span> resultCode, <span class="meta">@Nullable</span> Intent data)</span> {</span><br><span class="line">    String image_path;</span><br><span class="line">    <span class="type">RequestOptions</span> <span class="variable">options</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RequestOptions</span>().skipMemoryCache(<span class="literal">true</span>).diskCacheStrategy(DiskCacheStrategy.NONE);</span><br><span class="line">    <span class="keyword">if</span> (resultCode == Activity.RESULT_OK) {</span><br><span class="line">        <span class="keyword">switch</span> (requestCode) {</span><br><span class="line">            <span class="keyword">case</span> USE_PHOTO:</span><br><span class="line">                <span class="keyword">if</span> (data == <span class="literal">null</span>) {</span><br><span class="line">                    Log.w(TAG, <span class="string">"user photo data is null"</span>);</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                }</span><br><span class="line">                image_uri = data.getData();</span><br><span class="line">                Glide.with(MainActivity.<span class="built_in">this</span>).load(image_uri).apply(options).into(show_image);</span><br><span class="line">                <span class="comment">// get image path from uri</span></span><br><span class="line">                image_path = PhotoUtil.get_path_from_URI(MainActivity.<span class="built_in">this</span>, image_uri);</span><br><span class="line">                <span class="comment">// show result</span></span><br><span class="line">                result_text.setText(image_path);</span><br><span class="line">                <span class="comment">// predict image</span></span><br><span class="line">                predict_image(PhotoUtil.get_path_from_URI(MainActivity.<span class="built_in">this</span>, image_uri));</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> START_CAMERA:</span><br><span class="line">                <span class="comment">// show photo</span></span><br><span class="line">                Glide.with(MainActivity.<span class="built_in">this</span>).load(image_uri).apply(options).into(show_image);</span><br><span class="line">                <span class="comment">// get image path from uri</span></span><br><span class="line">                image_path = PhotoUtil.get_path_from_URI(MainActivity.<span class="built_in">this</span>, image_uri);</span><br><span class="line">                <span class="comment">// show result</span></span><br><span class="line">                result_text.setText(image_path);</span><br><span class="line">                <span class="comment">// predict image</span></span><br><span class="line">                predict_image(PhotoUtil.get_path_from_URI(MainActivity.<span class="built_in">this</span>, image_uri));</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="meta">@SuppressLint("SetTextI18n")</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">predict_image</span><span class="params">(String image_path)</span> {</span><br><span class="line">    <span class="comment">// picture to float array</span></span><br><span class="line">    <span class="type">Bitmap</span> <span class="variable">bmp</span> <span class="operator">=</span> PhotoUtil.getScaleBitmap(image_path);</span><br><span class="line">    <span class="type">float</span>[] inputData = PhotoUtil.getScaledMatrix(bmp, ddims[<span class="number">2</span>], ddims[<span class="number">3</span>]);</span><br><span class="line">    <span class="keyword">try</span> {</span><br><span class="line">        <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">        <span class="comment">// get predict result</span></span><br><span class="line">        <span class="type">float</span>[] result = ImageRecognition.predictImage(inputData, ddims);</span><br><span class="line">        Log.d(TAG, <span class="string">"origin predict result:"</span> + Arrays.toString(result));</span><br><span class="line">        <span class="type">long</span> <span class="variable">end</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">        <span class="type">long</span> <span class="variable">time</span> <span class="operator">=</span> end - start;</span><br><span class="line">        Log.d(<span class="string">"result length"</span>, String.valueOf(result.length));</span><br><span class="line">        <span class="comment">// show predict result and time</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">r</span> <span class="operator">=</span> get_max_result(result);</span><br><span class="line">        <span class="type">String</span> <span class="variable">show_text</span> <span class="operator">=</span> <span class="string">"result："</span> + r + <span class="string">"\nprobability："</span> + result[r] + <span class="string">"\ntime："</span> + time + <span class="string">"ms"</span>;</span><br><span class="line">        result_text.setText(show_text);</span><br><span class="line">    } <span class="keyword">catch</span> (Exception e) {</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="type">int</span> <span class="title function_">get_max_result</span><span class="params">(<span class="type">float</span>[] result)</span> {</span><br><span class="line">    <span class="type">float</span> <span class="variable">probability</span> <span class="operator">=</span> result[<span class="number">0</span>];</span><br><span class="line">    <span class="type">int</span> <span class="variable">r</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; result.length; i++) {</span><br><span class="line">        <span class="keyword">if</span> (probability &lt; result[i]) {</span><br><span class="line">            probability = result[i];</span><br><span class="line">            r = i;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> r;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// request permissions</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">request_permissions</span><span class="params">()</span> {</span><br><span class="line"></span><br><span class="line">    List&lt;String&gt; permissionList = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    <span class="keyword">if</span> (ContextCompat.checkSelfPermission(<span class="built_in">this</span>, Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED) {</span><br><span class="line">        permissionList.add(Manifest.permission.CAMERA);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ContextCompat.checkSelfPermission(<span class="built_in">this</span>, Manifest.permission.WRITE_EXTERNAL_STORAGE) != PackageManager.PERMISSION_GRANTED) {</span><br><span class="line">        permissionList.add(Manifest.permission.WRITE_EXTERNAL_STORAGE);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ContextCompat.checkSelfPermission(<span class="built_in">this</span>, Manifest.permission.READ_EXTERNAL_STORAGE) != PackageManager.PERMISSION_GRANTED) {</span><br><span class="line">        permissionList.add(Manifest.permission.READ_EXTERNAL_STORAGE);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if list is not empty will request permissions</span></span><br><span class="line">    <span class="keyword">if</span> (!permissionList.isEmpty()) {</span><br><span class="line">        ActivityCompat.requestPermissions(<span class="built_in">this</span>, permissionList.toArray(<span class="keyword">new</span> <span class="title class_">String</span>[permissionList.size()]), <span class="number">1</span>);</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onRequestPermissionsResult</span><span class="params">(<span class="type">int</span> requestCode, <span class="meta">@NonNull</span> String[] permissions, <span class="meta">@NonNull</span> <span class="type">int</span>[] grantResults)</span> {</span><br><span class="line">    <span class="built_in">super</span>.onRequestPermissionsResult(requestCode, permissions, grantResults);</span><br><span class="line">    <span class="keyword">switch</span> (requestCode) {</span><br><span class="line">        <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">if</span> (grantResults.length &gt; <span class="number">0</span>) {</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; grantResults.length; i++) {</span><br><span class="line"></span><br><span class="line">                    <span class="type">int</span> <span class="variable">grantResult</span> <span class="operator">=</span> grantResults[i];</span><br><span class="line">                    <span class="keyword">if</span> (grantResult == PackageManager.PERMISSION_DENIED) {</span><br><span class="line">                        <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> permissions[i];</span><br><span class="line">                        Toast.makeText(<span class="built_in">this</span>, s + <span class="string">" permission was denied"</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">                    }</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onDestroy</span><span class="params">()</span> {</span><br><span class="line">    <span class="comment">// clear model before destroy app</span></span><br><span class="line">    clear_model();</span><br><span class="line">    <span class="built_in">super</span>.onDestroy();</span><br><span class="line">}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>load_model()方法是加载预测模型的。</li>
<li>clear_model()方法是清空预测模型的。</li>
<li>copy_file_from_asset()方法是把预测模型复制到内存卡上。</li>
<li>predict_image()方法是预测图片的。</li>
<li>get_max_result()方法是获取概率最大的预测结果。</li>
<li>request_permissions()方法是动态请求权限的。</li>
</ul>
<p>因为使用到图像加载框架Glide，所以要在<code>build.gradle</code>加入以下的引用。</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">implementation 'com.github.bumptech.glide:glide:4.3.1'</span><br></pre></td></tr></tbody></table></figure>
<p>8、最后运行项目，选择图片预测就会得到结果。</p>
<h2 id="17-9-移动端开源框架部署疑难"><a href="#17-9-移动端开源框架部署疑难" class="headerlink" title="17.9 移动端开源框架部署疑难"></a>17.9 移动端开源框架部署疑难</h2><p>增加常见的几个问题</p>
<p>知识蒸馏（Distillation）相关论文阅读（1）——Distilling the Knowledge in a Neural Network（以及代码复现）</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2>
  </div>
  
  
    
    <div class="footer">
       <!-- 参考资料、相关资料等 -->
      
       <!-- 相关文章 -->
      
      <!-- 版权声明组件 -->
      
      <!-- 打赏组件 -->
      
        <div class="donate">
        <iframe src="https://pistachio0812.github.io/donate/drinks" style="overflow-x:hidden;overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe>
        </div>
      
    </div>
  
  
    


  <div class="article-meta" id="bottom">
    <div class="new-meta-box">
      
        
          <div class="new-meta-item date" itemprop="dateModified" datetime="2024-04-08T16:57:59+08:00">
  <a class="notlink">
    <i class="fa-solid fa-edit fa-fw" aria-hidden="true"></i>
    <p>更新于：2024年4月8日</p>
  </a>
</div>

        
      
        
          

        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title rel="external nofollow noopener noreferrer" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://pistachio0812.github.io/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/&title=模型压缩及移动端部署 - 阿月浑子-Hexo博客&summary=">
          
            <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/qq.png" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/qq.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title rel="external nofollow noopener noreferrer" target="_blank" href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://pistachio0812.github.io/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/&title=模型压缩及移动端部署 - 阿月浑子-Hexo博客&summary=">
          
            <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/qzone.png" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/qzone.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title rel="external nofollow noopener noreferrer" target="_blank" href="http://service.weibo.com/share/share.php?url=http://pistachio0812.github.io/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/&title=模型压缩及移动端部署 - 阿月浑子-Hexo博客&summary=">
          
            <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/weibo.png" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/weibo.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
          
        </a>
      
    
      
        
        <div class="hoverbox">
          <a class="share"><img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/wechat.png" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/wechat.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a>
          <div class="target">
            <img src="data:image/png;base64,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">
          </div>
        </div>
      
    
      
    
  </div>
</div>



        
      
    </div>
    <!-- Custom Files bottomMeta begin -->
    
    <!-- Custom Files bottomMeta end -->
  </div>


  
  

  
    <div class="prev-next">
      
      
        <a class="next" href="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/NCNN%E9%83%A8%E7%BD%B2/">
          <p class="title">NCNN部署<i class="fa-solid fa-chevron-right" aria-hidden="true"></i></p>
          <p class="content">NCNN部署1.在电脑端使用ncnn实现分类(alexnet)s1，安装g++，cmake，protobuf，opencv
s2，对源码进行编译
123456git clone https://...</p>
        </a>
      
    </div>
  
  <!-- Custom Files postEnd begin-->
  
  <!-- Custom Files postEnd end-->
</article>


  


  <article class="post white-box shadow" id="comments">
    <span hidden>
      <meta itemprop="discussionUrl" content="/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/index.html#comments">
    </span>
    <p ct><i class="fa-solid fa-comments"></i> 评论</p>
    

    <div id="layoutHelper-comments"></div>

  </article>






</div>
<aside id="l_side" itemscope itemtype="http://schema.org/WPSideBar">
  

  
    
    
      
    
  


<div class="widget-sticky pjax">

  
  


  <section class="widget toc-wrapper desktop mobile " id="toc-div">
    
  <header>
    
      <i class="fa-solid fa-list fa-fw" aria-hidden="true"></i><span class="name">本文目录</span>
    
  </header>


    <div class="content">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#17-1-%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%90%86%E8%A7%A3"><span class="toc-text">17.1 模型压缩理解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-2-%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E5%92%8C%E5%8A%A0%E9%80%9F%EF%BC%9F"><span class="toc-text">17.2 为什么需要模型压缩和加速？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-3-%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7%E5%8F%8A%E5%8F%AF%E8%A1%8C%E6%80%A7"><span class="toc-text">17.3 模型压缩的必要性及可行性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-4-%E7%9B%AE%E5%89%8D%E6%9C%89%E5%93%AA%E4%BA%9B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%EF%BC%9F"><span class="toc-text">17.4 目前有哪些深度学习模型压缩方法？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#17-4-1-%E5%89%8D%E7%AB%AF%E5%8E%8B%E7%BC%A9%E5%92%8C%E5%90%8E%E7%AB%AF%E5%8E%8B%E7%BC%A9%E5%AF%B9%E6%AF%94"><span class="toc-text">17.4.1 前端压缩和后端压缩对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-4-2-%E7%BD%91%E7%BB%9C%E5%89%AA%E6%9E%9D"><span class="toc-text">17.4.2 网络剪枝</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-4-3-%E5%85%B8%E5%9E%8B%E5%89%AA%E6%9E%9D%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94"><span class="toc-text">17.4.3 典型剪枝方法对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-4-4-%E7%BD%91%E7%BB%9C%E8%92%B8%E9%A6%8F"><span class="toc-text">17.4.4 网络蒸馏</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-4-5-%E5%89%8D%E7%AB%AF%E5%8E%8B%E7%BC%A9"><span class="toc-text">17.4.5 前端压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-4-6-%E5%90%8E%E7%AB%AF%E5%8E%8B%E7%BC%A9"><span class="toc-text">17.4.6 后端压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-4-6-%E4%BD%8E%E7%A7%A9%E5%88%86%E8%A7%A3"><span class="toc-text">17.4.6 低秩分解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-4-7-%E6%80%BB%E4%BD%93%E5%8E%8B%E7%BC%A9%E6%95%88%E6%9E%9C%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-text">17.4.7 总体压缩效果评价指标有哪些？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-4-8-%E5%87%A0%E7%A7%8D%E8%BD%BB%E9%87%8F%E5%8C%96%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%AF%B9%E6%AF%94"><span class="toc-text">17.4.8 几种轻量化网络结构对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-4-9-%E7%BD%91%E7%BB%9C%E5%8E%8B%E7%BC%A9%E6%9C%AA%E6%9D%A5%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-text">17.4.9 网络压缩未来研究方向有哪些？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-5-%E7%9B%AE%E5%89%8D%E6%9C%89%E5%93%AA%E4%BA%9B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E5%8A%A0%E9%80%9F%E6%96%B9%E6%B3%95%EF%BC%9F"><span class="toc-text">17.5 目前有哪些深度学习模型优化加速方法？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#17-5-1-%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E5%8A%A0%E9%80%9F%E6%96%B9%E6%B3%95"><span class="toc-text">17.5.1 模型优化加速方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-5-2-TensorRT%E5%8A%A0%E9%80%9F%E5%8E%9F%E7%90%86"><span class="toc-text">17.5.2 TensorRT加速原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-5-3-TensorRT%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%E9%87%8D%E6%9E%84%E6%A8%A1%E5%9E%8B%EF%BC%9F"><span class="toc-text">17.5.3 TensorRT如何优化重构模型？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-5-4-TensorRT%E5%8A%A0%E9%80%9F%E6%95%88%E6%9E%9C%E5%A6%82%E4%BD%95%EF%BC%9F"><span class="toc-text">17.5.4 TensorRT加速效果如何？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-6-%E5%BD%B1%E5%93%8D%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%80%9F%E5%BA%A6%E7%9A%844%E4%B8%AA%E5%9B%A0%E7%B4%A0%EF%BC%88%E5%86%8D%E7%A8%8D%E5%BE%AE%E8%AF%A6%E7%BB%86%E4%B8%80%E7%82%B9%EF%BC%89"><span class="toc-text">17.6 影响神经网络速度的4个因素（再稍微详细一点）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-7-%E5%8E%8B%E7%BC%A9%E5%92%8C%E5%8A%A0%E9%80%9F%E6%96%B9%E6%B3%95%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%EF%BC%9F"><span class="toc-text">17.7 压缩和加速方法如何选择？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-8-%E6%94%B9%E5%8F%98%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E5%AE%9E%E7%8E%B0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%EF%BC%9F"><span class="toc-text">17.8 改变网络结构设计为什么会实现模型压缩、加速？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#17-8-1-Group-convolution"><span class="toc-text">17.8.1 Group convolution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-8-2-Depthwise-separable-convolution"><span class="toc-text">17.8.2. Depthwise separable convolution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-8-3-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%9A%84channel%E7%9B%B8%E5%90%8C%E6%97%B6%EF%BC%8CMAC%E6%9C%80%E5%B0%8F"><span class="toc-text">17.8.3 输入输出的channel相同时，MAC最小</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-8-4-%E5%87%8F%E5%B0%91%E7%BB%84%E5%8D%B7%E7%A7%AF%E7%9A%84%E6%95%B0%E9%87%8F"><span class="toc-text">17.8.4 减少组卷积的数量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-8-5-%E5%87%8F%E5%B0%91%E7%BD%91%E7%BB%9C%E7%A2%8E%E7%89%87%E5%8C%96%E7%A8%8B%E5%BA%A6-%E5%88%86%E6%94%AF%E6%95%B0%E9%87%8F"><span class="toc-text">17.8.5 减少网络碎片化程度(分支数量)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-8-7-%E5%87%8F%E5%B0%91%E5%85%83%E7%B4%A0%E7%BA%A7%E6%93%8D%E4%BD%9C"><span class="toc-text">17.8.7 减少元素级操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-9-%E5%B8%B8%E7%94%A8%E7%9A%84%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%BD%91%E7%BB%9C%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-text">17.9 常用的轻量级网络有哪些？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#17-9-1-SequeezeNet"><span class="toc-text">17.9.1 SequeezeNet</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3"><span class="toc-text">1.1 设计思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="toc-text">1.2 网络架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-text">1.3实验结果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-9-2-MobileNet"><span class="toc-text">17.9.2 MobileNet</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3"><span class="toc-text">2.1 设计思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="toc-text">2.2 网络架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-text">2.3 实验结果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-9-3-MobileNet-v2"><span class="toc-text">17.9.3 MobileNet-v2</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3"><span class="toc-text">3.1 设计思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="toc-text">3.2 网络架构</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-9-4-Xception"><span class="toc-text">17.9.4 Xception</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3"><span class="toc-text">4.1设计思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="toc-text">4.2网络架构</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-9-5-ShuffleNet-v1"><span class="toc-text">17.9.5 ShuffleNet-v1</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3"><span class="toc-text">5.1 设计思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="toc-text">5.2 网络架构</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-9-6-ShuffleNet-v2"><span class="toc-text">17.9.6 ShuffleNet-v2</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#6-1-%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3"><span class="toc-text">6.1 设计思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-2-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-text">6.2 网络结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-4-ShuffleNet-v2%E5%85%B7%E6%9C%89%E9%AB%98%E7%B2%BE%E5%BA%A6%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="toc-text">6.4  ShuffleNet-v2具有高精度的原因</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-10-%E7%8E%B0%E6%9C%89%E7%A7%BB%E5%8A%A8%E7%AB%AF%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6%E5%8F%8A%E5%85%B6%E7%89%B9%E7%82%B9"><span class="toc-text">17.10 现有移动端开源框架及其特点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#17-10-1-NCNN"><span class="toc-text">17.10.1 NCNN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-10-2-QNNPACK"><span class="toc-text">17.10.2 QNNPACK</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-10-3-Prestissimo"><span class="toc-text">17.10.3 Prestissimo</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-10-4-MDL%EF%BC%88mobile-deep-learning%EF%BC%89"><span class="toc-text">17.10.4 MDL（mobile-deep-learning）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-10-5-Paddle-Mobile"><span class="toc-text">17.10.5 Paddle-Mobile</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-10-6-MACE%EF%BC%88-Mobile-AI-Compute-Engine%EF%BC%89"><span class="toc-text">17.10.6 MACE（ Mobile AI Compute Engine）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-10-7-FeatherCNN"><span class="toc-text">17.10.7 FeatherCNN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-10-8-TensorFlow-Lite"><span class="toc-text">17.10.8 TensorFlow Lite</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-10-9-PocketFlow"><span class="toc-text">17.10.9 PocketFlow</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-10-10-%E5%85%B6%E4%BB%96%E5%87%A0%E6%AC%BE%E6%94%AF%E6%8C%81%E7%A7%BB%E5%8A%A8%E7%AB%AF%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6"><span class="toc-text">17.10.10 其他几款支持移动端深度学习的开源框架</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-10-11-MDL%E3%80%81NCNN%E5%92%8C-TFLite%E6%AF%94%E8%BE%83"><span class="toc-text">17.10.11 MDL、NCNN和 TFLite比较</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-11-%E7%A7%BB%E5%8A%A8%E7%AB%AF%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6%E9%83%A8%E7%BD%B2"><span class="toc-text">17.11 移动端开源框架部署</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#17-8-1-%E4%BB%A5NCNN%E4%B8%BA%E4%BE%8B"><span class="toc-text">17.8.1 以NCNN为例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-8-2-%E4%BB%A5QNNPACK%E4%B8%BA%E4%BE%8B"><span class="toc-text">17.8.2 以QNNPACK为例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-8-4-%E5%9C%A8Android%E6%89%8B%E6%9C%BA%E4%B8%8A%E4%BD%BF%E7%94%A8MACE%E5%AE%9E%E7%8E%B0%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB"><span class="toc-text">17.8.4 在Android手机上使用MACE实现图像分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-8-3-%E5%9C%A8Android%E6%89%8B%E6%9C%BA%E4%B8%8A%E4%BD%BF%E7%94%A8PaddleMobile%E5%AE%9E%E7%8E%B0%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB"><span class="toc-text">17.8.3 在Android手机上使用PaddleMobile实现图像分类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-9-%E7%A7%BB%E5%8A%A8%E7%AB%AF%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6%E9%83%A8%E7%BD%B2%E7%96%91%E9%9A%BE"><span class="toc-text">17.9 移动端开源框架部署疑难</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-text">参考文献</span></a></li></ol>
    </div>
  </section>

  

</div>


<!-- 没有 pjax 占位会报错 万恶的 pjax -->

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <!-- Custom Files side begin -->
  
  <!-- Custom Files side end -->
</aside>



          <!--此文件用来存放一些不方便取值的变量-->
<!--思路大概是将值藏到重加载的区域内-->

<pjax>
<script>
  window.pdata={}
  pdata.ispage=true;
  pdata.commentPath="";
  pdata.commentPlaceholder="";
  pdata.commentConfig={};
  //  see: /layout/_partial/scripts/_ctrl/coverCtrl.ejs
  
    // header
    var l_header=document.getElementById("l_header");
    
    l_header.classList.add("show");
    
    
      // cover
      var cover_wrapper=document.querySelector('#l_cover .cover-wrapper');
      var scroll_down=document.getElementById('scroll-down');
      cover_wrapper.id="none";
      cover_wrapper.style.display="none";
      scroll_down.style.display="none";
    
  
</script>
</pjax>
        </div>
        
  
  <footer class="footer clearfix" itemscope itemtype="http://schema.org/WPFooter">
    <br><br>
    
      
        <div class="aplayer-container">
          

  
    <meting-js theme="#1BCDFC" autoplay="false" volume="0.7" loop="all" order="list" fixed="false" list-max-height="320px" server="tencent" type="playlist" id="2185397204" list-folded="true">
    </meting-js>
  


        </div>
      
    
      
        <br>
        <div class="social-wrapper" itemprop="about" itemscope itemtype="http://schema.org/Thing">
          
            
              <a href="/atom.xml" class="social fas fa-rss flat-btn" target="_blank" rel="external nofollow noopener noreferrer" itemprop="url">
                
              </a>
            
          
            
              <a href="mailto:2395856915@qq.com" class="social fas fa-envelope flat-btn" target="_blank" rel="external nofollow noopener noreferrer" itemprop="url">
                
              </a>
            
          
            
              <a href="https://github.com/pistachio0812" class="social fab fa-github flat-btn" target="_blank" rel="external nofollow noopener noreferrer" itemprop="url">
                
              </a>
            
          
            
          
            
          
        </div>
      
    
      
        <div><p>博客内容遵循 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
      
    
      
        本站使用
        <a href="https://github.com/volantis-x/hexo-theme-volantis/#7.6.2" target="_blank" class="codename" rel="external nofollow noopener noreferrer">Volantis</a>
        作为主题
      
    
      
        <div class="copyright">
        <p><a href="/">Copyright ©2020-2023江西理工大学.All Rights Reserved</a></p>

        </div>
      
    
    <!-- Custom Files footer begin-->
    
    <!-- Custom Files footer end-->
  </footer>


        <a id="s-top" class="fa-solid fa-arrow-up fa-fw" href="/" onclick="return false;" title="top"></a>
      </div>
    </div>
    <div>
      <script>
  /******************** volantis.dom ********************************/
  // 页面选择器 将dom对象缓存起来 see: /source/js/app.js etc.
  volantis.dom.bodyAnchor = volantis.dom.$(document.getElementById("safearea")); // 页面主体
  volantis.dom.topBtn = volantis.dom.$(document.getElementById('s-top')); // 向上
  volantis.dom.wrapper = volantis.dom.$(document.getElementById('wrapper')); // 整个导航栏
  volantis.dom.coverAnchor = volantis.dom.$(document.querySelector('#l_cover .cover-wrapper')); // 1个
  volantis.dom.switcher = volantis.dom.$(document.querySelector('#l_header .switcher .s-search')); // 搜索按钮   移动端 1个
  volantis.dom.header = volantis.dom.$(document.getElementById('l_header')); // 移动端导航栏
  volantis.dom.search = volantis.dom.$(document.querySelector('#l_header .m_search')); // 搜索框 桌面端 移动端 1个
  volantis.dom.mPhoneList = volantis.dom.$(document.querySelectorAll('#l_header .m-phone .list-v')); //  手机端 子菜单 多个
</script>

<script>
  
  volantis.css("https://unpkg.com/volantis-static@0.0.1654736714924/libs/@fortawesome/fontawesome-free/css/all.min.css");
  
  
  volantis.css("https://unpkg.com/volantis-static@0.0.1654736714924/libs/font-awesome-animation/font-awesome-animation.min.css");
  
  
  volantis.css("https://unpkg.com/volantis-static@0.0.1654736714924/libs/node-waves/dist/waves.min.css");
  
</script>

<!-- required -->


<!-- internal -->

<script src="/js/app.js"></script>





  













<div id="rightmenu-wrapper">
  <ul class="list-v rightmenu" id="rightmenu-content">
    
  <li class="navigation menuNavigation-Content">


    <a class="nav icon-only fix-cursor-default" onclick="history.back()"><i class="fa-solid fa-arrow-left fa-fw"></i></a>



    <a class="nav icon-only fix-cursor-default" onclick="history.forward()"><i class="fa-solid fa-arrow-right fa-fw"></i></a>



    <a class="nav icon-only fix-cursor-default" onclick="window.location.reload()"><i class="fa-solid fa-redo fa-fw"></i></a>



    <a class="nav icon-only fix-cursor-default" onclick="VolantisApp.scrolltoElement(volantis.dom.bodyAnchor)"><i class="fa-solid fa-arrow-up fa-fw"></i></a>


  </li>


    <hr class="menuLoad-Content">



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="prev" data-event="volantis.rightmenu.jump('prev')" data-group="prevNext">
      <i class="fa-solid fa-angles-left fa-fw"></i>
      查看上一篇
    </span>
  </li>



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="next" data-event="volantis.rightmenu.jump('next')" data-group="prevNext">
      <i class="fa-solid fa-angles-right fa-fw"></i>
      查看下一篇
    </span>
  </li>



    <hr class="menuLoad-Content">



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="copyPaste" data-event="copyPaste" data-group="inputBox">
      <i class="fa-solid fa-paste fa-fw"></i>
      粘贴文本
    </span>
  </li>



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="copyAll" data-event="copyAll" data-group="inputBox">
      <i class="fa-solid fa-object-ungroup fa-fw"></i>
      全选文本
    </span>
  </li>



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="copyCut" data-event="copyCut" data-group="inputBox">
      <i class="fa-solid fa-cut fa-fw"></i>
      剪切文本
    </span>
  </li>



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="copyText" data-event="copyText" data-group="seletctText">
      <i class="fa-solid fa-copy fa-fw"></i>
      复制文本
    </span>
  </li>



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="searchWord" data-event="OpenSearch(__text__)" data-group="seletctText">
      <i class="fa-solid fa-search fa-fw"></i>
      站内搜索
    </span>
  </li>



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="bingSearch" data-event="window.open(`https://cn.bing.com/search?q=${__text__}`)" data-group="seletctText">
      <i class="fa-solid fa-search fa-fw"></i>
      必应搜索
    </span>
  </li>



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="openTab" data-event="window.open(__link__)" data-group="elementCheck">
      <i class="fa-solid fa-external-link-square-alt fa-fw"></i>
      新标签页打开
    </span>
  </li>



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="copyLink" data-event="copyLink" data-group="elementCheck">
      <i class="fa-solid fa-link fa-fw"></i>
      复制链接地址
    </span>
  </li>



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="copyImg" data-event="copyImg" data-group="elementImage">
      <i class="fa-solid fa-image fa-fw"></i>
      复制图片
    </span>
  </li>



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="googleImg" data-event="window.open(`https://www.google.com.hk/searchbyimage?image_url=${__link__}`)" data-group="elementImage">
      <i class="fa-solid fa-images fa-fw"></i>
      谷歌识图
    </span>
  </li>



  <li class="menuLoad-Content">
    <a class="vlts-menu fix-cursor-default" id="help" target="_blank" rel="external nofollow noopener noreferrer" href="https://volantis.js.org/faqs/" data-group="link">
      <i class="fa-solid fa-question fa-fw"></i>
      常见问题
    </a>
  </li>



  <li class="menuLoad-Content">
    <a class="vlts-menu fix-cursor-default" id="examples" target="_blank" rel="external nofollow noopener noreferrer" href="https://volantis.js.org/examples/" data-group="link">
      <i class="fa-solid fa-rss fa-fw"></i>
      示例博客
    </a>
  </li>



  <li class="menuLoad-Content">
    <a class="vlts-menu fix-cursor-default" id="contributors" target="_blank" rel="external nofollow noopener noreferrer" href="https://volantis.js.org/contributors/" data-group="link">
      <i class="fa-solid fa-fan fa-fw"></i>
      加入社区
    </a>
  </li>



    <hr class="menuLoad-Content">



  <li class="menuLoad-Content">
    <a class="vlts-menu fix-cursor-default" id="source_docs" target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/volantis-x/volantis-docs/" data-group="link">
      <i class="fa-solid fa-code-branch fa-fw"></i>
      本站源码
    </a>
  </li>



  <li class="menuLoad-Content">
    <a class="vlts-menu fix-cursor-default" id="source_theme" target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/volantis-x/hexo-theme-volantis/" data-group="link">
      <i class="fa-solid fa-code-branch fa-fw"></i>
      主题源码
    </a>
  </li>



    <hr class="menuLoad-Content">



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="darkMode" data-event="volantis.dark.toggle()" data-group="darkMode">
      <i class="fa-solid fa-moon fa-fw"></i>
      暗黑模式
    </span>
  </li>



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="printMode" data-event="printMode" data-group="articlePage">
      <i class="fa-solid fa-print fa-fw"></i>
      打印页面
    </span>
  </li>



  <li class="menuLoad-Content">
    <span class="vlts-menu fix-cursor-default event" id="readMode" data-event="readMode" data-group="articlePage">
      <i class="fa-solid fa-book-open fa-fw"></i>
      阅读模式
    </span>
  </li>


<div id="menuMusic">
  <li class="music name menuOption-Content">
    <p class="nav music-title fix-cursor-default"></p>
  </li>
  <li class="music ctrl">
    <a class="nav icon-only backward fix-cursor-default" href="/" onclick="return false;" title="backward">
      <i class="fa-solid fa-step-backward fa-fw"></i>
    </a>
    <a class="nav icon-only toggle fix-cursor-default" href="/" onclick="return false;" title="toggle">
      <i class="fa-solid fa-play fa-fw"></i>
    </a>
    <a class="nav icon-only forward fix-cursor-default" href="/" onclick="return false;" title="forward">
      <i class="fa-solid fa-step-forward fa-fw"></i>
    </a>
  </li>
  <li class="music volume">
    <div class="nav volume">
      <div class="aplayer-volume-bar-wrap">
        <div class="aplayer-volume-bar fix-cursor-pointer">
          <div class="aplayer-volume"></div>
          <i class="left fa-solid fa-volume-off fa-fw"></i>
          <i class="right fa-solid fa-volume-up fa-fw"></i>
        </div>
      </div>
    </div>
  </li>
</div>

  </ul>
</div>
<script src="/js/plugins/rightMenus.js"></script>
<script>
  const RightMenusFunction = {};
  












  RightMenusFunction['prev'] = () => {volantis.rightmenu.jump('prev')}





  RightMenusFunction['next'] = () => {volantis.rightmenu.jump('next')}







  //RightMenusFunction['copyPaste'] = (fun) => {fun()}





  //RightMenusFunction['copyAll'] = (fun) => {fun()}





  //RightMenusFunction['copyCut'] = (fun) => {fun()}





  //RightMenusFunction['copyText'] = (fun) => {fun()}





  RightMenusFunction['searchWord'] = (__text__) => {OpenSearch(__text__)}





  RightMenusFunction['bingSearch'] = (__text__) => {window.open(`https://cn.bing.com/search?q=${__text__}`)}





  RightMenusFunction['openTab'] = (__link__) => {window.open(__link__)}





  //RightMenusFunction['copyLink'] = (fun) => {fun()}





  //RightMenusFunction['copyImg'] = (fun) => {fun()}





  RightMenusFunction['googleImg'] = (__link__) => {window.open(`https://www.google.com.hk/searchbyimage?image_url=${__link__}`)}



















  RightMenusFunction['darkMode'] = () => {volantis.dark.toggle()}





  //RightMenusFunction['printMode'] = (fun) => {fun()}





  //RightMenusFunction['readMode'] = (fun) => {fun()}





</script>



<!-- rightmenu要在darkmode之前（ToggleButton） darkmode要在comments之前（volantis.dark.push）-->

  <script>
const rootElement = document.documentElement;
const darkModeStorageKey = "color-scheme";
const rootElementDarkModeAttributeName = "color-scheme";
const setLS = (k, v) => {
    localStorage.setItem(k, v);
};
const removeLS = (k) => {
    localStorage.removeItem(k);
};
const getLS = (k) => {
    return localStorage.getItem(k);
};
const getModeFromCSSMediaQuery = () => {
  return window.matchMedia("(prefers-color-scheme: dark)").matches
    ? "dark"
    : "light";
};
const resetRootDarkModeAttributeAndLS = () => {
  rootElement.removeAttribute(rootElementDarkModeAttributeName);
  removeLS(darkModeStorageKey);
};
const validColorModeKeys = {
  dark: true,
  light: true,
};
const applyCustomDarkModeSettings = (mode) => {
  const currentSetting = mode || getLS(darkModeStorageKey);
  getCustomDarkMode();
  if (currentSetting === getModeFromCSSMediaQuery()) {
    resetRootDarkModeAttributeAndLS();
  } else if (validColorModeKeys[currentSetting]) {
    rootElement.setAttribute(rootElementDarkModeAttributeName, currentSetting);
  } else {
    resetRootDarkModeAttributeAndLS();
  }
};
const invertDarkModeObj = {
  dark: "light",
  light: "dark",
};
/**
 * get target mode
 */
 const getCustomDarkMode = () => {
  let currentSetting = getLS(darkModeStorageKey);
  if (validColorModeKeys[currentSetting]) {
    currentSetting = invertDarkModeObj[currentSetting];
  } else if (currentSetting === null) {
    currentSetting = invertDarkModeObj[getModeFromCSSMediaQuery()];
  } else {
    return;
  }
  if(currentSetting=="dark"){
    volantis.dark.mode="light";
  }else{
    volantis.dark.mode="dark";
  }
  // console.log(volantis.dark.mode)
};
const toggleCustomDarkMode = () => {
  let currentSetting = getLS(darkModeStorageKey);
  if (validColorModeKeys[currentSetting]) {
    currentSetting = invertDarkModeObj[currentSetting];
  } else if (currentSetting === null) {
    currentSetting = invertDarkModeObj[getModeFromCSSMediaQuery()];
  } else {
    return;
  }
  setLS(darkModeStorageKey, currentSetting);
  return currentSetting;
};
/**
 * 暗黑模式触发器
 */
volantis.dark.toggle=()=>{
  const mode = toggleCustomDarkMode();
  applyCustomDarkModeSettings(mode);
  // 使用 volantis.dark.push 方法传入volantis.dark.toggle回调函数 参见layout/_partial/scripts/global.ejs
  volantis.dark.method.toggle.start();
}
/**
 * bind event for toggle button
 */

function bindToggleButton() {
  var btn= document.querySelectorAll("#wrapper .toggle-mode-btn,#rightmenu-wrapper .toggle-mode-btn")
  btn.forEach(function (e) {
    volantis.dom.$(e).on('click',volantis.dark.toggle);
  })
}
applyCustomDarkModeSettings();
document.addEventListener("DOMContentLoaded", ()=>{
  volantis.requestAnimationFrame(bindToggleButton)
});
volantis.pjax.push(bindToggleButton);

const darkModelListeners={
  dark:(mediaQueryList )=>{
    if(mediaQueryList.matches){
      volantis.dark.mode = "dark";
    }
    volantis.dark.method.toggle.start();
  },
  light:(mediaQueryList)=>{
    if(mediaQueryList.matches){
      volantis.dark.mode = "light";
    }
    volantis.dark.method.toggle.start();
  }
}
window.matchMedia('(prefers-color-scheme: dark)').addListener(darkModelListeners.dark)
window.matchMedia('(prefers-color-scheme: light)').addListener(darkModelListeners.light)
</script>




<script>
  function loadIssuesJS() {
    
      const sites_api = document.getElementById('sites-api');
      if (sites_api != undefined && typeof SitesJS === 'undefined') {
        volantis.js("/js/plugins/tags/sites.js")
      }
    
    
      const friends_api = document.getElementById('friends-api');
      if (friends_api != undefined && typeof FriendsJS === 'undefined') {
        volantis.js("/js/plugins/tags/friends.js")
      }
    
    
      const contributors_api = document.getElementById('contributors-api');
      if (contributors_api != undefined && typeof ContributorsJS === 'undefined') {
        volantis.js("/js/plugins/tags/contributors.js")
      }
    
  };
  loadIssuesJS()
  volantis.pjax.push(()=>{
    loadIssuesJS();
  })

</script>




  <script defer src="https://unpkg.com/volantis-static@0.0.1654736714924/libs/vanilla-lazyload/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 0
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    lazyLoadInstance.update();
  });
  document.addEventListener('pjax:complete', function () {
    lazyLoadInstance.update();
  });
</script>




  

<script>
  window.FPConfig = {
	delay: 0,
	ignoreKeywords: ["#"],
	maxRPS: 6,
	hoverDelay: 0
  };
</script>
<script defer src="https://unpkg.com/volantis-static@0.0.1654736714924/libs/flying-pages/flying-pages.min.js"></script>







  <script>
  volantis.css("https://unpkg.com/volantis-static@0.0.1654736714924/libs/aplayer/dist/APlayer.min.css");
  (async () => {
    // APlayer 需要在  MetingJS 之前加载
    await volantis.js("https://unpkg.com/volantis-static@0.0.1654736714924/libs/aplayer/dist/APlayer.min.js")
    await volantis.js("https://unpkg.com/volantis-static@0.0.1654736714924/libs/meting/dist/Meting.min.js")
  
    // 右键 music 需要在 APlayer  MetingJS 之后加载
    await volantis.js('/js/plugins/aplayer.js')
  
  })();

  function SetAPlayerPlugin(){
    let Metings = document.querySelectorAll('meting-js');
    if (Metings.length === 0) {return;};
    if (Metings[0].aplayer && Metings[0].aplayer.on) {
      // improve the accessibility https://web.dev/button-name/
      document.querySelectorAll(".aplayer-icon-menu").forEach(e=>{
        e.setAttribute("aria-label","Aplayer Menu")
      })
      // message see: /layout/_plugins/message/script.ejs
      
        try {
          setTimeout(() => {
            Metings.forEach((item, index) => {
              const aplayerItem = item.aplayer; if(!aplayerItem) return;
              const rightAplayerCheck = 'true' === 'true'
                && item.meta.id === '2185397204';
              if(rightAplayerCheck) RightMenuAplayer.checkAPlayer();
              if(aplayerItem.events.events.play.every(item => {return item.name !== 'messagePlay'})) {
                aplayerItem.on('play', function messagePlay() {
                  let index = aplayerItem.list.index;
                  let title = aplayerItem.list.audios[index].title;
                  let artist = aplayerItem.list.audios[index].artist;
                  setTimeout(() => {
                    VolantisApp.message('音乐通知', title + ' - ' + artist, {
                      icon: 'fa-solid fa-play',
                      transitionIn: 'flipInX',
                      transitionOut: 'flipOutX'
                    });
                  }, 100)
                });
              }
              if(aplayerItem.events.events.pause.every(item => {return item.name !== 'messagePause'})) {
                aplayerItem.on('pause', function messagePause() {
                  let index = aplayerItem.list.index;
                  let title = aplayerItem.list.audios[index].title;
                  let artist = aplayerItem.list.audios[index].artist;
                  setTimeout(() => {
                    // 歌曲播放结束也会触发 pause 事件，为了避免错误提示，等待一会儿
                    if(aplayerItem.paused) {
                      VolantisApp.message('音乐通知', title + ' - ' + artist, {
                        icon: 'fa-solid fa-pause',
                        transitionIn: 'flipInX',
                        transitionOut: 'flipOutX'
                      });
                    }
                  }, 100)
                });
              }
            });
          }, 500)
        } catch (error) { console.error(error); }
      
    }else{
      volantis.requestAnimationFrame(SetAPlayerPlugin)
    }
  }

  document.addEventListener("DOMContentLoaded", ()=>{
    SetAPlayerPlugin();
  });
  volantis.pjax.push(SetAPlayerPlugin);
</script>




      <script>
  volantis.layoutHelper("comments",`<div id="giscus_container"></div>`)

  volantis.giscus = {};

  function check_giscus() {
    if (volantis.dark.mode === "dark") {
      volantis.giscus.Theme = '';
    } else {
      volantis.giscus.Theme = '';
    }

    return document.getElementById("giscus_container");
  }

  function pjax_giscus() {
    const HEAD = check_giscus();
    if (!HEAD) return;
    let cfg = Object.assign({"theme":"light_tritanopia","repo":"pistachio0812/blog_comments","repo-id":"R_kgDOIEvaCA","category":"Announcements","category-id":"DIC_kwDOIEvaCM4CRrCs","mapping":"title","strict":"0","reactions-enabled":"1","emit-metadata":"0","input-position":"top","lang":"zh-CN","loading":"lazy","crossorigin":"anonymous"},pdata.commentConfig)
    const script = document.createElement('script');
    script.setAttribute('src', 'https://giscus.app/client.js');
    Object.keys(cfg).forEach(k=>{
      if (k != "theme") {
        script.setAttribute('data-'+k, cfg[k]);
      }
    })
    script.setAttribute('data-theme', volantis.giscus.Theme);
    script.setAttribute('crossorigin', "anonymous");
    HEAD.appendChild(script);
  }

  function dark_giscus() {
    const HEAD = check_giscus();
    if (!HEAD) return;

    const message = {
      setConfig: {
        theme: volantis.giscus.Theme
      }
    };
    const giscusIframe = document.querySelector('iframe.giscus-frame');
    giscusIframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
  }
  pjax_giscus();
  volantis.pjax.push(pjax_giscus);
  volantis.dark.push(dark_giscus);
</script>

    





<!-- optional -->

  <script>
  const SearchServiceDataPathRoot = ("/" || "/").endsWith("/") ?
    "/" || "/" :
    "//" || "/";
  const SearchServiceDataPath = SearchServiceDataPathRoot + "content.json";

  function loadSearchScript() {
    // see: layout/_partial/scripts/_ctrl/cdnCtrl.ejs
    return volantis.js("/js/search/hexo.js");
  }

  function loadSearchService() {
    loadSearchScript();
    document.querySelectorAll(".input.u-search-input").forEach((e) => {
      e.removeEventListener("focus", loadSearchService, false);
    });

    document.querySelectorAll(".u-search-form").forEach((e) => {
      e.addEventListener("submit", (event) => {
        event.preventDefault();
      }, false);
    });
  }

  // 打开并搜索 字符串 s
  function OpenSearch(s) {
    if (typeof SearchService === 'undefined')
      loadSearchScript().then(() => {
        SearchService.setQueryText(s);
        SearchService.search();
      });
    else {
      SearchService.setQueryText(s);
      SearchService.search();
    }
  }

  // 访问含有 ?s=xxx  的链接时打开搜索 // 与搜索引擎 structured data 相关: /scripts/helpers/structured-data/lib/config.js
  if (window.location.search && /^\?s=/g.test(window.location.search)) {
    let queryText = decodeURI(window.location.search)
      .replace(/\ /g, "-")
      .replace(/^\?s=/g, "");
    OpenSearch(queryText);
  }

  // 搜索输入框获取焦点时加载搜索
  document.querySelectorAll(".input.u-search-input").forEach((e) => {
    e.addEventListener("focus", loadSearchService, false);
  });
</script>



  
<script src="https://unpkg.com/volantis-static@0.0.1654736714924/libs/node-waves/dist/waves.min.js"></script>

<script type="text/javascript">
document.addEventListener("DOMContentLoaded", function () {
  Waves.attach('.flat-btn', ['waves-button']);
  Waves.attach('.float-btn', ['waves-button', 'waves-float']);
  Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
  Waves.attach('.flat-box', ['waves-block']);
  Waves.attach('.float-box', ['waves-block', 'waves-float']);
  Waves.attach('.waves-image');
  Waves.init();
});
</script>



  
<script src="https://unpkg.com/volantis-static@0.0.1654736714924/libs/comment_typing/comment_typing.js"></script>




  <script>

  volantis.css("https://unpkg.com/@highlightjs/cdn-assets@11.5.1/styles/default.min.css");


  volantis.js("https://unpkg.com/@highlightjs/cdn-assets@11.5.1/highlight.min.js").then(()=>{
    volantis.requestAnimationFrame(hljs.highlightAll)
  })
  volantis.pjax.push(()=>{
    document.querySelectorAll('pre code').forEach((block) => {
      hljs.highlightElement(block);
    });
  },"highlightjs")


  function pjax_highlightjs_copyCode(){
    if (!(document.querySelector(".highlight .code pre") ||
      document.querySelector(".article pre code"))) {
      return;
    }
    VolantisApp.utilCopyCode(".highlight .code pre, .article pre code")
  }
  volantis.requestAnimationFrame(pjax_highlightjs_copyCode)
  volantis.pjax.push(pjax_highlightjs_copyCode)

</script>








  <script src="//code.tidio.co/zilxs37hi5azxti3c2wescen575qkim6.js" async></script>





  <script>
  let imgs = ["https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/034.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/019.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/033.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/056.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/002.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/042.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/016.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/001.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/003.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/046.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/035.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/038.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/006.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/051.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/054.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/004.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/005.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/052.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/039.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/025.webp","https://unpkg.com/volantis-static@0.0.1654736714924/media/wallpaper/minimalist/2020/012.webp"];
  let index = 0;
  let IntervalParallax = null;

  function parallax(){
    let ParallaxWindow = document.querySelector("#parallax-window");
    
      ParallaxWindow = document.querySelector("html");
    
    Parallax.window = ParallaxWindow;
    Parallax.options.fade = 1500;
    Parallax.cache = 1;
    next_parallax();
    Parallax.init();
    if (imgs.length>1) {
      IntervalParallax = setInterval(function () {
        next_parallax();
      }, '10000');
    }
  }

  function next_parallax() {
    if (typeof Parallax == "undefined") {
      return
    }
    
    if (imgs.length>=1) {
      Parallax.options.src = imgs[index % imgs.length];
      Parallax.start();
      index++;
      if (Parallax.cache) {
        fetch(imgs[index % imgs.length] +"?t=" + new Date().getTime());
        if (index == imgs.length) {
          Parallax.cache = 0;
        }
      }
    }
  }
  var runningOnBrowser = typeof window !== "undefined";
  var isBot = runningOnBrowser && !("onscroll" in window) || typeof navigator !== "undefined" && /(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent);
  if (!isBot) {
    volantis.js('/js/plugins/parallax.js').then(()=>{
      parallax()
    })
    volantis.pjax.send(()=>{
      clearInterval(IntervalParallax)
    },"clearIntervalParallax");
    volantis.pjax.push(parallax);
  }
</script>




  <script>
  function load_swiper() {
    if (!document.querySelectorAll(".swiper-container")[0]) return;
    volantis.css("https://unpkg.com/volantis-static@0.0.1654736714924/libs/swiper/swiper-bundle.min.css");
    volantis.js("https://unpkg.com/volantis-static@0.0.1654736714924/libs/swiper/swiper-bundle.min.js").then(() => {
      pjax_swiper();
    });
  }

  load_swiper();

  function pjax_swiper() {
    volantis.swiper = new Swiper('.swiper-container', {
      slidesPerView: 'auto',
      spaceBetween: 8,
      centeredSlides: true,
      loop: true,
      pagination: {
        el: '.swiper-pagination',
        clickable: true,
      },
      navigation: {
        nextEl: '.swiper-button-next',
        prevEl: '.swiper-button-prev',
      },
    });
  }

  volantis.pjax.push(() => {
    if (!document.querySelectorAll(".swiper-container")[0]) return;
    if (typeof volantis.swiper === "undefined") {
      load_swiper();
    } else {
      pjax_swiper();
    }
  });
</script>


<!-- pjax 标签必须存在于所有页面 否则 pjax error -->
<pjax>

</pjax>

<script>
  function listennSidebarTOC() {
    const navItems = document.querySelectorAll(".toc li");
    if (!navItems.length) return;
    let targets = []
    const sections = [...navItems].map((element) => {
      const link = element.querySelector(".toc-link");
      const target = document.getElementById(
        decodeURI(link.getAttribute("href")).replace("#", "")
      );
      targets.push(target)
      // 解除 a 标签 href 的 锚点定位, a 标签 href 的 锚点定位 会随机启用?? 产生错位???
      link.setAttribute("onclick","return false;")
      link.setAttribute("toc-action","toc-"+decodeURI(link.getAttribute("href")).replace("#", ""))
      link.setAttribute("href","/")
      // 配置 点击 触发新的锚点定位
      link.addEventListener("click", (event) => {
        event.preventDefault();
        // 这里的 addTop 是通过错位使得 toc 自动展开.
        volantis.scroll.to(target,{addTop: 5, observer:true})
        // Anchor id
        history.pushState(null, document.title, "#" + target.id);
      });
      return target;
    });

    function activateNavByIndex(target) {
      if (target.classList.contains("active-current")) return;

      document.querySelectorAll(".toc .active").forEach((element) => {
        element.classList.remove("active", "active-current");
      });
      target.classList.add("active", "active-current");
      let parent = target.parentNode;
      while (!parent.matches(".toc")) {
        if (parent.matches("li")) parent.classList.add("active");
        parent = parent.parentNode;
      }
    }

    // 方案一：
    volantis.activateNavIndex=0
    activateNavByIndex(navItems[volantis.activateNavIndex])
    volantis.scroll.push(()=>{
      if (targets[0].getBoundingClientRect().top >= 0) {
        volantis.activateNavIndex = 0
      }else if (targets[targets.length-1].getBoundingClientRect().top < 0) {
        volantis.activateNavIndex = targets.length-1
      } else {
        for (let index = 0; index < targets.length; index++) {
          const target0 = targets[index];
          const target1 = targets[(index+1)%targets.length];
          if (target0.getBoundingClientRect().top < 0&&target1.getBoundingClientRect().top >= 0) {
            volantis.activateNavIndex=index
            break;
          }
        }
      }
      activateNavByIndex(navItems[volantis.activateNavIndex])
    })

    // 方案二：
    // IntersectionObserver 不是完美精确到像素级别 也不是低延时性的
    // function findIndex(entries) {
    //   let index = 0;
    //   let entry = entries[index];
    //   if (entry.boundingClientRect.top > 0) {
    //     index = sections.indexOf(entry.target);
    //     return index === 0 ? 0 : index - 1;
    //   }
    //   for (; index < entries.length; index++) {
    //     if (entries[index].boundingClientRect.top <= 0) {
    //       entry = entries[index];
    //     } else {
    //       return sections.indexOf(entry.target);
    //     }
    //   }
    //   return sections.indexOf(entry.target);
    // }
    // function createIntersectionObserver(marginTop) {
    //   marginTop = Math.floor(marginTop + 10000);
    //   let intersectionObserver = new IntersectionObserver(
    //     (entries, observe) => {
    //       let scrollHeight = document.documentElement.scrollHeight;
    //       if (scrollHeight > marginTop) {
    //         observe.disconnect();
    //         createIntersectionObserver(scrollHeight);
    //         return;
    //       }
    //       let index = findIndex(entries);
    //       activateNavByIndex(navItems[index]);
    //     }, {
    //       rootMargin: marginTop + "px 0px -100% 0px",
    //       threshold: 0,
    //     }
    //   );
    //   sections.forEach((element) => {
    //     element && intersectionObserver.observe(element);
    //   });
    // }
    // createIntersectionObserver(document.documentElement.scrollHeight);
  }

  document.addEventListener("DOMContentLoaded", ()=>{
    volantis.requestAnimationFrame(listennSidebarTOC)
  });
  document.addEventListener("pjax:success", ()=>{
    volantis.requestAnimationFrame(listennSidebarTOC)
  });
</script>



<script>
  document.onreadystatechange = function () {
    if (document.readyState == 'complete') {
      // 页面加载完毕 样式加载失败，或是当前网速慢，或是开启了省流模式
      const { saveData, effectiveType } = navigator.connection || navigator.mozConnection || navigator.webkitConnection || {}
      if (getComputedStyle(document.querySelector("#safearea"), null)["display"] == "none" || saveData || /2g/.test(effectiveType)) {
        document.querySelectorAll(".reveal").forEach(function (e) {
          e.style["opacity"] = "1";
        });
        document.querySelector("#safearea").style["display"] = "block";
      }
    }
  }
</script>


  <script type="application/ld+json">[{"@context":"http://schema.org","@type":"Organization","name":"阿月浑子-Hexo博客","url":"http://pistachio0812.github.io/","logo":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png","width":192,"height":192}},{"@context":"http://schema.org","@type":"Person","name":"pistachio","image":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png"},"url":"http://pistachio0812.github.io/","sameAs":["https://github.com/volantis-x"],"description":"计算机视觉,文学,pytorch,hexo,江西理工大学,目标检测"},{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"http://pistachio0812.github.io/","name":"阿月浑子-Hexo博客"}},{"@type":"ListItem","position":2,"item":{"@id":"http://pistachio0812.github.io/categories/深度学习/","name":"深度学习"}},{"@type":"ListItem","position":3,"item":{"@id":"http://pistachio0812.github.io/zh-TW/ch17_模型部署/第十七章_模型压缩、加速及移动端部署/","name":"模型压缩及移动端部署"}}]},{"@context":"http://schema.org","@type":"WebSite","name":"阿月浑子-Hexo博客","url":"http://pistachio0812.github.io/","keywords":null,"description":"计算机视觉,文学,pytorch,hexo,江西理工大学,目标检测","author":{"@type":"Person","name":"pistachio","image":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png"},"url":"http://pistachio0812.github.io/","description":"计算机视觉,文学,pytorch,hexo,江西理工大学,目标检测"},"publisher":{"@type":"Organization","name":"阿月浑子-Hexo博客","url":"http://pistachio0812.github.io/","logo":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png","width":192,"height":192}},"potentialAction":{"@type":"SearchAction","name":"Site Search","target":{"@type":"EntryPoint","urlTemplate":"http://pistachio0812.github.io?s={search_term_string}"},"query-input":"required name=search_term_string"}},{"@context":"http://schema.org","@type":"BlogPosting","headline":"模型压缩及移动端部署","description":"计算机视觉,文学,pytorch,hexo,江西理工大学,目标检测","inLanguage":["zh-CN","en","zh-TW","default"],"mainEntityOfPage":{"@type":"WebPage","@id":"http://pistachio0812.github.io/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/"},"author":{"@type":"Person","name":"pistachio","image":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png"},"url":"http://pistachio0812.github.io/"},"publisher":{"@type":"Organization","name":"阿月浑子-Hexo博客","logo":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png","width":192,"height":192}},"url":"http://pistachio0812.github.io/zh-TW/ch17_%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E3%80%81%E5%8A%A0%E9%80%9F%E5%8F%8A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/","wordCount":0,"datePublished":"2024-01-24T01:24:21.236Z","dateModified":"2024-04-08T08:57:59.134Z","articleSection":"深度学习","image":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png","width":192,"height":192}}]</script>



      
        <!--
  pjax重载区域接口：
  1.  <pjax></pjax> 标签 pjax 标签必须存在于所有页面 否则 pjax error
  2.  script[data-pjax]
  3.  .pjax-reload script
  4.  .pjax
-->



<script src="https://unpkg.com/volantis-static@0.0.1654736714924/libs/pjax/pjax.min.js"></script>


<script>
    var pjax;
    document.addEventListener('DOMContentLoaded', function () {
      pjax = new Pjax({
        elements: 'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([pjax-fancybox]):not([onclick="return false;"]):not([onclick="return!1"]):not([target="_blank"]):not([target="view_window"]):not([href$=".xml"])',
        selectors: [
          "head title",
          "head meta[name=keywords]",
          "head meta[name=description]",
          
          "#l_main",
          "#pjax-header-nav-list",
          ".pjax",
          "pjax", // <pjax></pjax> 标签
          "script[data-pjax], .pjax-reload script" // script标签添加data-pjax 或 script标签外层添加.pjax-reload 的script代码段重载
        ],
        cacheBust: false,   // url 地址追加时间戳，用以避免浏览器缓存
        timeout: 5000,
        
      });
    });

    document.addEventListener('pjax:send', function (e) {
      //window.stop(); // 相当于点击了浏览器的停止按钮

      try {
        var currentUrl = window.location.pathname;
        var targetUrl = e.triggerElement.href;
        var banUrl = [""];
        if (banUrl[0] != "") {
          banUrl.forEach(item => {
            if(currentUrl.indexOf(item) != -1 || targetUrl.indexOf(item) != -1) {
              window.location.href = targetUrl;
            }
          });
        }
      } catch (error) {}

      // 使用 volantis.pjax.send 方法传入pjax:send回调函数 参见layout/_partial/scripts/global.ejs
      volantis.pjax.method.send.start();
    });

    document.addEventListener('pjax:complete', function () {
      // 使用 volantis.pjax.push 方法传入重载函数 参见layout/_partial/scripts/global.ejs
      volantis.pjax.method.complete.start();
    });

    document.addEventListener('pjax:error', function (e) {
      if(volantis.debug) {
        console.error(e);
        console.log('pjax error: \n' + JSON.stringify(e));
      }else{
        // 使用 volantis.pjax.error 方法传入pjax:error回调函数 参见layout/_partial/scripts/global.ejs
        volantis.pjax.method.error.start();
        window.location.href = e.triggerElement.href;
      }
    });
</script>

      
    </div>
    <!-- import body_end begin-->
        <script></script>
    <!-- import body_end end-->
    <!-- Custom Files bodyEnd begin-->
    <script> 
  volantis.rightmenu.jump = (type) => { 
    const selector = type === 'prev' ? 'article .prev-next a.prev' : 'article .prev-next a.next';
    const item = document.querySelector(selector); 
    if(!!item) { 
      if(typeof pjax !== 'undefined') { 
        pjax.loadUrl(item.href) 
      } else { 
        window.location.href = item.href; 
      } 
    } 
  } 
 
  volantis.rightmenu.handle(() => { 
    const prev = document.querySelector('#prev').parentElement, 
      next = document.querySelector('#next').parentElement, 
      articlePrev = document.querySelector('article .prev-next a.prev p.title'), 
      articleNext = document.querySelector('article .prev-next a.next p.title'); 
 
    prev.style.display = articlePrev ? 'block' : 'none'; 
    prev.title = articlePrev ? articlePrev.innerText : null; 
    next.style.display = articleNext ? 'block' : 'none'; 
    next.title = articleNext ? articleNext.innerText : null; 
  }, 'prevNext', false) 
</script> 
    <!-- Custom Files bodyEnd end-->
  <script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>